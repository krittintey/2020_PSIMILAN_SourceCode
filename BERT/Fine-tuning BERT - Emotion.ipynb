{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 GPU(s) available.\n",
      "Device name: GeForce RTX 2080 Ti\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():       \n",
    "    device = torch.device(\"cuda:1\")\n",
    "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
    "    print('Device name:', torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Input Sentiment\n",
       "0                                i didnt feel humiliated   sadness\n",
       "1      i can go from feeling so hopeless to so damned...   sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong     anger\n",
       "3      i am ever feeling nostalgic about the fireplac...      love\n",
       "4                                   i am feeling grouchy     anger\n",
       "...                                                  ...       ...\n",
       "15995  i just had a very brief time in the beanbag an...   sadness\n",
       "15996  i am now turning and i feel pathetic that i am...   sadness\n",
       "15997                     i feel strong and good overall       joy\n",
       "15998  i feel like this was such a rude comment and i...     anger\n",
       "15999  i know a lot but i feel so stupid because i ca...   sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../Dataset/emotion/train.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input Sentiment\n",
       "0     im feeling rather rotten so im not very ambiti...   sadness\n",
       "1             im updating my blog because i feel shitty   sadness\n",
       "2     i never make her separate from me because i do...   sadness\n",
       "3     i left with my bouquet of red and yellow tulip...       joy\n",
       "4       i was feeling a little vain when i did this one   sadness\n",
       "...                                                 ...       ...\n",
       "1995  i just keep feeling like someone is being unki...     anger\n",
       "1996  im feeling a little cranky negative after this...     anger\n",
       "1997  i feel that i am useful to my people and that ...       joy\n",
       "1998  im feeling more comfortable with derby i feel ...       joy\n",
       "1999  i feel all weird when i have to meet w people ...      fear\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../Dataset/emotion/test.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input Sentiment\n",
       "0     im feeling quite sad and sorry for myself but ...   sadness\n",
       "1     i feel like i am still looking at a blank canv...   sadness\n",
       "2                        i feel like a faithful servant      love\n",
       "3                     i am just feeling cranky and blue     anger\n",
       "4     i can have for a treat or if i am feeling festive       joy\n",
       "...                                                 ...       ...\n",
       "1995  im having ssa examination tomorrow in the morn...   sadness\n",
       "1996  i constantly worry about their fight against n...       joy\n",
       "1997  i feel its important to share this info for th...       joy\n",
       "1998  i truly feel that if you are passionate enough...       joy\n",
       "1999  i feel like i just wanna buy any cute make up ...       joy\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('../Dataset/emotion/val.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16000, 6)\n",
      "(2000, 6)\n",
      "(2000, 6)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "\n",
    "encode = LabelEncoder()\n",
    "\n",
    "labels_train = encode.fit_transform(df_train['Sentiment'])\n",
    "labels_test = encode.fit_transform(df_test['Sentiment'])\n",
    "labels_val = encode.fit_transform(df_val['Sentiment'])\n",
    "\n",
    "y_train = np_utils.to_categorical(labels_train)\n",
    "y_test = np_utils.to_categorical(labels_test)\n",
    "y_val = np_utils.to_categorical(labels_val)\n",
    "\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = { 'anger': 0,\n",
    "    'fear': 1,\n",
    "    'joy': 2,\n",
    "    'love': 3,\n",
    "    'sadness': 4,\n",
    "    'surprise': 5\n",
    "}\n",
    "\n",
    "X = np.concatenate([df_train['Input'].values, df_val['Input'].values])\n",
    "X_train = df_train['Input'].values\n",
    "y_train = [encoding[key] for key in df_train['Sentiment'].values]\n",
    "X_val = df_val['Input'].values\n",
    "y_val = [encoding[key] for key in df_val['Sentiment'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 4, 0, 3, 0, 4, 5, 1, 2, 3, 4, 2, 0, 4, 2, 2, 4, 4, 4, 1, 0, 1, 2, 2, 0, 4, 4, 4, 0, 2, 2, 1, 5, 0, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 4, 4, 2, 3, 2, 0, 2, 4, 0, 1, 2, 4, 4, 5, 2, 2, 2, 3, 1, 1, 5, 0, 0, 4, 3, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 0, 4, 0, 0, 0, 2, 2, 2, 2, 4, 1, 3, 0, 4, 0, 3, 4, 2, 2, 4, 0, 3, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 3, 4, 4, 2, 2, 4, 2, 2, 1, 1, 1, 4, 3, 2, 2, 3, 1, 5, 2, 2, 2, 2, 0, 1, 2, 0, 3, 0, 4, 2, 4, 0, 2, 5, 4, 0, 0, 4, 2, 1, 2, 2, 1, 4, 5, 5, 2, 0, 1, 0, 4, 0, 4, 1, 4, 2, 5, 1, 2, 0, 2, 0, 2, 1, 1, 4, 2, 2, 4, 5, 2, 1, 2, 4, 2, 2, 2, 1, 2, 5, 2, 0, 4, 4, 2, 0, 4, 2, 2, 5, 2, 1, 2, 1, 4, 1, 3, 4, 1, 3, 4, 4, 0, 2, 3, 0, 4, 5, 0, 2, 4, 0, 2, 2, 2, 2, 2, 4, 2, 3, 2, 4, 0, 5, 2, 0, 2, 3, 4, 4, 2, 4, 4, 2, 4, 2, 2, 2, 1, 4, 0, 4, 0, 3, 2, 3, 4, 2, 2, 2, 4, 2, 4, 0, 3, 4, 3, 4, 4, 4, 4, 4, 4, 1, 2, 4, 4, 2, 3, 4, 0, 4, 3, 2, 2, 2, 4, 2, 4, 2, 2, 2, 4, 4, 4, 3, 1, 4, 1, 2, 2, 1, 2, 0, 0, 3, 4, 5, 2, 0, 4, 4, 0, 3, 5, 4, 3, 2, 0, 2, 4, 4, 2, 2, 1, 4, 0, 2, 3, 2, 2, 2, 2, 2, 3, 2, 1, 1, 2, 2, 0, 2, 2, 2, 4, 5, 2, 2, 4, 5, 2, 1, 2, 0, 3, 0, 1, 5, 2, 0, 4, 4, 4, 1, 2, 1, 2, 0, 4, 3, 0, 4, 3, 3, 2, 4, 2, 2, 0, 2, 3, 2, 2, 4, 5, 2, 2, 4, 5, 0, 2, 2, 3, 2, 3, 3, 2, 4, 2, 4, 1, 0, 4, 0, 2, 1, 5, 3, 4, 4, 2, 5, 3, 4, 4, 2, 1, 2, 2, 2, 3, 1, 4, 4, 1, 3, 2, 4, 2, 4, 2, 4, 2, 4, 2, 2, 0, 4, 1, 4, 4, 0, 5, 5, 2, 5, 1, 3, 0, 2, 1, 4, 0, 4, 2, 1, 2, 2, 2, 2, 5, 0, 4, 2, 4, 0, 3, 4, 3, 0, 3, 3, 2, 2, 4, 2, 4, 2, 0, 2, 1, 4, 2, 4, 5, 2, 2, 3, 2, 4, 0, 2, 4, 4, 4, 2, 2, 2, 4, 4, 0, 0, 2, 4, 5, 2, 2, 4, 0, 2, 0, 2, 2, 3, 0, 2, 2, 2, 2, 2, 2, 2, 1, 2, 1, 4, 0, 0, 4, 3, 4, 4, 4, 5, 1, 4, 4, 2, 1, 2, 4, 4, 0, 4, 0, 0, 3, 2, 2, 4, 2, 2, 2, 3, 3, 3, 2, 5, 1, 4, 0, 4, 1, 2, 0, 2, 2, 4, 2, 1, 2, 0, 4, 0, 2, 3, 3, 4, 1, 4, 4, 4, 1, 4, 0, 2, 2, 4, 1, 1, 0, 0, 4, 4, 0, 0, 2, 1, 4, 4, 1, 2, 1, 4, 4, 2, 4, 0, 4, 3, 5, 2, 2, 2, 2, 2, 4, 4, 3, 1, 0, 2, 3, 2, 2, 1, 0, 1, 4, 0, 0, 0, 1, 2, 3, 0, 1, 0, 2, 1, 4, 4, 0, 2, 0, 1, 1, 5, 4, 2, 2, 2, 3, 4, 2, 4, 0, 2, 2, 1, 1, 2, 1, 0, 0, 0, 2, 4, 2, 2, 2, 0, 1, 0, 2, 4, 2, 1, 2, 4, 0, 4, 4, 2, 2, 4, 3, 2, 4, 0, 3, 4, 2, 2, 1, 0, 2, 2, 3, 5, 1, 1, 0, 0, 3, 4, 4, 2, 3, 0, 2, 0, 2, 2, 2, 1, 1, 3, 4, 3, 2, 2, 4, 4, 0, 0, 0, 0, 4, 2, 4, 2, 1, 4, 2, 4, 2, 5, 1, 2, 2, 1, 1, 4, 4, 0, 4, 3, 2, 5, 2, 5, 2, 1, 2, 2, 2, 2, 5, 3, 4, 3, 2, 4, 2, 2, 4, 2, 2, 2, 2, 1, 1, 1, 1, 0, 3, 4, 2, 2, 4, 4, 4, 4, 2, 4, 4, 1, 2, 0, 2, 2, 1, 0, 2, 0, 0, 0, 0, 0, 2, 1, 4, 3, 4, 1, 3, 2, 5, 2, 2, 2, 2, 4, 5, 2, 0, 0, 0, 2, 2, 4, 3, 4, 2, 0, 0, 0, 1, 2, 2, 1, 4, 5, 2, 3, 4, 2, 2, 4, 4, 4, 0, 2, 4, 4, 4, 4, 2, 5, 2, 0, 3, 2, 0, 4, 2, 0, 4, 1, 1, 4, 4, 1, 4, 3, 1, 2, 2, 1, 2, 0, 2, 2, 0, 2, 2, 3, 0, 2, 2, 2, 0, 2, 3, 1, 0, 3, 4, 1, 4, 4, 3, 2, 1, 3, 2, 2, 4, 2, 4, 1, 2, 4, 3, 4, 3, 4, 4, 0, 3, 0, 2, 0, 4, 4, 2, 2, 0, 4, 5, 2, 3, 4, 0, 1, 3, 2, 2, 0, 2, 4, 2, 2, 2, 3, 2, 4, 3, 1, 4, 2, 4, 0, 2, 2, 4, 2, 3, 2, 2, 2, 0, 1, 4, 2, 4, 4, 3, 0, 2, 3, 4, 2, 1, 4, 2, 2, 4, 4, 3, 2, 4, 4, 4, 4, 0, 4, 2, 4, 2, 4, 3, 0, 2, 1, 4, 4, 2, 2, 0, 1, 3, 2, 4, 0, 4, 2, 4, 2, 2, 4, 3, 2, 2, 4, 0, 4, 0, 4, 2, 4, 0, 2, 5, 4, 1, 4, 1, 4, 0, 0, 2, 0, 2, 2, 2, 4, 1, 2, 2, 0, 2, 1, 2, 3, 4, 4, 4, 4, 2, 3, 1, 2, 0, 4, 2, 1, 2, 2, 4, 1, 4, 2, 4, 4, 4, 4, 3, 4, 1, 1, 2, 3, 4, 4, 3, 2, 4, 4, 4, 4, 3, 2, 2, 4, 1, 2, 2, 2, 2, 2, 0, 1, 3, 2, 0, 3, 3, 2, 4, 4, 0, 2, 2, 1, 2, 2, 4, 4, 3, 2, 2, 2, 2, 2, 4, 2, 3, 2, 1, 2, 4, 2, 2, 1, 2, 4, 1, 2, 4, 2, 4, 1, 2, 2, 1, 4, 4, 2, 2, 2, 2, 1, 2, 2, 1, 2, 1, 5, 2, 1, 5, 1, 2, 2, 5, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 1, 4, 0, 2, 4, 2, 1, 3, 3, 1, 4, 4, 2, 1, 4, 3, 0, 2, 4, 2, 2, 4, 1, 4, 2, 4, 4, 2, 4, 4, 4, 1, 2, 0, 4, 4, 2, 2, 2, 2, 3, 2, 1, 2, 2, 2, 1, 4, 4, 2, 4, 4, 2, 4, 4, 4, 2, 4, 1, 0, 4, 2, 1, 2, 4, 2, 2, 1, 1, 4, 2, 5, 2, 0, 3, 4, 4, 3, 0, 1, 1, 2, 4, 3, 4, 4, 2, 2, 4, 3, 2, 2, 2, 2, 0, 5, 3, 0, 4, 4, 2, 4, 2, 2, 2, 4, 0, 4, 4, 4, 2, 0, 2, 4, 4, 2, 0, 2, 2, 3, 4, 2, 4, 5, 0, 2, 4, 1, 2, 2, 0, 2, 2, 4, 0, 3, 2, 4, 5, 3, 3, 4, 4, 4, 3, 4, 3, 2, 2, 4, 3, 2, 0, 4, 2, 0, 4, 0, 2, 3, 2, 1, 0, 2, 4, 1, 4, 4, 4, 4, 4, 1, 3, 4, 4, 2, 4, 3, 0, 2, 5, 2, 1, 4, 1, 4, 2, 0, 0, 5, 2, 3, 4, 5, 2, 2, 5, 4, 3, 2, 0, 1, 4, 4, 4, 4, 4, 0, 2, 2, 2, 4, 5, 5, 0, 2, 2, 1, 2, 4, 1, 0, 0, 1, 3, 1, 0, 0, 0, 4, 1, 2, 2, 1, 1, 0, 2, 0, 2, 2, 3, 0, 4, 1, 2, 0, 4, 0, 4, 3, 0, 1, 2, 1, 4, 4, 0, 2, 1, 4, 3, 3, 4, 0, 0, 2, 4, 0, 4, 4, 1, 2, 4, 4, 2, 0, 4, 2, 2, 0, 2, 2, 0, 0, 4, 2, 0, 4, 1, 4, 1, 2, 1, 2, 2, 2, 2, 4, 0, 4, 2, 1, 2, 4, 2, 1, 2, 2, 2, 2, 4, 2, 0, 2, 2, 2, 2, 1, 2, 1, 4, 3, 2, 2, 2, 2, 0, 2, 1, 4, 0, 2, 2, 4, 5, 5, 2, 4, 4, 3, 1, 2, 3, 3, 2, 4, 4, 2, 0, 2, 2, 2, 1, 1, 2, 4, 5, 2, 2, 2, 2, 2, 4, 0, 1, 0, 4, 2, 0, 1, 3, 4, 3, 2, 4, 3, 4, 2, 2, 3, 4, 3, 0, 2, 3, 2, 1, 4, 4, 5, 4, 2, 2, 2, 0, 4, 2, 2, 4, 2, 2, 4, 4, 2, 0, 2, 1, 0, 2, 2, 2, 1, 4, 2, 1, 4, 4, 0, 4, 2, 2, 0, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 1, 3, 1, 1, 1, 0, 0, 4, 2, 4, 4, 4, 4, 1, 2, 4, 2, 1, 1, 4, 0, 1, 4, 4, 2, 0, 4, 4, 2, 4, 1, 0, 0, 2, 2, 4, 2, 2, 4, 4, 2, 4, 1, 2, 4, 4, 4, 1, 2, 5, 4, 2, 3, 2, 0, 5, 2, 2, 4, 4, 2, 2, 1, 2, 0, 2, 2, 2, 1, 2, 0, 2, 0, 4, 2, 4, 4, 2, 1, 2, 2, 1, 4, 4, 3, 4, 0, 4, 4, 0, 0, 4, 3, 4, 3, 2, 4, 2, 3, 1, 2, 1, 2, 0, 2, 4, 2, 2, 1, 5, 4, 2, 4, 5, 4, 4, 4, 4, 2, 1, 4, 4, 0, 2, 4, 3, 1, 0, 4, 1, 4, 2, 2, 2, 5, 2, 4, 2, 0, 2, 2, 0, 0, 4, 5, 1, 5, 2, 1, 4, 3, 2, 2, 0, 4, 3, 4, 4, 2, 0, 4, 4, 0, 5, 2, 0, 4, 0, 0, 4, 2, 5, 1, 2, 2, 1, 2, 0, 4, 4, 2, 2, 4, 2, 4, 1, 0, 4, 2, 0, 0, 3, 2, 2, 2, 2, 0, 2, 2, 4, 2, 2, 2, 2, 1, 4, 4, 4, 2, 2, 4, 4, 2, 2, 3, 4, 0, 4, 3, 2, 4, 2, 4, 2, 0, 2, 4, 4, 4, 5, 0, 2, 4, 4, 0, 2, 2, 4, 1, 2, 3, 4, 0, 1, 1, 3, 4, 3, 2, 3, 4, 4, 2, 3, 1, 4, 2, 2, 4, 4, 3, 2, 1, 1, 0, 2, 1, 1, 5, 4, 2, 1, 2, 1, 2, 4, 3, 2, 2, 0, 4, 2, 2, 0, 4, 4, 2, 2, 1, 2, 1, 2, 2, 2, 1, 2, 0, 0, 2, 1, 4, 2, 4, 4, 0, 4, 0, 4, 4, 2, 4, 1, 4, 3, 1, 2, 4, 1, 3, 2, 1, 4, 4, 4, 2, 2, 2, 2, 4, 0, 1, 2, 2, 2, 4, 5, 1, 2, 2, 4, 2, 3, 2, 4, 1, 2, 0, 2, 2, 0, 1, 3, 5, 0, 2, 4, 4, 4, 4, 4, 0, 5, 1, 2, 4, 4, 2, 4, 2, 3, 0, 4, 1, 4, 2, 4, 3, 2, 4, 3, 3, 4, 1, 2, 2, 3, 2, 2, 4, 2, 4, 3, 3, 0, 4, 2, 4, 1, 2, 4, 2, 1, 4, 2, 5, 5, 2, 4, 0, 1, 0, 4, 4, 5, 2, 4, 0, 4, 1, 3, 2, 2, 5, 2, 4, 0, 1, 4, 2, 2, 1, 2, 2, 2, 4, 0, 2, 0, 4, 2, 4, 4, 1, 3, 1, 2, 2, 2, 2, 1, 0, 5, 2, 4, 4, 2, 1, 4, 2, 4, 2, 4, 2, 2, 2, 3, 1, 2, 4, 4, 5, 3, 1, 0, 0, 4, 4, 2, 3, 2, 3, 2, 1, 4, 3, 4, 4, 4, 4, 0, 4, 4, 2, 4, 4, 4, 3, 0, 0, 4, 4, 2, 1, 0, 4, 2, 2, 5, 3, 2, 0, 2, 2, 4, 5, 4, 2, 5, 0, 2, 4, 2, 3, 2, 2, 1, 5, 2, 1, 2, 0, 1, 2, 4, 4, 4, 2, 0, 2, 3, 4, 4, 2, 0, 4, 2, 2, 5, 4, 2, 4, 4, 3, 0, 0, 2, 5, 0, 3, 3, 0, 4, 0, 4, 0, 2, 4, 1, 2, 3, 1, 2, 2, 2, 2, 4, 4, 1, 2, 0, 4, 4, 0, 4, 0, 4, 1, 5, 4, 2, 2, 2, 0, 4, 2, 4, 2, 2, 4, 1, 4, 2, 5, 2, 3, 2, 1, 0, 4, 2, 2, 2, 0, 4, 4, 0, 1, 4, 0, 4, 4, 0, 2, 5, 4, 1, 4, 1, 1, 1, 4, 2, 3, 2, 2, 4, 0, 0, 0, 5, 2, 5, 1, 2, 0, 4, 1, 2, 1, 2, 3, 4, 4, 4, 4, 5, 4, 2, 2, 4, 2, 2, 1, 2, 3, 0, 1, 2, 4, 0, 4, 3, 2, 2, 5, 0, 4, 2, 2, 2, 4, 2, 3, 0, 2, 2, 0, 0, 4, 3, 4, 2, 2, 0, 2, 2, 4, 3, 3, 2, 0, 2, 2, 5, 4, 4, 2, 0, 4, 0, 4, 2, 2, 2, 2, 4, 1, 2, 4, 4, 0, 0, 2, 2, 4, 1, 4, 4, 0, 1, 0, 0, 2, 4, 2, 2, 5, 1, 2, 4, 2, 1, 5, 0, 2, 4, 1, 1, 0, 3, 2, 0, 2, 4, 5, 4, 0, 4, 5, 1, 4, 4, 4, 0, 4, 2, 1, 2, 2, 4, 4, 3, 0, 2, 4, 3, 4, 2, 2, 2, 1, 3, 2, 2, 1, 2, 0, 4, 3, 4, 0, 0, 2, 3, 4, 4, 2, 4, 2, 5, 2, 0, 1, 0, 2, 4, 2, 4, 0, 1, 4, 4, 4, 0, 2, 1, 0, 4, 0, 2, 4, 1, 1, 2, 4, 3, 5, 1, 2, 0, 2, 2, 4, 2, 2, 2, 4, 0, 2, 0, 2, 0, 3, 3, 3, 5, 4, 2, 2, 4, 2, 1, 2, 3, 2, 4, 4, 2, 1, 2, 4, 2, 1, 4, 2, 4, 5, 2, 1, 2, 4, 4, 4, 4, 4, 1, 2, 2, 0, 1, 0, 2, 2, 2, 0, 0, 4, 4, 4, 0, 3, 4, 0, 2, 0, 4, 2, 2, 2, 2, 4, 2, 4, 4, 2, 4, 2, 1, 2, 0, 2, 4, 4, 5, 2, 2, 2, 0, 2, 0, 2, 2, 2, 2, 5, 4, 2, 3, 2, 4, 4, 5, 0, 0, 3, 2, 0, 0, 0, 1, 4, 1, 2, 1, 3, 2, 0, 4, 3, 4, 5, 4, 2, 2, 4, 2, 2, 4, 2, 2, 1, 2, 2, 0, 2, 2, 4, 4, 4, 2, 4, 4, 1, 1, 3, 2, 2, 2, 1, 4, 0, 4, 4, 4, 2, 4, 4, 4, 4, 4, 2, 2, 0, 0, 0, 4, 0, 2, 4, 4, 1, 4, 2, 2, 0, 4, 1, 1, 4, 3, 4, 2, 4, 4, 1, 5, 4, 2, 5, 0, 4, 0, 0, 4, 0, 5, 2, 2, 4, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 3, 2, 1, 4, 2, 2, 4, 0, 2, 2, 2, 4, 4, 2, 4, 2, 2, 4, 4, 4, 2, 0, 5, 1, 2, 1, 4, 2, 4, 4, 4, 2, 1, 2, 4, 2, 2, 2, 4, 4, 2, 2, 1, 2, 0, 0, 2, 4, 2, 4, 4, 4, 4, 2, 1, 4, 4, 4, 0, 2, 3, 3, 2, 4, 4, 3, 4, 0, 4, 1, 2, 4, 4, 3, 4, 2, 4, 0, 5, 2, 5, 1, 2, 1, 4, 0, 2, 2, 2, 0, 1, 2, 4, 0, 4, 2, 4, 2, 2, 2, 0, 4, 2, 4, 4, 0, 2, 1, 2, 0, 1, 4, 0, 2, 0, 2, 2, 4, 2, 3, 5, 2, 1, 1, 2, 4, 2, 2, 2, 3, 4, 3, 0, 4, 4, 1, 2, 2, 0, 4, 2, 1, 1, 3, 0, 0, 3, 4, 0, 4, 3, 2, 1, 2, 2, 4, 2, 2, 0, 2, 2, 2, 2, 0, 2, 0, 4, 4, 4, 2, 4, 0, 4, 3, 0, 2, 4, 2, 0, 1, 3, 0, 2, 2, 4, 1, 1, 4, 4, 5, 2, 4, 2, 3, 0, 4, 3, 4, 4, 5, 2, 4, 4, 4, 0, 4, 4, 2, 0, 4, 4, 1, 4, 2, 4, 2, 0, 2, 4, 4, 0, 4, 0, 3, 2, 1, 4, 1, 1, 4, 1, 3, 4, 5, 0, 0, 1, 1, 1, 1, 4, 2, 4, 1, 4, 0, 2, 4, 3, 2, 4, 4, 0, 4, 2, 2, 1, 0, 4, 4, 4, 4, 2, 4, 2, 2, 4, 2, 0, 2, 2, 4, 4, 4, 0, 1, 4, 4, 0, 2, 2, 2, 4, 4, 4, 1, 2, 2, 1, 2, 4, 2, 2, 2, 0, 5, 0, 2, 2, 3, 4, 2, 4, 3, 2, 4, 0, 3, 0, 4, 4, 4, 2, 2, 2, 1, 3, 2, 2, 3, 0, 2, 1, 4, 3, 2, 2, 2, 5, 4, 2, 4, 4, 2, 4, 2, 2, 1, 4, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 3, 0, 2, 3, 4, 2, 0, 4, 2, 5, 1, 3, 2, 2, 4, 0, 4, 2, 4, 2, 1, 1, 2, 2, 1, 0, 2, 2, 4, 4, 0, 4, 2, 2, 0, 4, 2, 2, 4, 2, 2, 4, 0, 2, 0, 0, 4, 1, 5, 1, 2, 4, 4, 2, 4, 4, 3, 1, 3, 1, 4, 2, 4, 2, 4, 3, 2, 4, 4, 0, 2, 0, 1, 4, 4, 4, 3, 2, 2, 4, 1, 4, 0, 4, 2, 3, 2, 2, 0, 2, 1, 4, 2, 2, 1, 0, 1, 2, 4, 4, 1, 4, 4, 2, 5, 1, 1, 2, 4, 2, 1, 4, 1, 4, 0, 2, 0, 2, 3, 3, 2, 2, 2, 4, 4, 3, 1, 2, 4, 0, 1, 2, 4, 2, 2, 4, 1, 4, 2, 4, 0, 1, 1, 1, 4, 3, 5, 0, 3, 0, 4, 4, 2, 2, 4, 3, 1, 1, 2, 1, 4, 1, 3, 4, 1, 4, 0, 0, 4, 4, 4, 1, 2, 0, 2, 1, 4, 2, 1, 3, 1, 4, 2, 1, 2, 5, 2, 2, 2, 4, 2, 2, 2, 4, 0, 0, 2, 5, 0, 2, 1, 3, 4, 0, 5, 4, 2, 0, 2, 0, 4, 2, 1, 4, 5, 2, 0, 4, 2, 0, 4, 4, 3, 0, 4, 0, 4, 1, 0, 4, 2, 3, 0, 1, 2, 3, 4, 0, 4, 2, 2, 4, 1, 3, 1, 2, 3, 3, 2, 3, 2, 2, 2, 4, 0, 4, 2, 4, 2, 1, 2, 4, 4, 4, 4, 3, 5, 2, 2, 4, 4, 0, 3, 2, 2, 4, 5, 1, 3, 2, 2, 1, 4, 2, 4, 0, 4, 4, 4, 2, 4, 1, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 0, 0, 4, 2, 2, 3, 0, 3, 0, 2, 4, 3, 4, 4, 4, 4, 0, 2, 2, 4, 2, 2, 1, 4, 2, 2, 4, 1, 3, 2, 2, 1, 4, 3, 1, 1, 1, 4, 3, 2, 2, 4, 3, 2, 1, 2, 2, 2, 2, 0, 1, 4, 4, 4, 0, 2, 2, 1, 2, 1, 0, 4, 4, 2, 1, 2, 2, 4, 2, 4, 4, 3, 2, 4, 4, 0, 2, 5, 4, 4, 4, 2, 4, 2, 2, 4, 4, 3, 2, 2, 2, 2, 3, 0, 2, 2, 1, 2, 4, 2, 2, 2, 4, 2, 4, 4, 1, 2, 2, 2, 0, 2, 1, 2, 0, 3, 4, 4, 2, 2, 0, 4, 2, 1, 2, 0, 0, 4, 4, 2, 4, 4, 0, 2, 0, 4, 4, 4, 4, 0, 2, 4, 4, 2, 2, 2, 4, 4, 5, 4, 4, 4, 0, 2, 2, 4, 4, 2, 4, 4, 4, 4, 1, 3, 0, 2, 5, 5, 1, 4, 0, 2, 4, 1, 4, 1, 5, 1, 4, 4, 0, 4, 4, 3, 0, 2, 2, 2, 1, 4, 4, 2, 4, 2, 2, 4, 1, 4, 2, 0, 4, 1, 1, 1, 2, 4, 2, 4, 4, 2, 4, 4, 2, 2, 1, 3, 2, 2, 4, 4, 0, 4, 2, 2, 2, 2, 1, 2, 4, 4, 5, 2, 3, 0, 1, 0, 0, 2, 4, 2, 5, 2, 2, 4, 4, 3, 2, 4, 3, 4, 1, 2, 4, 2, 2, 2, 2, 4, 4, 0, 2, 4, 4, 4, 3, 4, 3, 1, 4, 2, 0, 0, 1, 2, 3, 2, 1, 5, 4, 2, 1, 1, 0, 4, 4, 1, 2, 2, 4, 4, 0, 3, 2, 1, 3, 2, 0, 2, 0, 2, 4, 0, 1, 2, 4, 3, 3, 2, 4, 0, 2, 2, 4, 2, 0, 1, 0, 5, 0, 5, 4, 1, 3, 3, 0, 3, 3, 2, 4, 4, 3, 4, 4, 0, 5, 4, 2, 1, 5, 4, 0, 3, 4, 1, 4, 0, 2, 4, 4, 3, 4, 3, 2, 1, 3, 2, 3, 4, 4, 4, 1, 2, 1, 1, 3, 2, 4, 1, 4, 2, 1, 4, 4, 0, 2, 2, 2, 3, 3, 2, 4, 2, 2, 0, 2, 2, 4, 2, 3, 4, 2, 4, 2, 4, 0, 2, 2, 2, 4, 2, 4, 2, 2, 1, 4, 1, 4, 0, 4, 4, 1, 4, 1, 2, 4, 1, 0, 4, 5, 2, 0, 2, 0, 2, 5, 4, 2, 2, 1, 3, 3, 2, 4, 4, 2, 1, 2, 0, 4, 1, 0, 4, 0, 4, 2, 2, 0, 2, 1, 3, 4, 3, 2, 4, 0, 2, 4, 1, 2, 2, 0, 1, 2, 2, 0, 2, 2, 2, 0, 1, 0, 2, 2, 2, 2, 0, 5, 2, 2, 2, 4, 2, 0, 2, 2, 4, 0, 4, 2, 0, 2, 2, 4, 2, 2, 2, 2, 2, 0, 1, 1, 1, 4, 4, 3, 3, 1, 1, 4, 2, 2, 2, 1, 4, 0, 0, 4, 0, 4, 4, 2, 4, 4, 1, 4, 0, 3, 4, 4, 2, 3, 4, 4, 0, 4, 2, 2, 4, 2, 2, 3, 0, 2, 4, 4, 3, 1, 5, 4, 0, 2, 4, 4, 0, 3, 0, 4, 2, 3, 4, 4, 2, 2, 1, 4, 2, 2, 0, 1, 1, 2, 2, 2, 4, 5, 1, 0, 0, 0, 4, 4, 2, 4, 4, 4, 4, 4, 5, 4, 0, 0, 4, 2, 2, 2, 5, 1, 2, 0, 2, 0, 3, 2, 4, 4, 2, 4, 4, 3, 1, 4, 2, 2, 4, 2, 4, 2, 3, 1, 2, 1, 4, 2, 2, 3, 3, 4, 2, 2, 4, 4, 2, 0, 2, 1, 0, 2, 1, 0, 2, 2, 1, 1, 4, 0, 0, 4, 3, 1, 2, 0, 2, 1, 2, 1, 1, 4, 2, 2, 2, 2, 0, 4, 2, 4, 0, 2, 0, 2, 2, 2, 2, 0, 2, 1, 2, 2, 0, 4, 4, 3, 0, 4, 2, 2, 2, 4, 5, 1, 2, 4, 4, 4, 2, 5, 4, 2, 4, 5, 4, 2, 0, 2, 5, 2, 2, 2, 0, 2, 4, 2, 5, 5, 2, 2, 4, 2, 4, 1, 1, 4, 2, 4, 4, 1, 4, 2, 2, 2, 2, 2, 2, 5, 1, 3, 1, 4, 2, 4, 1, 4, 0, 4, 4, 4, 4, 4, 2, 3, 2, 2, 4, 1, 2, 2, 3, 3, 4, 2, 5, 3, 4, 2, 2, 4, 0, 2, 0, 2, 2, 1, 1, 4, 4, 1, 2, 0, 4, 4, 2, 1, 4, 2, 2, 4, 3, 3, 2, 2, 5, 0, 5, 2, 2, 5, 4, 5, 4, 4, 1, 4, 3, 4, 2, 2, 4, 0, 4, 1, 1, 2, 0, 2, 2, 4, 2, 3, 2, 3, 0, 2, 1, 4, 2, 2, 3, 4, 2, 4, 1, 2, 2, 2, 4, 0, 4, 1, 2, 3, 0, 4, 4, 2, 4, 4, 1, 0, 4, 2, 2, 2, 3, 0, 2, 1, 0, 1, 2, 2, 2, 0, 4, 4, 4, 1, 2, 1, 2, 4, 2, 3, 2, 2, 2, 2, 2, 2, 2, 4, 0, 4, 3, 4, 3, 4, 2, 4, 1, 2, 0, 2, 1, 0, 4, 4, 4, 4, 2, 2, 2, 4, 2, 2, 0, 4, 2, 2, 1, 0, 4, 4, 4, 4, 4, 0, 2, 4, 2, 4, 4, 4, 4, 2, 2, 1, 4, 3, 0, 0, 2, 4, 4, 2, 0, 3, 2, 1, 2, 0, 2, 2, 2, 4, 4, 4, 0, 2, 3, 2, 2, 0, 5, 2, 4, 2, 2, 1, 5, 4, 4, 2, 0, 1, 2, 2, 4, 2, 5, 4, 5, 3, 3, 2, 4, 1, 4, 5, 4, 2, 5, 4, 3, 2, 2, 2, 2, 2, 2, 4, 3, 2, 4, 5, 1, 0, 4, 2, 2, 4, 0, 3, 4, 4, 1, 2, 2, 0, 1, 4, 4, 4, 3, 4, 2, 1, 2, 2, 4, 4, 2, 3, 4, 2, 4, 4, 0, 1, 4, 1, 1, 2, 1, 4, 0, 2, 2, 4, 2, 2, 1, 0, 4, 0, 3, 4, 1, 1, 1, 2, 3, 1, 0, 2, 0, 2, 3, 4, 2, 1, 1, 2, 2, 4, 2, 2, 1, 0, 4, 0, 1, 2, 4, 3, 2, 4, 2, 3, 4, 2, 2, 4, 0, 3, 2, 0, 4, 2, 4, 2, 4, 2, 4, 5, 0, 2, 2, 2, 0, 4, 3, 4, 1, 2, 4, 2, 1, 2, 2, 1, 1, 0, 4, 2, 0, 2, 4, 4, 4, 2, 2, 2, 3, 2, 1, 2, 4, 3, 2, 1, 4, 2, 4, 1, 3, 0, 4, 2, 2, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 1, 4, 4, 2, 0, 4, 5, 3, 4, 1, 5, 4, 0, 2, 1, 0, 4, 0, 2, 1, 2, 2, 3, 2, 4, 4, 2, 2, 1, 2, 2, 4, 0, 0, 0, 2, 3, 4, 1, 5, 4, 0, 2, 2, 4, 2, 4, 2, 2, 2, 1, 0, 2, 2, 2, 5, 1, 1, 4, 2, 3, 3, 2, 1, 4, 4, 4, 4, 2, 4, 2, 4, 0, 4, 3, 2, 3, 1, 4, 4, 2, 2, 3, 4, 2, 3, 1, 2, 4, 2, 2, 2, 1, 4, 2, 4, 2, 2, 1, 4, 3, 4, 2, 1, 3, 4, 4, 4, 3, 3, 0, 2, 1, 2, 2, 0, 2, 5, 4, 2, 3, 1, 4, 0, 0, 4, 4, 2, 4, 4, 3, 4, 4, 2, 4, 2, 1, 2, 2, 0, 2, 4, 2, 0, 5, 4, 2, 0, 2, 4, 1, 4, 4, 0, 4, 0, 2, 2, 2, 0, 1, 1, 4, 2, 0, 2, 3, 4, 4, 2, 2, 0, 4, 4, 2, 4, 4, 2, 4, 4, 2, 4, 4, 1, 4, 2, 4, 3, 2, 5, 0, 4, 2, 4, 5, 0, 1, 0, 4, 3, 4, 0, 2, 2, 1, 3, 1, 5, 4, 1, 4, 2, 4, 2, 2, 5, 0, 4, 0, 2, 0, 4, 4, 2, 4, 5, 3, 0, 4, 1, 2, 2, 4, 4, 4, 2, 2, 4, 4, 1, 1, 1, 4, 0, 0, 4, 0, 4, 4, 4, 4, 2, 4, 5, 2, 0, 3, 4, 0, 0, 2, 2, 0, 2, 4, 0, 4, 0, 4, 0, 2, 5, 5, 4, 4, 1, 0, 1, 2, 2, 2, 2, 2, 5, 2, 0, 4, 2, 1, 2, 2, 2, 4, 1, 4, 4, 2, 2, 0, 4, 2, 2, 0, 2, 4, 2, 4, 2, 3, 0, 3, 4, 3, 0, 0, 0, 1, 1, 3, 2, 0, 2, 4, 2, 4, 0, 3, 4, 4, 4, 2, 3, 0, 5, 5, 3, 4, 0, 4, 2, 4, 4, 4, 4, 3, 2, 4, 0, 2, 2, 4, 4, 2, 0, 1, 4, 3, 3, 0, 2, 4, 5, 5, 0, 2, 2, 5, 2, 3, 0, 2, 4, 0, 2, 2, 3, 2, 4, 2, 2, 3, 2, 4, 0, 1, 2, 2, 2, 0, 5, 1, 0, 1, 1, 0, 2, 0, 2, 2, 2, 4, 0, 1, 2, 2, 2, 4, 2, 2, 1, 4, 2, 2, 0, 5, 2, 0, 5, 4, 5, 4, 4, 2, 4, 2, 5, 1, 4, 2, 5, 4, 4, 2, 2, 2, 2, 2, 0, 2, 2, 3, 4, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 4, 4, 4, 2, 4, 3, 2, 3, 4, 3, 5, 0, 3, 1, 4, 2, 4, 1, 1, 1, 4, 4, 4, 1, 4, 4, 5, 3, 2, 1, 0, 2, 4, 2, 2, 1, 0, 0, 3, 2, 4, 4, 4, 5, 2, 2, 2, 0, 0, 2, 0, 2, 1, 4, 4, 4, 4, 1, 4, 4, 1, 1, 0, 4, 4, 2, 4, 2, 1, 2, 4, 4, 1, 4, 2, 3, 4, 4, 2, 2, 2, 0, 2, 4, 4, 2, 1, 5, 2, 4, 4, 4, 4, 2, 1, 2, 0, 4, 4, 2, 2, 4, 0, 1, 2, 0, 1, 0, 2, 2, 2, 2, 4, 0, 4, 4, 2, 0, 0, 0, 0, 2, 2, 0, 2, 1, 2, 0, 2, 4, 2, 4, 5, 1, 2, 5, 1, 4, 3, 2, 2, 1, 3, 2, 5, 5, 2, 4, 2, 4, 4, 0, 4, 2, 2, 4, 5, 2, 3, 0, 2, 0, 2, 4, 2, 4, 2, 2, 0, 4, 3, 4, 0, 2, 2, 4, 4, 4, 4, 1, 4, 4, 2, 2, 1, 4, 2, 5, 3, 4, 3, 5, 4, 4, 2, 1, 2, 2, 2, 3, 4, 4, 5, 1, 2, 4, 2, 1, 2, 4, 2, 4, 3, 1, 1, 4, 2, 0, 0, 4, 0, 2, 2, 2, 2, 4, 2, 1, 4, 0, 0, 4, 1, 4, 2, 2, 2, 2, 2, 1, 2, 1, 5, 5, 4, 4, 2, 2, 4, 1, 3, 2, 4, 5, 1, 2, 4, 4, 4, 2, 2, 4, 3, 3, 3, 2, 5, 3, 2, 2, 4, 5, 2, 4, 2, 2, 4, 2, 0, 2, 4, 4, 1, 4, 1, 2, 2, 1, 4, 4, 0, 0, 4, 4, 2, 1, 4, 2, 4, 4, 3, 0, 1, 4, 2, 2, 2, 2, 2, 2, 4, 4, 0, 2, 4, 4, 2, 0, 5, 5, 4, 2, 2, 4, 1, 4, 0, 2, 2, 4, 4, 5, 3, 2, 3, 2, 2, 4, 0, 3, 4, 0, 4, 1, 4, 0, 2, 3, 2, 4, 2, 5, 2, 2, 2, 1, 2, 4, 4, 5, 3, 0, 4, 4, 4, 1, 0, 4, 1, 0, 1, 4, 0, 4, 2, 5, 4, 2, 2, 3, 4, 4, 0, 0, 3, 4, 4, 2, 3, 2, 2, 2, 2, 4, 4, 2, 2, 2, 1, 0, 1, 2, 2, 2, 4, 4, 5, 4, 4, 2, 3, 0, 3, 2, 4, 1, 0, 0, 4, 1, 2, 2, 4, 2, 2, 0, 5, 4, 2, 4, 4, 4, 2, 2, 1, 4, 4, 4, 2, 1, 2, 2, 1, 2, 4, 4, 1, 2, 2, 4, 2, 4, 2, 4, 1, 4, 4, 3, 4, 2, 1, 0, 1, 1, 2, 3, 2, 5, 2, 2, 3, 4, 4, 1, 2, 2, 2, 0, 0, 4, 0, 2, 2, 3, 1, 2, 4, 3, 3, 4, 1, 2, 2, 5, 4, 2, 3, 3, 2, 3, 2, 4, 0, 2, 1, 2, 0, 5, 2, 1, 4, 4, 0, 4, 1, 3, 4, 2, 4, 5, 2, 4, 4, 3, 4, 0, 3, 4, 2, 2, 2, 1, 2, 2, 2, 2, 0, 2, 1, 0, 4, 4, 0, 0, 4, 3, 2, 2, 0, 2, 4, 2, 0, 4, 3, 0, 2, 2, 2, 0, 4, 2, 4, 4, 4, 4, 4, 2, 5, 1, 1, 0, 2, 4, 0, 4, 5, 2, 2, 3, 1, 0, 4, 3, 4, 4, 5, 2, 2, 2, 2, 4, 4, 2, 1, 0, 0, 1, 2, 5, 4, 1, 2, 2, 1, 2, 2, 4, 1, 0, 0, 2, 4, 4, 5, 2, 0, 2, 3, 2, 1, 0, 1, 1, 2, 4, 4, 0, 2, 1, 1, 0, 1, 1, 2, 2, 0, 5, 3, 4, 4, 2, 2, 2, 4, 1, 3, 0, 2, 5, 2, 1, 3, 1, 0, 4, 2, 4, 2, 4, 5, 3, 2, 0, 0, 1, 0, 4, 2, 0, 2, 2, 0, 1, 2, 4, 5, 2, 2, 4, 2, 4, 4, 4, 0, 0, 0, 2, 4, 4, 2, 4, 1, 2, 0, 1, 2, 5, 4, 0, 4, 2, 1, 4, 1, 0, 4, 2, 1, 2, 2, 1, 3, 4, 4, 1, 1, 2, 2, 2, 0, 4, 2, 3, 4, 4, 0, 4, 4, 3, 3, 4, 0, 2, 0, 0, 0, 2, 3, 4, 3, 2, 3, 2, 3, 3, 4, 3, 2, 4, 3, 2, 4, 3, 2, 4, 1, 2, 4, 1, 2, 2, 0, 1, 4, 2, 2, 1, 1, 3, 4, 2, 2, 1, 4, 2, 0, 2, 0, 0, 4, 0, 4, 1, 1, 5, 1, 2, 0, 5, 4, 4, 4, 2, 3, 3, 0, 2, 4, 0, 4, 0, 2, 1, 4, 4, 0, 2, 2, 3, 2, 0, 1, 0, 4, 4, 4, 4, 2, 3, 2, 3, 4, 2, 2, 3, 4, 4, 4, 2, 4, 4, 4, 3, 4, 4, 4, 2, 4, 0, 0, 2, 4, 2, 2, 4, 1, 2, 1, 4, 3, 4, 4, 2, 5, 4, 2, 1, 4, 1, 2, 2, 2, 1, 0, 4, 4, 2, 2, 0, 2, 2, 1, 2, 2, 2, 4, 4, 4, 0, 2, 0, 2, 4, 1, 0, 3, 1, 0, 2, 5, 0, 1, 0, 4, 4, 4, 2, 3, 4, 2, 2, 3, 4, 4, 0, 2, 4, 4, 4, 2, 3, 2, 2, 3, 2, 4, 2, 1, 4, 2, 1, 0, 2, 4, 0, 1, 2, 5, 4, 1, 1, 1, 4, 4, 2, 2, 4, 4, 1, 4, 2, 4, 2, 2, 2, 3, 5, 2, 4, 4, 3, 4, 2, 2, 2, 2, 0, 2, 4, 2, 4, 1, 5, 4, 2, 2, 1, 4, 0, 2, 2, 2, 3, 5, 2, 2, 3, 2, 3, 3, 4, 4, 3, 5, 0, 4, 4, 4, 2, 0, 2, 2, 2, 0, 4, 2, 4, 2, 1, 2, 2, 1, 1, 4, 2, 0, 0, 2, 3, 2, 4, 0, 2, 5, 4, 1, 2, 2, 2, 4, 3, 4, 2, 1, 5, 4, 2, 0, 2, 1, 2, 4, 0, 3, 1, 2, 0, 5, 2, 2, 1, 1, 4, 2, 4, 2, 2, 0, 2, 2, 4, 2, 2, 3, 4, 3, 2, 4, 4, 3, 2, 1, 2, 2, 4, 0, 2, 4, 2, 4, 4, 2, 2, 4, 0, 2, 4, 4, 1, 1, 3, 2, 2, 2, 1, 4, 3, 1, 3, 2, 2, 4, 4, 5, 2, 4, 0, 4, 5, 4, 2, 1, 3, 4, 0, 2, 2, 4, 3, 3, 4, 1, 1, 2, 4, 4, 1, 2, 4, 4, 0, 4, 4, 0, 2, 1, 4, 0, 4, 4, 3, 2, 2, 3, 4, 0, 4, 2, 0, 4, 1, 2, 0, 4, 2, 1, 4, 2, 1, 4, 2, 2, 0, 4, 0, 1, 0, 4, 5, 0, 1, 1, 2, 0, 2, 2, 4, 1, 2, 2, 2, 4, 0, 1, 2, 0, 2, 4, 3, 1, 1, 1, 0, 0, 4, 0, 1, 2, 2, 4, 3, 4, 2, 2, 2, 1, 3, 4, 1, 4, 1, 4, 4, 2, 1, 2, 0, 2, 4, 2, 2, 2, 5, 4, 5, 1, 4, 4, 3, 4, 3, 1, 3, 2, 2, 0, 2, 2, 0, 4, 1, 0, 4, 4, 0, 0, 4, 4, 0, 3, 2, 4, 2, 0, 3, 4, 0, 1, 2, 4, 2, 0, 2, 2, 1, 4, 2, 4, 2, 1, 4, 4, 2, 5, 2, 0, 5, 5, 2, 2, 4, 4, 0, 1, 2, 4, 3, 1, 4, 4, 2, 3, 1, 0, 2, 1, 4, 1, 5, 4, 4, 2, 4, 1, 0, 3, 4, 1, 2, 2, 3, 4, 0, 1, 4, 4, 1, 2, 4, 4, 1, 2, 4, 4, 2, 4, 4, 0, 4, 2, 0, 1, 4, 2, 4, 2, 2, 1, 0, 2, 5, 0, 4, 2, 1, 4, 3, 3, 4, 5, 2, 1, 3, 0, 5, 4, 0, 0, 2, 2, 1, 2, 2, 0, 4, 4, 2, 0, 4, 2, 4, 3, 0, 1, 4, 2, 1, 0, 2, 2, 2, 4, 2, 2, 2, 2, 0, 2, 4, 2, 4, 2, 4, 4, 4, 4, 1, 0, 2, 2, 0, 3, 4, 1, 2, 2, 2, 1, 4, 4, 3, 4, 4, 1, 4, 2, 0, 1, 2, 4, 4, 0, 2, 2, 1, 4, 1, 1, 4, 0, 2, 0, 1, 1, 2, 2, 2, 1, 4, 2, 2, 0, 4, 2, 4, 5, 0, 2, 1, 0, 4, 0, 1, 4, 3, 1, 4, 3, 3, 1, 0, 2, 2, 4, 2, 3, 4, 3, 5, 4, 0, 3, 2, 4, 1, 5, 2, 4, 3, 2, 4, 4, 2, 2, 1, 0, 2, 4, 2, 4, 3, 2, 1, 4, 2, 4, 4, 5, 5, 4, 4, 2, 2, 0, 4, 4, 0, 4, 1, 1, 2, 2, 4, 2, 4, 0, 4, 3, 4, 2, 4, 0, 2, 2, 0, 2, 2, 0, 2, 3, 0, 2, 0, 4, 1, 4, 3, 4, 1, 0, 0, 0, 4, 2, 4, 2, 2, 5, 4, 3, 4, 2, 1, 3, 2, 0, 5, 2, 5, 0, 2, 4, 0, 2, 3, 0, 2, 0, 4, 3, 4, 2, 4, 4, 4, 0, 4, 4, 2, 2, 2, 3, 4, 1, 4, 1, 4, 2, 2, 4, 4, 2, 4, 1, 4, 2, 1, 1, 4, 2, 4, 4, 4, 0, 2, 2, 0, 4, 4, 4, 0, 4, 2, 4, 2, 4, 3, 0, 4, 5, 4, 2, 2, 0, 0, 4, 1, 1, 4, 4, 2, 3, 0, 2, 2, 2, 3, 3, 4, 0, 1, 2, 5, 1, 2, 4, 2, 0, 0, 4, 0, 4, 1, 4, 4, 4, 3, 5, 2, 0, 2, 2, 3, 0, 2, 4, 4, 1, 2, 1, 0, 2, 0, 0, 0, 2, 3, 2, 2, 0, 0, 4, 1, 2, 1, 4, 2, 0, 2, 1, 0, 2, 4, 0, 2, 0, 2, 4, 3, 2, 2, 0, 4, 3, 2, 0, 2, 4, 2, 1, 0, 2, 4, 2, 4, 2, 4, 5, 2, 0, 4, 1, 2, 0, 2, 2, 2, 4, 2, 4, 0, 4, 4, 2, 0, 4, 4, 2, 2, 1, 2, 5, 0, 0, 2, 2, 1, 1, 2, 2, 1, 0, 0, 2, 4, 1, 2, 3, 1, 4, 1, 1, 5, 4, 2, 1, 2, 4, 4, 2, 1, 0, 4, 0, 2, 2, 2, 4, 2, 2, 2, 0, 3, 3, 4, 3, 0, 4, 0, 4, 0, 2, 4, 2, 1, 1, 1, 3, 4, 0, 4, 1, 4, 1, 4, 3, 2, 2, 5, 2, 1, 3, 2, 2, 4, 1, 2, 3, 1, 0, 2, 0, 2, 2, 4, 2, 3, 4, 0, 2, 1, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 3, 5, 2, 2, 1, 2, 3, 4, 3, 4, 1, 4, 2, 4, 4, 2, 4, 4, 2, 5, 2, 2, 0, 0, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 4, 4, 2, 4, 4, 2, 1, 4, 4, 4, 2, 0, 4, 1, 0, 4, 2, 4, 4, 2, 2, 2, 2, 4, 4, 3, 3, 4, 2, 3, 0, 5, 2, 4, 4, 1, 4, 4, 1, 4, 0, 2, 0, 2, 5, 4, 4, 4, 1, 0, 2, 0, 0, 2, 4, 2, 4, 2, 0, 4, 1, 0, 3, 4, 2, 0, 1, 2, 4, 3, 2, 3, 4, 2, 0, 0, 4, 1, 4, 1, 0, 2, 5, 0, 1, 1, 2, 0, 2, 2, 1, 5, 1, 2, 2, 0, 2, 2, 3, 4, 4, 0, 2, 4, 4, 3, 3, 1, 4, 4, 2, 2, 2, 0, 4, 2, 0, 2, 2, 4, 0, 4, 2, 2, 0, 2, 2, 0, 4, 0, 4, 1, 4, 2, 3, 4, 0, 4, 2, 3, 2, 2, 2, 2, 0, 4, 2, 4, 3, 2, 2, 0, 2, 2, 2, 2, 0, 1, 4, 4, 4, 3, 3, 0, 4, 1, 0, 2, 3, 4, 0, 3, 4, 0, 1, 4, 1, 2, 2, 5, 2, 2, 3, 4, 4, 1, 3, 2, 5, 4, 5, 2, 4, 2, 0, 4, 2, 0, 4, 0, 5, 4, 4, 0, 2, 4, 1, 0, 1, 2, 4, 2, 5, 3, 4, 3, 2, 5, 2, 0, 2, 0, 5, 4, 2, 2, 2, 1, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 5, 2, 2, 5, 1, 2, 2, 1, 2, 2, 5, 4, 4, 3, 2, 0, 0, 1, 2, 4, 4, 3, 2, 4, 2, 2, 5, 2, 4, 4, 2, 4, 4, 4, 4, 0, 3, 4, 2, 2, 2, 2, 0, 3, 4, 1, 3, 3, 2, 2, 2, 2, 0, 4, 2, 0, 4, 1, 0, 2, 1, 4, 2, 2, 2, 4, 2, 2, 2, 4, 2, 1, 2, 4, 1, 1, 3, 1, 3, 2, 3, 1, 0, 4, 4, 0, 1, 2, 2, 4, 4, 5, 2, 1, 4, 0, 2, 0, 0, 4, 4, 4, 2, 1, 4, 4, 4, 4, 2, 2, 2, 4, 0, 0, 2, 2, 4, 2, 0, 4, 1, 3, 4, 0, 2, 5, 2, 2, 2, 2, 3, 3, 4, 2, 2, 3, 4, 2, 4, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 3, 3, 4, 4, 1, 4, 0, 2, 4, 0, 2, 4, 2, 4, 2, 4, 4, 0, 0, 0, 4, 1, 4, 0, 4, 1, 1, 4, 1, 4, 2, 4, 2, 2, 2, 1, 3, 2, 2, 1, 4, 2, 4, 1, 4, 4, 0, 1, 2, 2, 2, 3, 0, 1, 4, 2, 1, 2, 3, 3, 4, 3, 0, 4, 4, 4, 5, 2, 0, 2, 4, 1, 0, 2, 5, 2, 2, 2, 2, 4, 2, 4, 4, 3, 4, 3, 4, 4, 2, 2, 0, 0, 4, 1, 0, 2, 4, 2, 0, 3, 2, 1, 2, 2, 2, 0, 0, 1, 5, 2, 0, 0, 2, 1, 4, 1, 3, 4, 3, 2, 2, 1, 4, 0, 2, 4, 1, 2, 4, 2, 1, 2, 0, 2, 2, 2, 5, 2, 0, 4, 1, 4, 4, 2, 2, 4, 0, 4, 2, 5, 2, 2, 4, 2, 2, 2, 4, 2, 4, 4, 0, 0, 0, 0, 0, 4, 0, 4, 2, 0, 3, 0, 2, 2, 3, 3, 3, 4, 4, 4, 3, 2, 4, 0, 2, 3, 2, 2, 3, 3, 2, 4, 1, 2, 4, 2, 0, 4, 2, 2, 0, 1, 1, 0, 3, 4, 1, 1, 2, 4, 3, 4, 2, 2, 4, 0, 4, 2, 3, 4, 2, 2, 0, 4, 0, 2, 2, 2, 2, 3, 4, 2, 1, 2, 4, 3, 4, 4, 2, 4, 2, 2, 4, 1, 2, 1, 4, 4, 4, 2, 4, 1, 5, 4, 2, 4, 0, 4, 3, 4, 2, 2, 4, 0, 4, 3, 4, 2, 4, 2, 0, 4, 2, 2, 4, 4, 0, 2, 5, 1, 4, 0, 4, 2, 4, 0, 0, 5, 0, 2, 0, 4, 3, 2, 4, 2, 1, 4, 2, 0, 0, 4, 2, 0, 2, 4, 2, 2, 2, 3, 2, 3, 2, 2, 2, 0, 2, 2, 0, 2, 0, 2, 2, 2, 2, 0, 4, 2, 4, 4, 2, 4, 2, 4, 1, 2, 1, 4, 4, 1, 5, 0, 5, 4, 2, 0, 2, 5, 4, 0, 4, 3, 4, 4, 0, 2, 4, 4, 4, 1, 0, 2, 5, 2, 5, 2, 0, 3, 4, 0, 1, 2, 3, 4, 2, 2, 2, 2, 0, 4, 0, 2, 2, 0, 4, 4, 0, 2, 4, 0, 0, 2, 4, 4, 4, 2, 1, 0, 4, 3, 2, 5, 1, 1, 4, 3, 2, 4, 1, 3, 2, 1, 2, 4, 1, 2, 2, 1, 2, 2, 2, 4, 4, 4, 2, 1, 0, 4, 4, 3, 4, 5, 5, 3, 2, 3, 4, 4, 0, 2, 2, 4, 1, 2, 4, 2, 4, 1, 0, 1, 1, 2, 4, 2, 0, 0, 2, 2, 3, 2, 2, 2, 2, 1, 2, 4, 4, 2, 2, 3, 2, 2, 4, 0, 2, 2, 4, 2, 2, 2, 2, 5, 4, 2, 3, 0, 2, 2, 3, 3, 4, 2, 2, 4, 5, 4, 2, 4, 3, 0, 1, 4, 0, 2, 3, 4, 4, 4, 1, 4, 4, 3, 4, 2, 2, 1, 2, 4, 2, 4, 2, 2, 1, 4, 4, 4, 4, 0, 4, 2, 5, 1, 4, 0, 3, 0, 4, 1, 5, 4, 2, 1, 2, 4, 4, 3, 0, 2, 2, 0, 5, 3, 2, 2, 2, 2, 1, 2, 2, 4, 2, 3, 4, 3, 4, 1, 1, 2, 4, 4, 5, 4, 0, 4, 4, 2, 3, 1, 4, 4, 4, 0, 2, 0, 1, 4, 4, 1, 4, 0, 4, 4, 0, 3, 1, 3, 5, 4, 0, 2, 2, 4, 3, 4, 4, 0, 2, 4, 2, 2, 3, 0, 2, 4, 3, 0, 4, 4, 4, 2, 2, 2, 2, 0, 2, 4, 0, 2, 4, 4, 4, 0, 3, 1, 1, 1, 4, 4, 4, 1, 4, 2, 4, 5, 3, 4, 4, 0, 3, 5, 4, 1, 0, 4, 2, 2, 2, 2, 0, 3, 3, 2, 2, 2, 0, 1, 4, 4, 4, 1, 2, 5, 2, 2, 2, 2, 4, 4, 4, 1, 4, 2, 2, 2, 4, 4, 2, 2, 4, 3, 2, 4, 3, 2, 2, 1, 4, 3, 0, 2, 3, 0, 2, 3, 0, 0, 3, 4, 0, 3, 4, 2, 2, 3, 4, 1, 2, 4, 2, 2, 4, 4, 2, 5, 4, 3, 2, 5, 4, 1, 5, 4, 2, 3, 4, 2, 3, 2, 2, 0, 2, 2, 4, 2, 4, 0, 2, 2, 0, 2, 2, 2, 2, 2, 1, 3, 2, 2, 0, 2, 2, 4, 4, 2, 5, 1, 4, 1, 4, 4, 1, 4, 3, 1, 2, 2, 2, 4, 0, 0, 4, 2, 1, 4, 2, 4, 2, 4, 0, 1, 2, 4, 0, 1, 4, 2, 2, 4, 4, 4, 0, 0, 1, 4, 2, 2, 2, 0, 0, 3, 1, 0, 4, 2, 5, 2, 1, 2, 2, 2, 4, 2, 2, 2, 4, 4, 1, 4, 2, 2, 4, 2, 2, 3, 2, 0, 0, 1, 2, 4, 1, 2, 2, 0, 4, 3, 2, 2, 3, 2, 4, 2, 2, 2, 4, 2, 5, 2, 4, 3, 4, 4, 0, 4, 2, 3, 3, 2, 2, 2, 4, 2, 2, 0, 4, 2, 0, 4, 2, 1, 0, 2, 3, 3, 2, 3, 2, 2, 2, 2, 0, 2, 1, 0, 1, 2, 0, 1, 4, 2, 4, 1, 4, 4, 2, 2, 2, 2, 2, 4, 0, 2, 2, 5, 4, 4, 2, 2, 4, 4, 2, 2, 0, 2, 2, 4, 4, 4, 1, 1, 4, 5, 2, 2, 2, 1, 2, 4, 2, 2, 4, 4, 1, 0, 4, 2, 1, 0, 2, 2, 4, 2, 3, 4, 1, 0, 1, 3, 2, 0, 4, 2, 5, 0, 4, 0, 2, 4, 2, 4, 1, 4, 2, 4, 2, 5, 4, 0, 4, 2, 2, 2, 2, 2, 2, 4, 2, 1, 3, 2, 4, 2, 4, 2, 2, 2, 1, 4, 0, 1, 0, 2, 0, 4, 3, 4, 4, 1, 2, 2, 4, 2, 5, 0, 2, 4, 4, 3, 4, 4, 2, 4, 2, 0, 4, 1, 4, 4, 0, 0, 2, 1, 2, 4, 1, 1, 2, 4, 0, 0, 4, 3, 0, 0, 4, 4, 2, 5, 0, 4, 5, 1, 0, 0, 0, 4, 4, 0, 3, 4, 1, 4, 2, 1, 4, 2, 0, 2, 3, 2, 2, 4, 2, 1, 4, 4, 4, 2, 2, 2, 2, 2, 1, 4, 1, 4, 3, 0, 2, 2, 0, 2, 0, 2, 4, 4, 4, 5, 1, 3, 4, 2, 3, 5, 4, 1, 2, 3, 4, 0, 4, 2, 4, 4, 2, 1, 4, 4, 3, 2, 2, 2, 2, 4, 3, 1, 3, 4, 1, 4, 4, 4, 0, 4, 1, 2, 4, 4, 2, 2, 4, 2, 1, 4, 2, 4, 4, 3, 4, 2, 2, 0, 4, 4, 2, 2, 1, 4, 2, 2, 2, 1, 4, 4, 4, 2, 2, 1, 4, 2, 1, 0, 2, 2, 2, 4, 5, 0, 2, 2, 4, 1, 3, 2, 1, 2, 0, 4, 4, 2, 1, 1, 0, 4, 1, 4, 4, 1, 1, 2, 3, 0, 1, 2, 2, 1, 3, 3, 4, 2, 5, 2, 4, 0, 3, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 0, 4, 1, 0, 4, 0, 3, 1, 2, 4, 2, 4, 3, 2, 0, 3, 1, 0, 2, 1, 4, 3, 4, 4, 4, 2, 4, 2, 2, 0, 2, 0, 2, 0, 4, 0, 1, 5, 2, 2, 2, 0, 2, 2, 1, 5, 4, 1, 2, 2, 0, 1, 2, 3, 4, 2, 1, 2, 5, 2, 4, 2, 5, 0, 4, 0, 4, 2, 2, 2, 2, 2, 3, 3, 0, 2, 3, 3, 3, 1, 4, 4, 2, 4, 4, 2, 4, 2, 4, 0, 2, 4, 2, 2, 4, 2, 2, 0, 3, 2, 2, 2, 1, 4, 0, 0, 4, 2, 4, 2, 2, 4, 2, 0, 4, 4, 4, 2, 3, 0, 2, 2, 2, 2, 4, 1, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 0, 1, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 3, 3, 4, 4, 2, 3, 1, 2, 2, 4, 2, 4, 2, 2, 2, 2, 0, 2, 4, 2, 4, 2, 4, 0, 2, 2, 4, 3, 1, 1, 1, 4, 1, 2, 4, 2, 3, 1, 3, 1, 0, 4, 2, 3, 4, 4, 2, 0, 5, 4, 4, 0, 2, 2, 1, 2, 4, 2, 2, 4, 2, 0, 4, 2, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 4, 3, 4, 2, 4, 2, 3, 4, 3, 3, 4, 4, 3, 4, 1, 0, 2, 2, 0, 0, 2, 2, 0, 2, 4, 2, 2, 3, 2, 3, 5, 4, 4, 2, 4, 2, 4, 0, 2, 1, 2, 1, 1, 1, 2, 4, 0, 4, 5, 4, 4, 2, 2, 4, 4, 2, 1, 4, 0, 3, 0, 0, 0, 4, 2, 4, 5, 0, 4, 4, 4, 4, 4, 3, 4, 0, 2, 2, 4, 2, 3, 2, 0, 3, 2, 2, 2, 5, 2, 2, 4, 2, 1, 2, 5, 2, 2, 1, 2, 0, 1, 4, 0, 4, 3, 2, 0, 2, 0, 1, 3, 4, 4, 3, 1, 4, 4, 0, 4, 0, 2, 2, 4, 2, 4, 0, 2, 4, 5, 0, 0, 2, 2, 4, 4, 4, 4, 2, 0, 4, 2, 4, 4, 1, 0, 0, 3, 4, 4, 4, 1, 2, 1, 2, 5, 2, 4, 4, 1, 4, 3, 4, 2, 4, 0, 4, 2, 0, 3, 2, 2, 4, 4, 2, 4, 0, 2, 4, 4, 4, 0, 3, 0, 0, 4, 2, 3, 4, 2, 1, 2, 2, 3, 4, 3, 2, 2, 0, 5, 2, 4, 1, 4, 4, 1, 1, 2, 4, 4, 4, 4, 4, 0, 1, 4, 1, 4, 2, 2, 4, 1, 1, 2, 0, 0, 1, 2, 2, 4, 2, 2, 4, 4, 3, 4, 2, 1, 0, 1, 0, 2, 1, 4, 0, 4, 4, 2, 4, 0, 2, 2, 4, 4, 4, 1, 2, 4, 2, 4, 4, 4, 4, 3, 1, 4, 5, 3, 1, 1, 2, 4, 2, 4, 0, 2, 5, 1, 1, 4, 2, 4, 4, 0, 4, 1, 1, 2, 2, 4, 0, 2, 1, 0, 2, 2, 2, 1, 2, 2, 2, 1, 4, 0, 2, 1, 4, 0, 2, 2, 4, 4, 3, 2, 0, 0, 4, 2, 1, 2, 2, 2, 2, 1, 4, 2, 3, 2, 2, 3, 4, 2, 1, 2, 4, 2, 0, 4, 4, 2, 2, 2, 2, 1, 4, 4, 2, 0, 4, 2, 2, 4, 2, 4, 4, 2, 2, 0, 2, 1, 4, 4, 3, 2, 0, 4, 0, 1, 1, 2, 4, 4, 4, 4, 2, 2, 0, 4, 1, 3, 5, 4, 1, 0, 1, 4, 3, 4, 4, 1, 2, 3, 4, 4, 3, 5, 4, 3, 2, 2, 3, 4, 3, 2, 2, 2, 4, 2, 2, 4, 4, 4, 2, 3, 2, 3, 2, 1, 2, 1, 2, 2, 2, 4, 4, 1, 2, 2, 4, 2, 2, 4, 2, 0, 1, 4, 4, 4, 4, 1, 2, 2, 3, 1, 2, 2, 4, 1, 5, 2, 4, 4, 4, 2, 4, 3, 3, 1, 2, 1, 0, 0, 1, 0, 0, 2, 4, 4, 3, 2, 2, 3, 2, 3, 4, 5, 2, 4, 2, 0, 4, 1, 4, 1, 2, 1, 2, 0, 1, 1, 4, 4, 2, 0, 0, 2, 2, 2, 4, 2, 1, 2, 4, 4, 4, 2, 3, 0, 2, 0, 2, 0, 2, 1, 2, 0, 0, 2, 1, 4, 2, 1, 4, 1, 2, 2, 2, 2, 2, 4, 0, 4, 2, 0, 0, 2, 2, 4, 4, 1, 2, 1, 2, 4, 4, 3, 2, 2, 1, 1, 4, 2, 1, 2, 4, 3, 0, 2, 4, 3, 3, 2, 2, 1, 1, 4, 2, 2, 4, 0, 1, 4, 1, 2, 5, 4, 4, 1, 4, 2, 4, 0, 4, 1, 2, 1, 4, 3, 4, 4, 2, 2, 2, 4, 2, 4, 5, 4, 0, 2, 4, 2, 2, 4, 0, 3, 0, 1, 2, 4, 2, 1, 3, 4, 2, 4, 4, 2, 1, 4, 3, 4, 4, 2, 3, 4, 3, 2, 1, 0, 1, 4, 1, 1, 4, 4, 1, 2, 2, 2, 0, 3, 1, 4, 2, 4, 0, 4, 2, 3, 2, 4, 2, 4, 4, 4, 4, 2, 0, 3, 4, 2, 4, 3, 2, 2, 2, 4, 1, 2, 4, 2, 2, 5, 2, 1, 1, 0, 1, 4, 4, 4, 1, 4, 0, 2, 0, 4, 4, 0, 1, 0, 1, 3, 0, 3, 2, 1, 0, 2, 3, 2, 4, 3, 2, 3, 1, 2, 1, 1, 4, 4, 2, 3, 4, 2, 4, 4, 3, 4, 4, 1, 2, 4, 2, 0, 2, 1, 4, 2, 2, 3, 5, 2, 0, 3, 0, 4, 2, 2, 2, 3, 4, 3, 2, 4, 2, 2, 0, 0, 2, 4, 1, 4, 2, 1, 2, 0, 4, 2, 2, 2, 1, 1, 4, 2, 4, 4, 2, 2, 4, 2, 1, 0, 2, 4, 1, 2, 4, 3, 0, 4, 2, 5, 2, 2, 1, 0, 1, 1, 0, 2, 0, 0, 5, 0, 1, 4, 2, 2, 2, 4, 3, 4, 2, 4, 2, 1, 4, 2, 1, 0, 2, 0, 4, 2, 0, 2, 4, 1, 2, 2, 4, 4, 0, 3, 4, 4, 2, 2, 0, 3, 0, 4, 4, 2, 4, 5, 5, 4, 1, 2, 2, 2, 1, 4, 2, 1, 4, 2, 1, 2, 2, 4, 1, 2, 0, 1, 4, 2, 0, 4, 2, 4, 4, 4, 4, 4, 3, 4, 0, 1, 4, 2, 4, 4, 3, 1, 0, 0, 2, 1, 2, 2, 4, 4, 4, 4, 4, 0, 1, 4, 3, 2, 4, 2, 2, 1, 1, 2, 4, 3, 4, 4, 3, 1, 0, 0, 2, 4, 4, 2, 0, 2, 4, 4, 4, 4, 1, 4, 0, 2, 2, 0, 0, 3, 2, 1, 2, 4, 4, 5, 2, 2, 2, 4, 2, 4, 0, 0, 2, 4, 4, 4, 2, 4, 3, 2, 5, 4, 4, 2, 0, 4, 4, 1, 1, 4, 4, 2, 2, 2, 3, 3, 3, 2, 1, 1, 2, 4, 0, 2, 2, 0, 0, 0, 4, 3, 2, 4, 5, 4, 4, 4, 4, 4, 0, 4, 0, 3, 0, 2, 0, 1, 1, 4, 1, 1, 2, 0, 2, 2, 4, 4, 2, 4, 4, 1, 4, 2, 2, 5, 4, 3, 4, 3, 2, 4, 2, 0, 2, 0, 1, 2, 3, 4, 4, 3, 4, 2, 2, 0, 2, 0, 3, 4, 0, 2, 4, 2, 4, 2, 0, 0, 4, 3, 2, 2, 4, 3, 3, 5, 2, 2, 2, 2, 2, 4, 2, 0, 1, 0, 3, 4, 2, 4, 2, 2, 2, 5, 2, 2, 5, 4, 4, 3, 0, 2, 3, 1, 3, 1, 2, 4, 0, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 4, 3, 4, 4, 0, 2, 2, 0, 2, 2, 2, 1, 4, 3, 4, 0, 4, 2, 2, 4, 4, 4, 4, 2, 0, 2, 2, 4, 4, 0, 0, 4, 2, 1, 4, 1, 2, 4, 0, 2, 2, 1, 2, 4, 4, 4, 2, 2, 4, 4, 1, 4, 2, 3, 4, 4, 4, 2, 1, 1, 4, 0, 0, 2, 2, 4, 1, 2, 0, 1, 0, 4, 2, 4, 2, 4, 0, 4, 2, 2, 2, 0, 4, 5, 4, 3, 2, 2, 1, 4, 3, 2, 2, 4, 3, 2, 1, 5, 2, 2, 2, 1, 2, 0, 4, 2, 4, 4, 4, 2, 2, 1, 1, 4, 4, 0, 2, 4, 2, 4, 5, 2, 0, 3, 1, 4, 3, 0, 2, 3, 4, 2, 2, 4, 3, 3, 3, 0, 4, 1, 4, 2, 1, 2, 3, 4, 4, 2, 2, 3, 0, 0, 1, 2, 2, 2, 0, 4, 2, 1, 1, 4, 1, 0, 3, 2, 4, 4, 1, 2, 2, 4, 2, 2, 2, 2, 3, 0, 2, 2, 4, 1, 1, 1, 2, 2, 2, 0, 2, 2, 1, 4, 4, 4, 4, 0, 4, 1, 4, 5, 4, 1, 0, 0, 1, 4, 1, 3, 3, 2, 5, 4, 2, 0, 0, 4, 0, 1, 1, 3, 5, 4, 2, 2, 2, 4, 4, 4, 1, 4, 2, 2, 1, 2, 1, 3, 5, 2, 0, 2, 3, 1, 1, 4, 5, 2, 1, 4, 2, 4, 2, 4, 3, 5, 0, 2, 2, 4, 4, 2, 0, 2, 2, 2, 2, 1, 2, 0, 3, 1, 4, 4, 2, 0, 5, 2, 0, 4, 2, 3, 2, 0, 4, 2, 2, 4, 1, 4, 0, 4, 3, 4, 2, 5, 4, 2, 1, 2, 2, 2, 4, 1, 1, 4, 4, 0, 0, 2, 2, 2, 2, 4, 2, 2, 0, 2, 2, 0, 2, 0, 2, 4, 1, 4, 2, 0, 3, 1, 2, 0, 1, 1, 2, 4, 4, 0, 2, 0, 2, 2, 2, 1, 4, 4, 4, 1, 2, 0, 4, 1, 4, 2, 4, 0, 0, 0, 2, 4, 4, 2, 4, 1, 4, 4, 4, 4, 4, 5, 2, 2, 4, 3, 2, 2, 2, 0, 0, 2, 2, 4, 2, 3, 2, 3, 4, 0, 1, 2, 4, 4, 5, 3, 2, 2, 2, 1, 4, 2, 4, 2, 5, 2, 1, 2, 2, 5, 4, 4, 4, 0, 4, 2, 4, 3, 0, 2, 4, 2, 2, 3, 4, 4, 2, 1, 3, 2, 4, 3, 2, 2, 1, 2, 2, 2, 0, 3, 4, 2, 2, 2, 4, 2, 4, 5, 4, 2, 2, 2, 3, 1, 4, 2, 4, 2, 4, 3, 2, 3, 4, 1, 0, 5, 2, 4, 1, 4, 4, 2, 4, 2, 2, 4, 2, 0, 4, 1, 2, 2, 2, 5, 4, 2, 1, 2, 4, 4, 4, 2, 0, 4, 2, 1, 2, 2, 2, 2, 4, 4, 4, 3, 2, 1, 3, 4, 0, 4, 2, 2, 3, 4, 3, 2, 2, 2, 2, 4, 4, 1, 4, 4, 2, 4, 2, 3, 3, 3, 2, 3, 2, 2, 2, 2, 2, 3, 4, 2, 4, 2, 0, 4, 2, 2, 1, 1, 2, 2, 0, 4, 3, 1, 4, 2, 2, 0, 1, 1, 0, 1, 1, 0, 2, 1, 5, 1, 4, 2, 3, 2, 0, 1, 2, 2, 2, 2, 2, 1, 4, 4, 4, 1, 2, 5, 0, 2, 2, 1, 4, 2, 2, 0, 1, 1, 2, 4, 2, 2, 4, 1, 2, 4, 2, 4, 2, 4, 0, 2, 3, 4, 4, 1, 2, 4, 4, 3, 4, 1, 0, 4, 0, 2, 4, 0, 0, 2, 1, 3, 2, 4, 2, 4, 2, 2, 4, 4, 4, 1, 1, 3, 1, 2, 3, 0, 4, 4, 2, 0, 2, 4, 2, 2, 3, 0, 0, 3, 4, 0, 2, 0, 2, 1, 2, 2, 1, 4, 4, 2, 2, 2, 2, 2, 2, 4, 4, 4, 2, 5, 2, 3, 2, 0, 3, 4, 2, 2, 2, 2, 4, 4, 4, 3, 4, 0, 2, 4, 4, 2, 2, 4, 4, 3, 1, 2, 4, 4, 2, 4, 3, 0, 3, 0, 4, 2, 0, 0, 3, 1, 4, 4, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 5, 2, 0, 1, 2, 2, 4, 2, 2, 2, 2, 5, 2, 5, 2, 1, 4, 2, 2, 5, 0, 1, 4, 0, 1, 2, 4, 1, 3, 2, 4, 4, 4, 4, 2, 4, 2, 1, 4, 4, 4, 2, 0, 2, 4, 2, 4, 2, 4, 4, 2, 4, 2, 2, 0, 4, 2, 2, 0, 0, 2, 3, 2, 0, 1, 4, 3, 4, 3, 4, 4, 4, 2, 4, 1, 2, 0, 4, 4, 4, 3, 2, 0, 2, 2, 1, 2, 4, 2, 4, 1, 3, 3, 2, 2, 4, 2, 2, 2, 4, 1, 2, 2, 4, 1, 2, 4, 0, 3, 0, 4, 5, 1, 0, 5, 5, 4, 0, 1, 2, 2, 2, 0, 1, 4, 2, 2, 3, 2, 0, 2, 1, 2, 4, 2, 2, 4, 2, 4, 0, 0, 2, 4, 2, 2, 4, 0, 0, 4, 2, 2, 3, 2, 2, 2, 3, 3, 2, 1, 4, 1, 4, 4, 0, 4, 2, 0, 1, 0, 0, 0, 3, 2, 4, 4, 4, 1, 2, 2, 0, 4, 0, 2, 0, 2, 2, 0, 2, 4, 2, 1, 2, 3, 3, 4, 4, 1, 0, 2, 0, 2, 2, 0, 4, 2, 2, 5, 1, 2, 3, 3, 4, 4, 4, 4, 0, 4, 4, 2, 1, 3, 0, 0, 1, 2, 1, 4, 4, 0, 4, 2, 2, 4, 1, 0, 4, 0, 4, 2, 4, 2, 1, 4, 4, 2, 4, 4, 2, 2, 2, 2, 4, 1, 4, 3, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 0, 2, 2, 2, 2, 1, 2, 4, 2, 4, 4, 2, 2, 1, 4, 1, 4, 4, 4, 4, 0, 2, 1, 2, 2, 1, 2, 4, 4, 2, 0, 4, 2, 1, 4, 2, 2, 1, 0, 2, 0, 4, 0, 3, 4, 2, 0, 4, 4, 2, 2, 2, 2, 4, 1, 4, 1, 2, 0, 0, 2, 4, 2, 2, 0, 4, 4, 2, 4, 3, 1, 1, 2, 3, 2, 2, 1, 4, 4, 1, 3, 4, 2, 2, 1, 3, 1, 4, 2, 4, 3, 1, 4, 2, 2, 4, 4, 3, 2, 2, 2, 1, 4, 1, 4, 4, 1, 1, 3, 4, 5, 4, 2, 1, 3, 3, 2, 3, 1, 4, 0, 2, 4, 4, 3, 2, 4, 4, 2, 3, 4, 0, 4, 1, 4, 4, 2, 2, 2, 2, 1, 2, 4, 4, 1, 2, 1, 4, 0, 4, 2, 4, 4, 2, 4, 2, 4, 2, 2, 2, 2, 1, 4, 0, 2, 1, 2, 2, 4, 4, 4, 4, 1, 0, 2, 4, 2, 1, 0, 4, 0, 4, 4, 2, 4, 3, 4, 1, 2, 2, 2, 2, 2, 0, 4, 4, 0, 4, 4, 2, 0, 0, 2, 2, 1, 3, 0, 4, 4, 1, 4, 2, 1, 5, 4, 1, 4, 3, 1, 4, 4, 4, 2, 4, 3, 1, 0, 0, 2, 2, 2, 2, 4, 4, 2, 2, 0, 2, 0, 2, 4, 2, 2, 0, 4, 4, 2, 4, 2, 3, 0, 2, 0, 2, 0, 4, 4, 3, 4, 0, 2, 3, 2, 0, 4, 2, 4, 0, 0, 4, 2, 1, 0, 3, 4, 0, 4, 1, 2, 4, 4, 0, 0, 1, 5, 1, 4, 2, 2, 3, 2, 3, 2, 4, 3, 2, 2, 2, 4, 2, 4, 2, 0, 2, 3, 2, 4, 4, 4, 0, 1, 3, 2, 0, 4, 4, 2, 1, 2, 1, 3, 3, 0, 0, 4, 1, 4, 4, 5, 3, 2, 2, 3, 4, 2, 2, 1, 4, 0, 0, 4, 3, 1, 1, 0, 0, 2, 4, 4, 2, 2, 1, 4, 2, 3, 1, 0, 4, 2, 0, 5, 1, 2, 2, 3, 1, 4, 2, 0, 1, 0, 4, 4, 4, 0, 4, 1, 2, 0, 0, 4, 1, 2, 0, 1, 4, 2, 1, 2, 3, 0, 1, 1, 1, 1, 2, 0, 0, 4, 2, 4, 2, 4, 4, 2, 4, 1, 1, 2, 4, 2, 4, 2, 1, 0, 4, 2, 0, 2, 2, 4, 2, 2, 0, 0, 2, 2, 2, 4, 2, 2, 2, 0, 0, 2, 3, 2, 3, 2, 2, 2, 4, 2, 4, 5, 4, 0, 0, 0, 1, 1, 2, 1, 1, 2, 0, 2, 2, 2, 3, 2, 1, 4, 4, 5, 4, 4, 0, 2, 3, 1, 2, 0, 2, 5, 0, 1, 4, 2, 4, 2, 4, 3, 1, 4, 4, 5, 2, 0, 0, 4, 5, 0, 2, 1, 4, 1, 2, 2, 1, 4, 2, 2, 2, 1, 4, 3, 1, 3, 4, 0, 3, 4, 2, 2, 2, 1, 4, 0, 1, 3, 2, 3, 0, 4, 2, 2, 3, 4, 2, 4, 2, 4, 4, 1, 0, 2, 4, 2, 4, 2, 2, 4, 5, 2, 2, 0, 2, 2, 1, 2, 4, 4, 1, 0, 4, 2, 4, 4, 2, 0, 4, 4, 1, 4, 2, 5, 4, 2, 4, 0, 0, 1, 2, 2, 1, 1, 3, 4, 3, 2, 4, 2, 2, 2, 0, 5, 2, 0, 0, 0, 2, 4, 1, 0, 2, 4, 4, 1, 2, 2, 0, 4, 2, 1, 2, 4, 4, 2, 2, 4, 4, 4, 5, 3, 5, 2, 2, 2, 2, 3, 2, 4, 1, 1, 4, 0, 2, 2, 1, 4, 4, 4, 1, 2, 3, 0, 4, 2, 2, 2, 4, 3, 4, 2, 2, 4, 2, 2, 4, 4, 2, 1, 4, 2, 2, 4, 2, 4, 4, 2, 3, 2, 4, 4, 4, 3, 2, 2, 2, 5, 2, 0, 2, 4, 2, 2, 1, 0, 2, 4, 2, 4, 4, 4, 2, 2, 4, 2, 5, 2, 4, 5, 1, 2, 2, 4, 4, 5, 4, 1, 1, 0, 5, 3, 5, 0, 2, 2, 2, 4, 2, 2, 4, 0, 4, 4, 4, 2, 1, 2, 2, 2, 4, 2, 4, 2, 4, 4, 1, 2, 2, 4, 2, 2, 0, 2, 2, 4, 2, 4, 1, 0, 2, 2, 0, 2, 4, 3, 0, 2, 4, 3, 1, 0, 2, 4, 4, 2, 2, 1, 4, 4, 3, 4, 0, 2, 4, 0, 4, 4, 2, 1, 5, 1, 2, 4, 2, 0, 5, 4, 0, 0, 1, 4, 4, 2, 4, 1, 4, 0, 4, 2, 0, 2, 3, 0, 1, 3, 3, 4, 4, 0, 2, 3, 4, 2, 4, 4, 1, 1, 1, 4, 3, 2, 3, 4, 1, 2, 1, 2, 2, 0, 2, 1, 2, 2, 4, 0, 4, 2, 0, 1, 5, 2, 4, 1, 4, 2, 2, 0, 4, 3, 1, 0, 4, 4, 3, 4, 3, 2, 2, 4, 4, 1, 2, 2, 2, 2, 2, 4, 2, 2, 3, 0, 2, 1, 1, 3, 1, 4, 2, 4, 4, 2, 0, 2, 2, 2, 4, 4, 3, 4, 4, 4, 1, 0, 0, 0, 4, 4, 3, 0, 1, 2, 2, 3, 2, 1, 4, 0, 3, 2, 2, 5, 4, 2, 4, 4, 4, 4, 2, 2, 4, 3, 4, 4, 1, 2, 4, 2, 2, 4, 1, 1, 2, 2, 2, 2, 0, 4, 4, 1, 1, 4, 4, 0, 2, 2, 4, 2, 1, 1, 4, 0, 2, 2, 1, 2, 2, 0, 4, 0, 1, 4, 5, 2, 4, 5, 4, 0, 2, 4, 1, 1, 1, 2, 0, 3, 0, 0, 0, 2, 0, 0, 2, 0, 1, 2, 4, 3, 4, 0, 1, 4, 2, 2, 0, 2, 2, 2, 0, 4, 4, 4, 2, 4, 3, 4, 2, 1, 2, 0, 4, 0, 1, 4, 0, 2, 0, 4, 2, 1, 4, 4, 1, 2, 1, 1, 1, 4, 2, 5, 2, 2, 4, 2, 3, 1, 2, 1, 2, 3, 4, 4, 0, 3, 2, 4, 3, 0, 2, 0, 4, 1, 4, 5, 5, 2, 3, 0, 1, 2, 4, 4, 2, 4, 4, 2, 2, 3, 4, 1, 3, 0, 2, 2, 4, 2, 2, 2, 5, 2, 1, 3, 2, 1, 4, 1, 3, 2, 1, 4, 1, 4, 2, 4, 4, 4, 0, 2, 2, 2, 3, 1, 4, 0, 0, 4, 1, 1, 3, 1, 4, 1, 0, 2, 0, 4, 0, 2, 0, 4, 0, 4, 4, 2, 2, 0, 1, 4, 0, 4, 3, 4, 4, 4, 0, 3, 4, 2, 0, 3, 2, 4, 0, 4, 1, 3, 4, 4, 0, 3, 2, 5, 1, 0, 4, 4, 1, 1, 4, 1, 4, 0, 1, 0, 4, 2, 5, 1, 3, 4, 0, 4, 2, 3, 4, 0, 1, 3, 2, 2, 2, 2, 2, 0, 3, 1, 2, 2, 2, 0, 4, 4, 4, 2, 2, 4, 2, 1, 4, 4, 4, 4, 1, 1, 4, 2, 0, 2, 5, 4, 4, 4, 4, 2, 0, 3, 4, 2, 4, 4, 2, 2, 4, 4, 4, 0, 5, 4, 0, 2, 3, 3, 0, 3, 1, 2, 1, 2, 3, 2, 2, 1, 1, 0, 2, 0, 1, 3, 1, 4, 0, 1, 1, 2, 2, 4, 4, 3, 4, 4, 2, 4, 4, 1, 4, 2, 1, 2, 2, 4, 4, 0, 1, 4, 5, 5, 5, 4, 4, 2, 4, 0, 4, 4, 2, 4, 2, 4, 4, 0, 2, 0, 2, 5, 0, 4, 5, 1, 0, 4, 2, 4, 3, 2, 4, 4, 2, 2, 5, 2, 2, 2, 2, 2, 2, 0, 4, 1, 0, 1, 4, 2, 5, 2, 0, 1, 4, 3, 2, 4, 2, 2, 2, 4, 2, 0, 0, 2, 2, 4, 4, 4, 2, 2, 4, 4, 0, 2, 2, 4, 4, 0, 1, 2, 4, 3, 2, 4, 4, 4, 4, 0, 4, 2, 5, 3, 2, 5, 3, 2, 2, 2, 2, 2, 0, 2, 2, 0, 3, 2, 5, 0, 0, 4, 1, 1, 2, 2, 4, 4, 2, 0, 2, 4, 2, 4, 2, 2, 2, 4, 3, 2, 4, 3, 0, 3, 2, 2, 4, 1, 2, 1, 4, 2, 2, 3, 0, 0, 0, 3, 0, 0, 1, 2, 2, 4, 4, 4, 2, 0, 5, 2, 4, 4, 2, 2, 3, 0, 2, 2, 1, 2, 0, 1, 0, 4, 2, 4, 2, 4, 2, 4, 4, 0, 1, 2, 4, 3, 0, 4, 4, 2, 0, 1, 5, 3, 4, 5, 5, 3, 4, 2, 2, 0, 4, 4, 3, 0, 1, 1, 2, 1, 2, 4, 4, 2, 2, 4, 1, 3, 4, 2, 4, 5, 2, 2, 0, 2, 2, 0, 2, 4, 4, 0, 2, 1, 1, 4, 2, 4, 4, 4, 0, 2, 0, 0, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 1, 0, 3, 4, 4, 2, 4, 1, 2, 0, 1, 4, 2, 4, 3, 2, 2, 2, 2, 1, 2, 1, 0, 3, 0, 4, 1, 4, 4, 2, 2, 4, 4, 4, 2, 2, 2, 3, 0, 5, 4, 4, 4, 2, 5, 5, 3, 1, 3, 1, 0, 2, 2, 4, 2, 4, 4, 2, 4, 2, 3, 1, 4, 2, 2, 4, 2, 4, 0, 2, 4, 3, 4, 1, 2, 1, 3, 2, 0, 2, 2, 1, 2, 2, 2, 2, 2, 2, 4, 2, 1, 5, 4, 0, 4, 4, 2, 1, 1, 0, 2, 3, 1, 2, 4, 1, 3, 4, 2, 2, 4, 4, 2, 4, 2, 4, 2, 0, 3, 1, 2, 2, 5, 2, 4, 2, 2, 2, 1, 1, 2, 4, 4, 2, 2, 2, 3, 4, 3, 2, 2, 1, 4, 4, 3, 4, 4, 4, 2, 4, 4, 4, 3, 1, 2, 2, 1, 2, 4, 0, 4, 2, 2, 4, 0, 2, 4, 3, 2, 0, 2, 1, 2, 5, 4, 4, 0, 1, 4, 1, 4, 2, 1, 0, 2, 4, 2, 4, 2, 4, 0, 1, 4, 2, 0, 4, 0, 1, 2, 0, 2, 4, 1, 2, 2, 4, 4, 4, 3, 4, 4, 2, 1, 2, 4, 0, 2, 4, 3, 1, 2, 2, 4, 2, 4, 2, 3, 5, 4, 4, 2, 1, 4, 4, 4, 3, 2, 2, 1, 4, 1, 4, 2, 2, 5, 4, 2, 4, 0, 2, 0, 2, 0, 4, 4, 0, 2, 4, 4, 1, 0, 1, 4, 1, 2, 1, 2, 0, 2, 4, 5, 0, 4, 4, 1, 1, 2, 4, 4, 4, 2, 2, 5, 0, 0, 0, 2, 0, 4, 4, 2, 3, 2, 2, 4, 0, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 3, 2, 2, 3, 2, 1, 4, 2, 3, 3, 2, 4, 2, 2, 2, 0, 4, 2, 1, 2, 4, 4, 2, 1, 0, 0, 2, 0, 2, 3, 2, 2, 2, 2, 4, 2, 2, 2, 2, 0, 2, 5, 4, 2, 4, 0, 0, 4, 4, 4, 3, 0, 0, 4, 4, 2, 4, 4, 2, 2, 1, 2, 2, 2, 1, 5, 4, 4, 2, 1, 1, 2, 2, 4, 1, 2, 4, 4, 4, 1, 1, 4, 5, 4, 2, 4, 1, 2, 2, 2, 1, 1, 2, 2, 0, 1, 4, 4, 2, 0, 1, 4, 4, 4, 4, 2, 3, 2, 2, 0, 3, 0, 2, 4, 5, 4, 0, 4, 1, 4, 0, 0, 4, 2, 4, 0, 3, 2, 4, 4, 4, 0, 2, 1, 2, 0, 1, 2, 1, 4, 1, 2, 2, 2, 4, 1, 4, 4, 4, 4, 2, 4, 2, 3, 3, 4, 2, 3, 3, 2, 0, 4, 2, 1, 4, 4, 2, 0, 1, 4, 5, 0, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 5, 0, 0, 2, 2, 2, 2, 2, 4, 4, 4, 0, 0, 4, 2, 1, 4, 1, 4, 4, 2, 2, 2, 0, 2, 2, 2, 4, 2, 0, 1, 0, 1, 0, 4, 2, 0, 4, 0, 0, 2, 4, 2, 3, 2, 4, 4, 1, 2, 2, 4, 2, 5, 2, 2, 0, 4, 0, 2, 4, 2, 2, 3, 2, 0, 0, 4, 2, 4, 4, 2, 4, 3, 5, 2, 2, 4, 4, 4, 3, 4, 3, 4, 2, 4, 2, 0, 1, 2, 3, 0, 4, 0, 2, 5, 4, 2, 1, 4, 1, 2, 1, 2, 0, 1, 2, 0, 2, 2, 4, 4, 2, 4, 4, 3, 4, 1, 0, 0, 2, 0, 4, 2, 2, 2, 2, 4, 2, 2, 3, 4, 1, 2, 4, 2, 0, 0, 0, 2, 2, 4, 2, 0, 0, 4, 2, 2, 2, 0, 3, 4, 2, 4, 2, 4, 4, 1, 4, 1, 4, 4, 4, 2, 2, 2, 4, 4, 4, 3, 4, 1, 5, 4, 4, 2, 2, 2, 0, 0, 5, 3, 4, 2, 0, 4, 0, 0, 1, 1, 2, 2, 2, 2, 2, 4, 0, 3, 2, 4, 1, 2, 4, 2, 1, 0, 0, 2, 1, 4, 2, 3, 3, 2, 2, 0, 4, 1, 2, 1, 3, 4, 4, 4, 0, 5, 4, 0, 4, 4, 1, 5, 3, 2, 2, 4, 2, 0, 2, 3, 0, 2, 5, 1, 0, 2, 2, 3, 2, 3, 4, 2, 4, 2, 2, 2, 2, 2, 4, 0, 2, 1, 4, 2, 4, 4, 4, 2, 2, 1, 1, 2, 5, 0, 4, 4, 2, 2, 2, 0, 2, 2, 0, 1, 2, 2, 1, 1, 1, 2, 4, 2, 0, 2, 4, 4, 4, 4, 5, 2, 2, 4, 2, 4, 4, 5, 2, 1, 0, 0, 2, 4, 2, 2, 2, 4, 2, 0, 4, 2, 2, 4, 4, 4, 1, 2, 4, 0, 0, 4, 2, 2, 4, 2, 0, 3, 5, 4, 2, 4, 0, 2, 5, 3, 4, 0, 4, 2, 4, 3, 3, 2, 4, 4, 4, 2, 4, 0, 4, 1, 4, 2, 3, 4, 4, 4, 2, 1, 4, 2, 4, 4, 2, 2, 2, 4, 4, 4, 5, 1, 2, 4, 0, 4, 2, 1, 5, 3, 5, 2, 2, 2, 4, 2, 1, 4, 1, 4, 4, 1, 3, 4, 2, 4, 0, 2, 4, 3, 2, 2, 4, 2, 4, 4, 1, 3, 0, 4, 4, 0, 2, 4, 3, 2, 4, 1, 2, 1, 2, 4, 4, 0, 1, 2, 2, 4, 2, 4, 0, 2, 0, 0, 4, 2, 4, 2, 4, 4, 4, 2, 5, 2, 3, 5, 4, 2, 2, 4, 2, 2, 2, 0, 2, 4, 4, 2, 2, 2, 1, 4, 0, 4, 2, 4, 2, 3, 4, 4, 4, 0, 1, 0, 1, 2, 0, 2, 2, 0, 2, 4, 0, 2, 0, 0, 2, 2, 5, 0, 1, 0, 1, 2, 4, 2, 4, 4, 2, 1, 2, 4, 1, 4, 3, 4, 5, 2, 0, 2, 0, 4, 1, 2, 1, 0, 4, 4, 3, 2, 2, 4, 2, 4, 2, 2, 0, 4, 4, 1, 2, 4, 2, 0, 4, 2, 4, 4, 3, 0, 2, 1, 4, 0, 0, 5, 0, 4, 0, 0, 0, 0, 2, 2, 3, 2, 4, 4, 4, 2, 1, 1, 2, 2, 0, 4, 0, 1, 2, 0, 4, 4, 2, 0, 2, 0, 5, 3, 2, 0, 4, 2, 4, 2, 4, 4, 1, 0, 0, 4, 1, 4, 4, 4, 3, 2, 0, 2, 3, 0, 3, 2, 2, 3, 4, 4, 0, 2, 4, 1, 5, 4, 1, 4, 0, 4, 2, 1, 3, 2, 4, 2, 0, 4, 1, 2, 2, 2, 2, 3, 4, 2, 2, 2, 1, 2, 2, 4, 3, 4, 4, 0, 2, 4, 0, 2, 4, 2, 5, 2, 1, 4, 1, 2, 3, 0, 2, 3, 2, 2, 2, 0, 3, 4, 1, 4, 2, 4, 4, 2, 2, 0, 0, 2, 3, 2, 4, 4, 0, 0, 4, 0, 3, 4, 1, 2, 2, 2, 4, 2, 0, 0, 1, 2, 2, 1, 2, 5, 4, 0, 5, 1, 2, 2, 2, 4, 2, 2, 1, 5, 2, 4, 2, 3, 4, 4, 0, 2, 4, 4, 3, 1, 0, 2, 0, 4, 2, 4, 4, 4, 2, 3, 2, 4, 2, 2, 0, 1, 4, 3, 4, 4, 0, 4, 2, 3, 2, 3, 1, 2, 2, 4, 2, 2, 2, 3, 0, 2, 4, 2, 2, 2, 4, 2, 2, 1, 0, 4, 0, 3, 2, 2, 2, 4, 1, 2, 1, 4, 2, 2, 2, 4, 2, 2, 2, 4, 0, 2, 2, 4, 2, 0, 1, 2, 4, 2, 4, 0, 2, 4, 4, 1, 3, 4, 2, 3, 2, 1, 4, 0, 2, 1, 4, 4, 0, 0, 1, 1, 3, 0, 2, 4, 3, 2, 4, 5, 0, 2, 2, 1, 4, 2, 3, 4, 0, 2, 0, 1, 4, 0, 4, 2, 2, 4, 1, 2, 0, 1, 4, 1, 0, 2, 4, 2, 1, 2, 4, 4, 4, 2, 1, 4, 1, 2, 3, 2, 2, 2, 2, 2, 2, 1, 2, 2, 4, 1, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 4, 3, 2, 5, 4, 4, 3, 4, 3, 3, 2, 3, 0, 1, 2, 2, 4, 1, 1, 1, 2, 2, 0, 2, 2, 0, 3, 1, 0, 4, 4, 1, 4, 4, 0, 0, 0, 2, 2, 2, 2, 2, 2, 3, 2, 0, 4, 2, 1, 4, 3, 3, 1, 2, 4, 5, 4, 1, 1, 0, 4, 4, 2, 2, 2, 2, 4, 4, 1, 2, 2, 2, 2, 4, 2, 2, 1, 4, 2, 2, 3, 2, 4, 4, 0, 2, 2, 4, 5, 2, 1, 5, 1, 2, 2, 1, 2, 0, 3, 4, 2, 4, 3, 4, 2, 0, 1, 4, 3, 3, 2, 4, 2, 2, 4, 4, 2, 4, 4, 1, 4, 2, 4, 2, 2, 1, 2, 2, 3, 2, 2, 2, 0, 3, 2, 2, 4, 2, 4, 4, 4, 1, 4, 2, 4, 1, 2, 1, 4, 4, 1, 2, 3, 2, 3, 2, 2, 1, 4, 2, 2, 3, 0, 2, 0, 2, 4, 4, 1, 2, 4, 5, 1, 2, 4, 2, 3, 2, 2, 2, 4, 5, 5, 1, 4, 2, 1, 4, 4, 0, 1, 5, 1, 4, 2, 2, 2, 2, 4, 4, 2, 1, 0, 0, 4, 4, 5, 4, 1, 0, 2, 1, 0, 1, 2, 4, 0, 3, 1, 2, 2, 4, 2, 4, 2, 2, 0, 3, 1, 2, 4, 2, 4, 4, 4, 4, 2, 0, 3, 0, 2, 2, 2, 4, 2, 4, 0, 2, 2, 4, 2, 2, 4, 0, 0, 2, 2, 4, 4, 2, 1, 3, 4, 2, 1, 2, 1, 3, 2, 2, 2, 2, 4, 2, 4, 2, 4, 1, 4, 2, 1, 2, 4, 2, 3, 3, 3, 2, 4, 2, 4, 4, 4, 0, 1, 5, 1, 2, 2, 0, 4, 2, 2, 2, 0, 0, 2, 4, 4, 4, 0, 1, 4, 2, 0, 2, 1, 0, 2, 0, 4, 2, 0, 4, 4, 1, 2, 2, 1, 4, 2, 2, 2, 4, 2, 1, 3, 0, 2, 2, 2, 4, 2, 4, 4, 0, 2, 0, 0, 2, 3, 4, 1, 1, 0, 1, 1, 4, 2, 4, 2, 4, 1, 3, 5, 3, 2, 4, 2, 1, 4, 2, 2, 4, 4, 0, 0, 1, 3, 2, 2, 2, 4, 4, 4, 4, 2, 3, 2, 1, 2, 4, 4, 1, 4, 4, 4, 0, 0, 2, 4, 4, 0, 4, 3, 1, 0, 4, 2, 2, 2, 3, 0, 0, 0, 1, 1, 2, 3, 1, 1, 5, 2, 2, 1, 4, 4, 4, 3, 5, 2, 3, 2, 2, 3, 2, 3, 5, 4, 2, 2, 2, 2, 0, 4, 2, 0, 3, 2, 1, 1, 4, 3, 4, 4, 4, 2, 4, 4, 3, 2, 4, 4, 2, 5, 0, 4, 4, 4, 2, 3, 1, 4, 4, 4, 2, 4, 4, 2, 4, 5, 3, 5, 4, 4, 3, 0, 4, 2, 0, 4, 2, 2, 2, 4, 0, 5, 2, 4, 1, 4, 2, 2, 4, 2, 4, 2, 4, 1, 5, 2, 5, 3, 2, 3, 2, 4, 1, 0, 2, 1, 4, 3, 4, 4, 4, 4, 2, 2, 4, 1, 0, 2, 4, 4, 5, 4, 5, 4, 1, 3, 3, 4, 1, 4, 4, 4, 2, 4, 2, 2, 4, 3, 2, 2, 0, 4, 2, 2, 4, 4, 2, 4, 4, 4, 4, 4, 0, 0, 0, 4, 3, 3, 4, 0, 4, 3, 4, 4, 2, 1, 3, 2, 1, 4, 2, 2, 4, 4, 0, 3, 2, 3, 2, 3, 2, 3, 2, 2, 4, 1, 5, 4, 2, 1, 4, 2, 1, 4, 4, 4, 0, 4, 2, 2, 3, 1, 3, 5, 4, 4, 2, 5, 0, 1, 2, 2, 4, 2, 4, 5, 1, 0, 2, 2, 1, 2, 4, 4, 2, 0, 4, 1, 1, 0, 0, 4, 0, 4, 4, 4, 2, 1, 3, 4, 4, 4, 1, 1, 4, 2, 2, 0, 4, 3, 2, 1, 4, 1, 3, 4, 4, 2, 4, 2, 2, 3, 2, 4, 2, 4, 1, 4, 2, 2, 0, 0, 0, 1, 0, 2, 5, 4, 4, 0, 2, 1, 0, 4, 2, 0, 4, 2, 1, 0, 1, 0, 2, 1, 0, 2, 0, 0, 0, 0, 1, 2, 2, 5, 4, 1, 2, 4, 4, 4, 2, 4, 4, 2, 0, 0, 2, 1, 3, 4, 2, 2, 0, 4, 2, 1, 1, 2, 4, 4, 0, 2, 3, 0, 4, 5, 2, 2, 4, 4, 4, 0, 4, 2, 4, 2, 0, 2, 2, 0, 2, 2, 4, 4, 2, 0, 2, 3, 1, 5, 4, 3, 5, 4, 0, 1, 1, 0, 0, 2, 0, 0, 3, 1, 3, 2, 0, 2, 0, 2, 4, 5, 1, 2, 2, 4, 4, 0, 2, 3, 4, 4, 4, 2, 1, 2, 1, 0, 3, 1, 0, 2, 4, 2, 3, 2, 1, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 3, 4, 0, 2, 4, 2, 3, 4, 2, 4, 2, 4, 0, 1, 5, 4, 4, 4, 4, 2, 1, 4, 3, 2, 4, 4, 2, 0, 5, 0, 4, 3, 3, 3, 3, 1, 3, 2, 4, 5, 4, 4, 2, 4, 1, 2, 2, 4, 4, 2, 0, 4, 2, 2, 2, 1, 1, 1, 2, 2, 2, 1, 4, 4, 4, 2, 0, 3, 2, 0, 2, 4, 3, 2, 4, 3, 4, 3, 1, 0, 4, 4, 4, 4, 4, 4, 4, 0, 4, 2, 2, 4, 4, 1, 1, 2, 2, 0, 2, 3, 2, 2, 4, 4, 2, 2, 0, 4, 4, 4, 4, 4, 1, 4, 2, 4, 4, 1, 4, 1, 4, 2, 4, 4, 4, 1, 1, 0, 1, 1, 2, 0, 4, 0, 2, 0, 4, 2, 3, 2, 2, 4, 4, 2, 4, 4, 0, 4, 4, 0, 0, 2, 0, 4, 1, 0, 1, 4, 0, 2, 4, 1, 4, 4, 2, 5, 4, 1, 1, 5, 4, 2, 4, 4, 2, 2, 4, 1, 1, 1, 1, 3, 2, 5, 4, 2, 0, 4, 4, 4, 0, 4, 0, 4, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 2, 2, 1, 4, 2, 2, 3, 2, 0, 2, 2, 0, 4, 2, 2, 0, 4, 0, 0, 5, 4, 4, 4, 4, 0, 2, 1, 4, 0, 0, 4, 4, 2, 4, 2, 2, 1, 2, 3, 4, 4, 0, 1, 0, 4, 2, 3, 0, 2, 4, 4, 2, 5, 1, 2, 2, 4, 1, 4, 2, 2, 3, 2, 4, 4, 5, 0, 4, 0, 4, 4, 4, 0, 4, 4, 2, 5, 4, 0, 5, 2, 2, 2, 3, 4, 4, 4, 4, 2, 4, 4, 4, 1, 4, 0, 4, 1, 3, 0, 2, 3, 4, 4, 1, 4, 4, 0, 4, 2, 1, 0, 0, 2, 2, 2, 2, 1, 4, 2, 5, 0, 2, 4, 4, 4, 3, 4, 2, 2, 2, 2, 2, 5, 2, 1, 1, 5, 2, 2, 0, 4, 2, 4, 0, 2, 0, 2, 0, 3, 0, 0, 4, 2, 1, 2, 2, 4, 3, 4, 4, 2, 2, 2, 2, 2, 2, 1, 0, 4, 2, 4, 2, 2, 4, 4, 2, 4, 2, 2, 0, 2, 4, 2, 2, 2, 0, 2, 2, 4, 1, 4, 2, 4, 0, 1, 4, 4, 4, 4, 3, 4, 2, 0, 4, 0, 4, 3, 4, 1, 1, 5, 2, 4, 1, 4, 3, 2, 4, 2, 0, 5, 4, 2, 2, 0, 3, 1, 2, 0, 4, 4, 3, 0, 4, 4, 2, 4, 2, 2, 4, 4, 0, 2, 2, 0, 4, 2, 2, 1, 4, 2, 4, 4, 4, 4, 2, 1, 4, 3, 3, 4, 1, 1, 2, 4, 2, 0, 4, 4, 4, 4, 1, 4, 4, 2, 4, 2, 2, 4, 3, 2, 4, 0, 0, 2, 2, 2, 5, 0, 1, 4, 4, 2, 4, 1, 4, 2, 1, 4, 0, 2, 2, 0, 2, 0, 0, 1, 2, 5, 1, 0, 0, 2, 2, 4, 4, 4, 2, 0, 5, 4, 0, 4, 2, 0, 2, 1, 2, 1, 2, 4, 4, 2, 2, 4, 2, 4, 4, 2, 4, 2, 4, 4, 0, 2, 0, 4, 2, 2, 1, 0, 0, 3, 2, 4, 2, 2, 0, 4, 0, 4, 4, 0, 0, 3, 1, 1, 2, 3, 4, 2, 2, 4, 2, 4, 4, 4, 4, 1, 4, 2, 0, 0, 1, 2, 3, 2, 2, 2, 2, 2, 4, 1, 2, 2, 3, 0, 2, 2, 4, 2, 4, 4, 1, 2, 2, 5, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 0, 4, 4, 2, 2, 0, 2, 2, 2, 1, 1, 4, 4, 0, 4, 4, 0, 2, 1, 2, 0, 4, 3, 3, 4, 4, 4, 3, 2, 4, 2, 4, 0, 0, 2, 0, 2, 3, 2, 2, 3, 0, 1, 2, 0, 3, 3, 1, 2, 0, 2, 4, 3, 1, 2, 2, 4, 1, 2, 1, 2, 4, 3, 1, 2, 4, 4, 4, 4, 2, 2, 3, 4, 2, 1, 2, 2, 2, 2, 3, 4, 4, 0, 4, 0, 4, 2, 4, 4, 0, 2, 2, 2, 1, 2, 0, 2, 3, 1, 3, 1, 0, 2, 4, 4, 2, 3, 2, 3, 1, 3, 4, 1, 2, 0, 1, 1, 3, 4, 2, 1, 4, 2, 2, 4, 4, 0, 2, 4, 1, 4, 4, 1, 1, 4, 2, 2, 2, 4, 2, 0, 0, 2, 1, 2, 2, 2, 2, 3, 2, 2, 1, 0, 2, 2, 4, 4, 4, 2, 4, 0, 4, 2, 5, 3, 1, 5, 1, 0, 3, 2, 3, 0, 0, 4, 3, 4, 0, 4, 4, 4, 2, 4, 4, 2, 4, 2, 1, 4, 4, 0, 4, 1, 2, 4, 4, 4, 2, 2, 4, 0, 2, 2, 3, 0, 4, 0, 4, 2, 4, 1, 2, 2, 1, 0, 1, 4, 4, 3, 2, 1, 0, 4, 2, 4, 3, 3, 1, 0, 4, 2, 0, 3, 4, 0, 2, 5, 4, 2, 4, 4, 4, 2, 5, 0, 1, 0, 4, 4, 1, 4, 5, 2, 3, 4, 4, 4, 1, 3, 5, 2, 2, 4, 4, 4, 4, 2, 4, 1, 4, 0, 3, 2, 0, 4, 3, 2, 4, 1, 2, 2, 3, 4, 2, 1, 0, 4, 4, 2, 4, 4, 2, 3, 4, 0, 2, 0, 2, 4, 1, 0, 4, 1, 2, 2, 2, 2, 4, 2, 3, 0, 3, 4, 2, 1, 4, 2, 1, 4, 3, 4, 5, 5, 0, 1, 2, 2, 2, 4, 4, 2, 5, 2, 2, 2, 4, 2, 0, 1, 2, 4, 2, 4, 0, 4, 3, 3, 1, 1, 5, 4, 4, 2, 0, 0, 4, 1, 2, 4, 2, 0, 2, 5, 2, 5, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 1, 4, 3, 0, 0, 4, 3, 3, 4, 5, 1, 4, 1, 2, 2, 0, 4, 1, 4, 2, 0, 2, 1, 0, 2, 1, 4, 3, 2, 2, 3, 2, 4, 2, 2, 0, 4, 2, 3, 2, 4, 2, 1, 1, 5, 0, 5, 1, 4, 4, 3, 4, 0, 0, 2, 0, 2, 3, 2, 2, 0, 2, 4, 4, 2, 2, 2, 0, 4, 4, 1, 4, 3, 4, 1, 2, 4, 2, 3, 2, 4, 4, 1, 1, 5, 0, 4, 1, 4, 1, 2, 0, 2, 2, 2, 1, 0, 2, 4, 2, 2, 3, 1, 4, 1, 4, 4, 2, 2, 2, 1, 4, 4, 4, 1, 0, 2, 4, 4, 5, 2, 3, 5, 2, 4, 2, 4, 0, 3, 2, 0, 0, 1, 2, 0, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 1, 1, 0, 0, 5, 4, 2, 2, 2, 2, 2, 4, 0, 2, 4, 2, 2, 2, 4, 2, 1, 4, 3, 3, 4, 4, 0, 2, 4, 2, 2, 2, 2, 1, 3, 4, 2, 4, 4, 1, 1, 4, 3, 0, 4, 4, 2, 4, 0, 4, 4, 4, 2, 5, 1, 4, 1, 2, 1, 0, 4, 3, 0, 1, 0, 4, 4, 2, 4, 2, 4, 2, 2, 0, 2, 4, 1, 1, 4, 2, 4, 4, 4, 3, 3, 2, 3, 4, 2, 2, 4, 1, 4, 1, 2, 4, 1, 4, 2, 4, 4, 1, 0, 1, 1, 2, 2, 2, 4, 2, 2, 4, 2, 2, 0, 3, 1, 1, 2, 2, 4, 4, 2, 2, 2, 1, 2, 2, 2, 2, 3, 2, 0, 4, 3, 2, 0, 4, 1, 4, 2, 1, 4, 0, 0, 0, 0, 3, 1, 4, 1, 4, 2, 2, 2, 2, 2, 0, 2, 4, 4, 2, 2, 1, 4, 1, 4, 2, 0, 4, 2, 0, 1, 3, 3, 2, 2, 0, 1, 0, 2, 2, 2, 4, 5, 4, 3, 2, 1, 2, 4, 4, 3, 0, 2, 3, 0, 2, 2, 4, 2, 4, 4, 0, 1, 1, 2, 4, 1, 4, 3, 2, 1, 3, 2, 0, 0, 0, 5, 2, 2, 2, 0, 2, 0, 4, 2, 2, 2, 0, 0, 2, 2, 1, 4, 3, 2, 1, 2, 4, 4, 4, 2, 5, 0, 2, 0, 2, 2, 0, 1, 2, 1, 3, 2, 5, 3, 1, 2, 2, 0, 1, 2, 4, 2, 4, 2, 4, 3, 1, 4, 4, 4, 2, 3, 4, 2, 2, 4, 1, 0, 4, 4, 4, 4, 2, 4, 2, 4, 0, 0, 2, 2, 1, 1, 0, 1, 2, 4, 4, 2, 5, 4, 3, 3, 3, 0, 2, 0, 1, 1, 4, 0, 4, 4, 2, 2, 4, 2, 1, 2, 0, 4, 1, 1, 0, 2, 3, 0, 3, 0, 2, 0, 2, 0, 4, 4, 1, 4, 4, 4, 2, 2, 3, 1, 4, 4, 4, 4, 4, 4, 2, 1, 2, 4, 1, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 3, 4, 4, 4, 2, 4, 1, 5, 1, 1, 2, 2, 0, 2, 0, 2, 0, 4, 0, 2, 2, 0, 3, 2, 4, 0, 1, 3, 0, 2, 4, 0, 4, 4, 5, 3, 4, 2, 5, 1, 4, 0, 1, 1, 2, 2, 0, 1, 2, 2, 2, 2, 4, 5, 2, 4, 0, 2, 3, 4, 4, 2, 0, 4]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18000\n",
      "16000\n",
      "2000\n"
     ]
    }
   ],
   "source": [
    "print(len(X))\n",
    "print(len(X_train))\n",
    "print(len(X_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  i didnt feel humiliated\n",
      "Processed:  i didnt feel humiliated\n"
     ]
    }
   ],
   "source": [
    "# Print sentence 0\n",
    "print('Original: ', X[0])\n",
    "print('Processed: ', text_preprocessing(X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Create a function to tokenize a set of texts\n",
    "def preprocessing_for_bert(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained BERT.\n",
    "    @param    data (np.array): Array of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=text_preprocessing(sent),  # Preprocess sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,                  # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            #return_tensors='pt',           # Return PyTorch tensor\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "            )\n",
    "        \n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  87\n"
     ]
    }
   ],
   "source": [
    "# Concatenate train data and test data\n",
    "all_tweets = np.concatenate([df_train['Input'].values, df_test['Input'].values])\n",
    "\n",
    "# Encode our concatenated data\n",
    "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_tweets])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/psimilan/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  i didnt feel humiliated\n",
      "Token IDs:  [101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Tokenizing data...\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 87\n",
    "\n",
    "# Print sentence 0 and its encoded token ids\n",
    "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
    "print('Original: ', X[0])\n",
    "print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_bert(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16000, 87])\n",
      "torch.Size([16000, 87])\n"
     ]
    }
   ],
   "source": [
    "print(train_inputs.shape)\n",
    "print(train_masks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train)\n",
    "val_labels = torch.tensor(y_val)\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataset.TensorDataset object at 0x7f910715c400>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38 µs, sys: 0 ns, total: 38 µs\n",
      "Wall time: 42.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "\n",
    "# Create the BertClassfier class\n",
    "class BertClassifier(nn.Module):\n",
    "    \"\"\"Bert Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_bert=False):\n",
    "        \"\"\"\n",
    "        @param    bert: a BertModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_bert (bool): Set `False` to fine-tune the BERT model\n",
    "        \"\"\"\n",
    "        super(BertClassifier, self).__init__()\n",
    "        # Specify hidden size of BERT, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 50, 6\n",
    "\n",
    "        # Instantiate BERT model\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        # Instantiate an one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            #nn.Dropout(0.5),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the BERT model\n",
    "        if freeze_bert:\n",
    "            for param in self.bert.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to BERT and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that hold attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to BERT\n",
    "        outputs = self.bert(input_ids=input_ids,\n",
    "                            attention_mask=attention_mask)\n",
    "        \n",
    "        # Extract the last hidden state of the token `[CLS]` for classification task\n",
    "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "def initialize_model(epochs=10):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    bert_classifier = BertClassifier(freeze_bert=False)\n",
    "\n",
    "    # Tell PyTorch to run the model on GPU\n",
    "    bert_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(bert_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return bert_classifier, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=None, epochs=10, evaluation=False):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            #print(logits)\n",
    "            #print(b_labels)\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "            \n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "    on our validation set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "\n",
    "    # For each batch in our validation set...\n",
    "    for batch in val_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        #print(logits)\n",
    "        #print(b_labels)\n",
    "        loss = loss_fn(logits, b_labels)\n",
    "        val_loss.append(loss.item())\n",
    "\n",
    "        # Get the predictions\n",
    "        preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "        # Calculate the accuracy rate\n",
    "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "        val_accuracy.append(accuracy)\n",
    "\n",
    "    # Compute the average accuracy and loss over the validation set.\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    return val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   1.572703   |     -      |     -     |   3.71   \n",
      "   1    |   40    |   1.309237   |     -      |     -     |   3.51   \n",
      "   1    |   60    |   1.063842   |     -      |     -     |   3.53   \n",
      "   1    |   80    |   0.882139   |     -      |     -     |   3.54   \n",
      "   1    |   100   |   0.703019   |     -      |     -     |   3.54   \n",
      "   1    |   120   |   0.490705   |     -      |     -     |   3.52   \n",
      "   1    |   140   |   0.423874   |     -      |     -     |   3.54   \n",
      "   1    |   160   |   0.412985   |     -      |     -     |   3.55   \n",
      "   1    |   180   |   0.337185   |     -      |     -     |   3.58   \n",
      "   1    |   200   |   0.291516   |     -      |     -     |   3.59   \n",
      "   1    |   220   |   0.325266   |     -      |     -     |   3.56   \n",
      "   1    |   240   |   0.292858   |     -      |     -     |   3.60   \n",
      "   1    |   260   |   0.252736   |     -      |     -     |   3.58   \n",
      "   1    |   280   |   0.279070   |     -      |     -     |   3.60   \n",
      "   1    |   300   |   0.247576   |     -      |     -     |   3.60   \n",
      "   1    |   320   |   0.245943   |     -      |     -     |   3.60   \n",
      "   1    |   340   |   0.220768   |     -      |     -     |   3.59   \n",
      "   1    |   360   |   0.259216   |     -      |     -     |   3.59   \n",
      "   1    |   380   |   0.268312   |     -      |     -     |   3.60   \n",
      "   1    |   400   |   0.176319   |     -      |     -     |   3.74   \n",
      "   1    |   420   |   0.242547   |     -      |     -     |   3.84   \n",
      "   1    |   440   |   0.224608   |     -      |     -     |   3.62   \n",
      "   1    |   460   |   0.200917   |     -      |     -     |   3.60   \n",
      "   1    |   480   |   0.225240   |     -      |     -     |   3.60   \n",
      "   1    |   499   |   0.205278   |     -      |     -     |   3.42   \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.448889   |  0.183596  |   93.50   |   93.19  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.174535   |     -      |     -     |   3.77   \n",
      "   2    |   40    |   0.179975   |     -      |     -     |   3.61   \n",
      "   2    |   60    |   0.126700   |     -      |     -     |   3.62   \n",
      "   2    |   80    |   0.171368   |     -      |     -     |   3.61   \n",
      "   2    |   100   |   0.130381   |     -      |     -     |   3.58   \n",
      "   2    |   120   |   0.149809   |     -      |     -     |   3.60   \n",
      "   2    |   140   |   0.187242   |     -      |     -     |   3.59   \n",
      "   2    |   160   |   0.144472   |     -      |     -     |   3.60   \n",
      "   2    |   180   |   0.148781   |     -      |     -     |   3.60   \n",
      "   2    |   200   |   0.148818   |     -      |     -     |   3.59   \n",
      "   2    |   220   |   0.162991   |     -      |     -     |   3.60   \n",
      "   2    |   240   |   0.166596   |     -      |     -     |   3.59   \n",
      "   2    |   260   |   0.125522   |     -      |     -     |   3.60   \n",
      "   2    |   280   |   0.134310   |     -      |     -     |   3.60   \n",
      "   2    |   300   |   0.101021   |     -      |     -     |   3.61   \n",
      "   2    |   320   |   0.093883   |     -      |     -     |   3.60   \n",
      "   2    |   340   |   0.150049   |     -      |     -     |   3.59   \n",
      "   2    |   360   |   0.129858   |     -      |     -     |   3.60   \n",
      "   2    |   380   |   0.127888   |     -      |     -     |   3.59   \n",
      "   2    |   400   |   0.165860   |     -      |     -     |   3.59   \n",
      "   2    |   420   |   0.131739   |     -      |     -     |   3.59   \n",
      "   2    |   440   |   0.155554   |     -      |     -     |   3.60   \n",
      "   2    |   460   |   0.145143   |     -      |     -     |   3.60   \n",
      "   2    |   480   |   0.103310   |     -      |     -     |   3.60   \n",
      "   2    |   499   |   0.142323   |     -      |     -     |   3.42   \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.143990   |  0.156353  |   93.75   |   93.40  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   3    |   20    |   0.086574   |     -      |     -     |   3.77   \n",
      "   3    |   40    |   0.118995   |     -      |     -     |   3.60   \n",
      "   3    |   60    |   0.165325   |     -      |     -     |   3.61   \n",
      "   3    |   80    |   0.103991   |     -      |     -     |   3.61   \n",
      "   3    |   100   |   0.094638   |     -      |     -     |   3.61   \n",
      "   3    |   120   |   0.119549   |     -      |     -     |   3.60   \n",
      "   3    |   140   |   0.080794   |     -      |     -     |   3.62   \n",
      "   3    |   160   |   0.108097   |     -      |     -     |   3.60   \n",
      "   3    |   180   |   0.086760   |     -      |     -     |   3.62   \n",
      "   3    |   200   |   0.090289   |     -      |     -     |   3.61   \n",
      "   3    |   220   |   0.131535   |     -      |     -     |   3.61   \n",
      "   3    |   240   |   0.135259   |     -      |     -     |   3.62   \n",
      "   3    |   260   |   0.080022   |     -      |     -     |   3.60   \n",
      "   3    |   280   |   0.134501   |     -      |     -     |   3.62   \n",
      "   3    |   300   |   0.110082   |     -      |     -     |   3.62   \n",
      "   3    |   320   |   0.088092   |     -      |     -     |   3.61   \n",
      "   3    |   340   |   0.101452   |     -      |     -     |   3.61   \n",
      "   3    |   360   |   0.093010   |     -      |     -     |   3.62   \n",
      "   3    |   380   |   0.090573   |     -      |     -     |   3.61   \n",
      "   3    |   400   |   0.134771   |     -      |     -     |   3.62   \n",
      "   3    |   420   |   0.099645   |     -      |     -     |   3.62   \n",
      "   3    |   440   |   0.131022   |     -      |     -     |   3.64   \n",
      "   3    |   460   |   0.090738   |     -      |     -     |   3.63   \n",
      "   3    |   480   |   0.113851   |     -      |     -     |   3.61   \n",
      "   3    |   499   |   0.125654   |     -      |     -     |   3.43   \n",
      "----------------------------------------------------------------------\n",
      "   3    |    -    |   0.108531   |  0.134529  |   93.90   |   93.80  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   4    |   20    |   0.061669   |     -      |     -     |   3.81   \n",
      "   4    |   40    |   0.089761   |     -      |     -     |   3.61   \n",
      "   4    |   60    |   0.061842   |     -      |     -     |   3.63   \n",
      "   4    |   80    |   0.073058   |     -      |     -     |   3.62   \n",
      "   4    |   100   |   0.091597   |     -      |     -     |   3.64   \n",
      "   4    |   120   |   0.150779   |     -      |     -     |   3.63   \n",
      "   4    |   140   |   0.079452   |     -      |     -     |   3.62   \n",
      "   4    |   160   |   0.075891   |     -      |     -     |   3.61   \n",
      "   4    |   180   |   0.076502   |     -      |     -     |   3.63   \n",
      "   4    |   200   |   0.081692   |     -      |     -     |   3.64   \n",
      "   4    |   220   |   0.115546   |     -      |     -     |   3.62   \n",
      "   4    |   240   |   0.090383   |     -      |     -     |   3.63   \n",
      "   4    |   260   |   0.090483   |     -      |     -     |   3.63   \n",
      "   4    |   280   |   0.117987   |     -      |     -     |   3.63   \n",
      "   4    |   300   |   0.064169   |     -      |     -     |   3.61   \n",
      "   4    |   320   |   0.074473   |     -      |     -     |   3.63   \n",
      "   4    |   340   |   0.076114   |     -      |     -     |   3.62   \n",
      "   4    |   360   |   0.083055   |     -      |     -     |   3.61   \n",
      "   4    |   380   |   0.062701   |     -      |     -     |   3.63   \n",
      "   4    |   400   |   0.134692   |     -      |     -     |   3.63   \n",
      "   4    |   420   |   0.082952   |     -      |     -     |   3.64   \n",
      "   4    |   440   |   0.092598   |     -      |     -     |   3.63   \n",
      "   4    |   460   |   0.073454   |     -      |     -     |   3.64   \n",
      "   4    |   480   |   0.081924   |     -      |     -     |   3.62   \n",
      "   4    |   499   |   0.105082   |     -      |     -     |   3.46   \n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   4    |    -    |   0.087427   |  0.173352  |   93.75   |   94.16  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   5    |   20    |   0.059183   |     -      |     -     |   3.79   \n",
      "   5    |   40    |   0.059305   |     -      |     -     |   3.63   \n",
      "   5    |   60    |   0.076254   |     -      |     -     |   3.62   \n",
      "   5    |   80    |   0.079035   |     -      |     -     |   3.61   \n",
      "   5    |   100   |   0.051603   |     -      |     -     |   3.62   \n",
      "   5    |   120   |   0.050878   |     -      |     -     |   3.62   \n",
      "   5    |   140   |   0.044038   |     -      |     -     |   3.61   \n",
      "   5    |   160   |   0.055733   |     -      |     -     |   3.64   \n",
      "   5    |   180   |   0.056302   |     -      |     -     |   3.62   \n",
      "   5    |   200   |   0.083764   |     -      |     -     |   3.63   \n",
      "   5    |   220   |   0.061801   |     -      |     -     |   3.63   \n",
      "   5    |   240   |   0.056689   |     -      |     -     |   3.63   \n",
      "   5    |   260   |   0.116881   |     -      |     -     |   3.62   \n",
      "   5    |   280   |   0.066369   |     -      |     -     |   3.62   \n",
      "   5    |   300   |   0.045794   |     -      |     -     |   3.62   \n",
      "   5    |   320   |   0.054016   |     -      |     -     |   3.62   \n",
      "   5    |   340   |   0.062669   |     -      |     -     |   3.64   \n",
      "   5    |   360   |   0.074126   |     -      |     -     |   3.63   \n",
      "   5    |   380   |   0.066765   |     -      |     -     |   3.62   \n",
      "   5    |   400   |   0.058052   |     -      |     -     |   3.62   \n",
      "   5    |   420   |   0.073954   |     -      |     -     |   3.62   \n",
      "   5    |   440   |   0.057469   |     -      |     -     |   3.64   \n",
      "   5    |   460   |   0.082785   |     -      |     -     |   3.63   \n",
      "   5    |   480   |   0.038456   |     -      |     -     |   3.60   \n",
      "   5    |   499   |   0.067671   |     -      |     -     |   3.44   \n",
      "----------------------------------------------------------------------\n",
      "   5    |    -    |   0.063967   |  0.230319  |   93.80   |   94.08  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   6    |   20    |   0.030128   |     -      |     -     |   3.80   \n",
      "   6    |   40    |   0.034409   |     -      |     -     |   3.61   \n",
      "   6    |   60    |   0.030761   |     -      |     -     |   3.62   \n",
      "   6    |   80    |   0.028955   |     -      |     -     |   3.61   \n",
      "   6    |   100   |   0.027327   |     -      |     -     |   3.61   \n",
      "   6    |   120   |   0.018980   |     -      |     -     |   3.62   \n",
      "   6    |   140   |   0.047091   |     -      |     -     |   3.61   \n",
      "   6    |   160   |   0.041576   |     -      |     -     |   3.60   \n",
      "   6    |   180   |   0.040946   |     -      |     -     |   3.63   \n",
      "   6    |   200   |   0.024699   |     -      |     -     |   3.62   \n",
      "   6    |   220   |   0.051702   |     -      |     -     |   3.62   \n",
      "   6    |   240   |   0.026055   |     -      |     -     |   3.61   \n",
      "   6    |   260   |   0.053014   |     -      |     -     |   3.63   \n",
      "   6    |   280   |   0.031256   |     -      |     -     |   3.60   \n",
      "   6    |   300   |   0.033999   |     -      |     -     |   3.62   \n",
      "   6    |   320   |   0.052977   |     -      |     -     |   3.64   \n",
      "   6    |   340   |   0.039968   |     -      |     -     |   3.62   \n",
      "   6    |   360   |   0.049184   |     -      |     -     |   3.62   \n",
      "   6    |   380   |   0.049291   |     -      |     -     |   3.61   \n",
      "   6    |   400   |   0.032766   |     -      |     -     |   3.62   \n",
      "   6    |   420   |   0.054835   |     -      |     -     |   3.64   \n",
      "   6    |   440   |   0.039509   |     -      |     -     |   3.63   \n",
      "   6    |   460   |   0.057545   |     -      |     -     |   3.62   \n",
      "   6    |   480   |   0.038726   |     -      |     -     |   3.62   \n",
      "   6    |   499   |   0.024268   |     -      |     -     |   3.43   \n",
      "----------------------------------------------------------------------\n",
      "   6    |    -    |   0.038410   |  0.266688  |   93.85   |   93.97  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   7    |   20    |   0.016859   |     -      |     -     |   3.79   \n",
      "   7    |   40    |   0.038990   |     -      |     -     |   3.62   \n",
      "   7    |   60    |   0.016680   |     -      |     -     |   3.60   \n",
      "   7    |   80    |   0.016961   |     -      |     -     |   3.61   \n",
      "   7    |   100   |   0.016121   |     -      |     -     |   3.61   \n",
      "   7    |   120   |   0.005200   |     -      |     -     |   3.60   \n",
      "   7    |   140   |   0.018135   |     -      |     -     |   3.60   \n",
      "   7    |   160   |   0.051045   |     -      |     -     |   3.62   \n",
      "   7    |   180   |   0.037040   |     -      |     -     |   3.61   \n",
      "   7    |   200   |   0.010624   |     -      |     -     |   3.60   \n",
      "   7    |   220   |   0.030213   |     -      |     -     |   3.62   \n",
      "   7    |   240   |   0.020229   |     -      |     -     |   3.60   \n",
      "   7    |   260   |   0.026272   |     -      |     -     |   3.61   \n",
      "   7    |   280   |   0.012723   |     -      |     -     |   3.60   \n",
      "   7    |   300   |   0.018414   |     -      |     -     |   3.61   \n",
      "   7    |   320   |   0.008846   |     -      |     -     |   3.61   \n",
      "   7    |   340   |   0.023079   |     -      |     -     |   3.61   \n",
      "   7    |   360   |   0.003776   |     -      |     -     |   3.60   \n",
      "   7    |   380   |   0.034138   |     -      |     -     |   3.61   \n",
      "   7    |   400   |   0.021343   |     -      |     -     |   3.60   \n",
      "   7    |   420   |   0.028019   |     -      |     -     |   3.60   \n",
      "   7    |   440   |   0.003103   |     -      |     -     |   3.62   \n",
      "   7    |   460   |   0.044602   |     -      |     -     |   3.63   \n",
      "   7    |   480   |   0.034503   |     -      |     -     |   3.61   \n",
      "   7    |   499   |   0.022557   |     -      |     -     |   3.43   \n",
      "----------------------------------------------------------------------\n",
      "   7    |    -    |   0.022367   |  0.276654  |   93.85   |   93.74  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   8    |   20    |   0.013503   |     -      |     -     |   3.79   \n",
      "   8    |   40    |   0.010415   |     -      |     -     |   3.61   \n",
      "   8    |   60    |   0.004371   |     -      |     -     |   3.81   \n",
      "   8    |   80    |   0.007203   |     -      |     -     |   4.01   \n",
      "   8    |   100   |   0.005901   |     -      |     -     |   4.09   \n",
      "   8    |   120   |   0.009237   |     -      |     -     |   3.86   \n",
      "   8    |   140   |   0.010509   |     -      |     -     |   3.66   \n",
      "   8    |   160   |   0.002873   |     -      |     -     |   3.64   \n",
      "   8    |   180   |   0.018692   |     -      |     -     |   3.66   \n",
      "   8    |   200   |   0.010958   |     -      |     -     |   3.64   \n",
      "   8    |   220   |   0.021754   |     -      |     -     |   3.68   \n",
      "   8    |   240   |   0.006862   |     -      |     -     |   3.66   \n",
      "   8    |   260   |   0.009271   |     -      |     -     |   3.65   \n",
      "   8    |   280   |   0.022536   |     -      |     -     |   3.65   \n",
      "   8    |   300   |   0.009317   |     -      |     -     |   3.64   \n",
      "   8    |   320   |   0.017605   |     -      |     -     |   3.65   \n",
      "   8    |   340   |   0.012422   |     -      |     -     |   3.70   \n",
      "   8    |   360   |   0.020163   |     -      |     -     |   3.64   \n",
      "   8    |   380   |   0.007831   |     -      |     -     |   3.63   \n",
      "   8    |   400   |   0.023510   |     -      |     -     |   3.63   \n",
      "   8    |   420   |   0.021149   |     -      |     -     |   3.65   \n",
      "   8    |   440   |   0.029595   |     -      |     -     |   3.63   \n",
      "   8    |   460   |   0.008880   |     -      |     -     |   3.61   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   8    |   480   |   0.006229   |     -      |     -     |   3.61   \n",
      "   8    |   499   |   0.016093   |     -      |     -     |   3.45   \n",
      "----------------------------------------------------------------------\n",
      "   8    |    -    |   0.013070   |  0.301034  |   94.05   |   95.74  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   9    |   20    |   0.024105   |     -      |     -     |   3.79   \n",
      "   9    |   40    |   0.001508   |     -      |     -     |   3.60   \n",
      "   9    |   60    |   0.001022   |     -      |     -     |   3.60   \n",
      "   9    |   80    |   0.009984   |     -      |     -     |   3.61   \n",
      "   9    |   100   |   0.007413   |     -      |     -     |   3.61   \n",
      "   9    |   120   |   0.021758   |     -      |     -     |   3.61   \n",
      "   9    |   140   |   0.010834   |     -      |     -     |   3.61   \n",
      "   9    |   160   |   0.005984   |     -      |     -     |   3.62   \n",
      "   9    |   180   |   0.002843   |     -      |     -     |   3.60   \n",
      "   9    |   200   |   0.015880   |     -      |     -     |   3.61   \n",
      "   9    |   220   |   0.010727   |     -      |     -     |   3.61   \n",
      "   9    |   240   |   0.010362   |     -      |     -     |   3.62   \n",
      "   9    |   260   |   0.009155   |     -      |     -     |   3.60   \n",
      "   9    |   280   |   0.025571   |     -      |     -     |   3.61   \n",
      "   9    |   300   |   0.004305   |     -      |     -     |   3.61   \n",
      "   9    |   320   |   0.009077   |     -      |     -     |   3.61   \n",
      "   9    |   340   |   0.017492   |     -      |     -     |   3.61   \n",
      "   9    |   360   |   0.011064   |     -      |     -     |   3.61   \n",
      "   9    |   380   |   0.006007   |     -      |     -     |   3.60   \n",
      "   9    |   400   |   0.008655   |     -      |     -     |   3.61   \n",
      "   9    |   420   |   0.009139   |     -      |     -     |   3.61   \n",
      "   9    |   440   |   0.008976   |     -      |     -     |   3.62   \n",
      "   9    |   460   |   0.001120   |     -      |     -     |   3.61   \n",
      "   9    |   480   |   0.015789   |     -      |     -     |   3.63   \n",
      "   9    |   499   |   0.009635   |     -      |     -     |   3.44   \n",
      "----------------------------------------------------------------------\n",
      "   9    |    -    |   0.010365   |  0.338670  |   94.05   |   93.76  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "  10    |   20    |   0.009948   |     -      |     -     |   3.87   \n",
      "  10    |   40    |   0.004033   |     -      |     -     |   3.68   \n",
      "  10    |   60    |   0.005581   |     -      |     -     |   3.65   \n",
      "  10    |   80    |   0.002622   |     -      |     -     |   3.61   \n",
      "  10    |   100   |   0.019866   |     -      |     -     |   3.68   \n",
      "  10    |   120   |   0.012541   |     -      |     -     |   3.62   \n",
      "  10    |   140   |   0.002138   |     -      |     -     |   3.61   \n",
      "  10    |   160   |   0.003649   |     -      |     -     |   3.62   \n",
      "  10    |   180   |   0.002703   |     -      |     -     |   3.63   \n",
      "  10    |   200   |   0.005422   |     -      |     -     |   3.65   \n",
      "  10    |   220   |   0.014280   |     -      |     -     |   3.64   \n",
      "  10    |   240   |   0.011113   |     -      |     -     |   3.66   \n",
      "  10    |   260   |   0.013100   |     -      |     -     |   3.69   \n",
      "  10    |   280   |   0.025083   |     -      |     -     |   3.66   \n",
      "  10    |   300   |   0.007446   |     -      |     -     |   3.69   \n",
      "  10    |   320   |   0.004432   |     -      |     -     |   3.68   \n",
      "  10    |   340   |   0.016174   |     -      |     -     |   3.65   \n",
      "  10    |   360   |   0.009393   |     -      |     -     |   3.65   \n",
      "  10    |   380   |   0.003786   |     -      |     -     |   3.66   \n",
      "  10    |   400   |   0.005511   |     -      |     -     |   3.65   \n",
      "  10    |   420   |   0.000916   |     -      |     -     |   3.68   \n",
      "  10    |   440   |   0.003690   |     -      |     -     |   3.62   \n",
      "  10    |   460   |   0.002096   |     -      |     -     |   3.61   \n",
      "  10    |   480   |   0.010156   |     -      |     -     |   3.61   \n",
      "  10    |   499   |   0.015439   |     -      |     -     |   3.43   \n",
      "----------------------------------------------------------------------\n",
      "  10    |    -    |   0.008434   |  0.337087  |   93.75   |   94.68  \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=10)\n",
    "train(bert_classifier, train_dataloader, val_dataloader, epochs=10, evaluation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4425, -1.2383,  0.5189, -0.4659, -0.6504],\n",
      "        [ 0.3995,  0.0748, -0.3477, -2.0204, -1.4760],\n",
      "        [-0.7025,  0.5460, -0.2742,  1.1410, -1.3207]], requires_grad=True)\n",
      "tensor([3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.empty(3, dtype=torch.long).random_(5)\n",
    "print(input)\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    preds = probs[:, 1]\n",
    "    fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'AUC: {roc_auc:.4f}')\n",
    "       \n",
    "    # Get accuracy over the test set\n",
    "    y_pred = np.where(preds >= 0.5, 1, 0)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "    \n",
    "    # Plot ROC AUC\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "    \n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits, dim=1).cpu().numpy()\n",
    "\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-e481a2ef1bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Evaluate the Bert classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mevaluate_roc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-53-bde1be800687>\u001b[0m in \u001b[0;36mevaluate_roc\u001b[0;34m(probs, y_true)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \"\"\"\n\u001b[1;32m     10\u001b[0m     \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'AUC: {roc_auc:.4f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \"\"\"\n\u001b[0;32m--> 775\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    776\u001b[0m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[1;32m    777\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    537\u001b[0m     if not (y_type == \"binary\" or\n\u001b[1;32m    538\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[0;32m--> 539\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, val_dataloader)\n",
    "\n",
    "# Evaluate the Bert classifier\n",
    "evaluate_roc(probs, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |   20    |   0.395516   |     -      |     -     |   2.92   \n",
      "   1    |   40    |   0.076552   |     -      |     -     |   2.74   \n",
      "   1    |   60    |   0.041534   |     -      |     -     |   2.72   \n",
      "   1    |   80    |   0.056735   |     -      |     -     |   2.75   \n",
      "   1    |   100   |   0.047529   |     -      |     -     |   2.70   \n",
      "   1    |   120   |   0.029075   |     -      |     -     |   2.72   \n",
      "   1    |   140   |   0.017800   |     -      |     -     |   2.71   \n",
      "   1    |   160   |   0.021259   |     -      |     -     |   2.71   \n",
      "   1    |   180   |   0.023377   |     -      |     -     |   2.70   \n",
      "   1    |   200   |   0.035580   |     -      |     -     |   2.69   \n",
      "   1    |   220   |   0.025894   |     -      |     -     |   2.70   \n",
      "   1    |   240   |   0.041768   |     -      |     -     |   2.72   \n",
      "   1    |   260   |   0.014341   |     -      |     -     |   2.72   \n",
      "   1    |   280   |   0.011376   |     -      |     -     |   2.71   \n",
      "   1    |   300   |   0.016533   |     -      |     -     |   2.72   \n",
      "   1    |   320   |   0.004703   |     -      |     -     |   2.72   \n",
      "   1    |   340   |   0.020214   |     -      |     -     |   2.73   \n",
      "   1    |   360   |   0.048679   |     -      |     -     |   2.74   \n",
      "   1    |   380   |   0.049293   |     -      |     -     |   2.72   \n",
      "   1    |   400   |   0.020120   |     -      |     -     |   2.72   \n",
      "   1    |   420   |   0.032923   |     -      |     -     |   2.72   \n",
      "   1    |   440   |   0.036409   |     -      |     -     |   2.73   \n",
      "   1    |   460   |   0.024441   |     -      |     -     |   2.74   \n",
      "   1    |   480   |   0.047097   |     -      |     -     |   2.74   \n",
      "   1    |   500   |   0.036398   |     -      |     -     |   2.73   \n",
      "   1    |   520   |   0.021526   |     -      |     -     |   2.72   \n",
      "   1    |   540   |   0.016162   |     -      |     -     |   2.73   \n",
      "   1    |   560   |   0.007679   |     -      |     -     |   2.73   \n",
      "   1    |   580   |   0.020263   |     -      |     -     |   2.74   \n",
      "   1    |   600   |   0.001832   |     -      |     -     |   2.73   \n",
      "   1    |   620   |   0.004811   |     -      |     -     |   2.73   \n",
      "   1    |   640   |   0.009038   |     -      |     -     |   2.73   \n",
      "   1    |   660   |   0.013796   |     -      |     -     |   2.76   \n",
      "   1    |   680   |   0.034352   |     -      |     -     |   2.77   \n",
      "   1    |   700   |   0.004024   |     -      |     -     |   2.76   \n",
      "   1    |   720   |   0.012922   |     -      |     -     |   2.76   \n",
      "   1    |   740   |   0.020312   |     -      |     -     |   2.75   \n",
      "   1    |   760   |   0.025714   |     -      |     -     |   2.74   \n",
      "   1    |   780   |   0.030863   |     -      |     -     |   2.75   \n",
      "   1    |   800   |   0.020861   |     -      |     -     |   2.74   \n",
      "   1    |   820   |   0.001899   |     -      |     -     |   2.74   \n",
      "   1    |   840   |   0.008741   |     -      |     -     |   2.73   \n",
      "   1    |   860   |   0.009669   |     -      |     -     |   2.75   \n",
      "   1    |   880   |   0.002423   |     -      |     -     |   2.75   \n",
      "   1    |   900   |   0.010641   |     -      |     -     |   2.75   \n",
      "   1    |   920   |   0.019522   |     -      |     -     |   2.75   \n",
      "   1    |   940   |   0.041712   |     -      |     -     |   2.76   \n",
      "   1    |   960   |   0.029445   |     -      |     -     |   2.76   \n",
      "   1    |   968   |   0.001423   |     -      |     -     |   1.07   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |   20    |   0.022635   |     -      |     -     |   2.88   \n",
      "   2    |   40    |   0.010394   |     -      |     -     |   2.73   \n",
      "   2    |   60    |   0.001368   |     -      |     -     |   2.76   \n",
      "   2    |   80    |   0.004448   |     -      |     -     |   2.73   \n",
      "   2    |   100   |   0.014046   |     -      |     -     |   2.74   \n",
      "   2    |   120   |   0.022355   |     -      |     -     |   2.75   \n",
      "   2    |   140   |   0.007386   |     -      |     -     |   2.75   \n",
      "   2    |   160   |   0.001190   |     -      |     -     |   2.73   \n",
      "   2    |   180   |   0.008168   |     -      |     -     |   2.74   \n",
      "   2    |   200   |   0.007849   |     -      |     -     |   2.75   \n",
      "   2    |   220   |   0.013681   |     -      |     -     |   2.75   \n",
      "   2    |   240   |   0.002247   |     -      |     -     |   2.74   \n",
      "   2    |   260   |   0.005043   |     -      |     -     |   2.75   \n",
      "   2    |   280   |   0.005906   |     -      |     -     |   2.74   \n",
      "   2    |   300   |   0.001395   |     -      |     -     |   2.73   \n",
      "   2    |   320   |   0.016739   |     -      |     -     |   2.72   \n",
      "   2    |   340   |   0.011128   |     -      |     -     |   2.76   \n",
      "   2    |   360   |   0.001008   |     -      |     -     |   2.77   \n",
      "   2    |   380   |   0.001785   |     -      |     -     |   2.76   \n",
      "   2    |   400   |   0.017156   |     -      |     -     |   2.78   \n",
      "   2    |   420   |   0.000829   |     -      |     -     |   2.76   \n",
      "   2    |   440   |   0.006234   |     -      |     -     |   2.75   \n",
      "   2    |   460   |   0.011082   |     -      |     -     |   2.76   \n",
      "   2    |   480   |   0.000804   |     -      |     -     |   2.76   \n",
      "   2    |   500   |   0.014691   |     -      |     -     |   2.76   \n",
      "   2    |   520   |   0.000900   |     -      |     -     |   2.76   \n",
      "   2    |   540   |   0.009648   |     -      |     -     |   2.78   \n",
      "   2    |   560   |   0.017215   |     -      |     -     |   2.77   \n",
      "   2    |   580   |   0.021357   |     -      |     -     |   2.78   \n",
      "   2    |   600   |   0.017723   |     -      |     -     |   2.78   \n",
      "   2    |   620   |   0.001437   |     -      |     -     |   2.77   \n",
      "   2    |   640   |   0.010750   |     -      |     -     |   2.76   \n",
      "   2    |   660   |   0.018236   |     -      |     -     |   2.75   \n",
      "   2    |   680   |   0.000928   |     -      |     -     |   2.72   \n",
      "   2    |   700   |   0.000849   |     -      |     -     |   2.72   \n",
      "   2    |   720   |   0.009824   |     -      |     -     |   2.72   \n",
      "   2    |   740   |   0.000966   |     -      |     -     |   2.72   \n",
      "   2    |   760   |   0.000865   |     -      |     -     |   2.76   \n",
      "   2    |   780   |   0.001749   |     -      |     -     |   2.82   \n",
      "   2    |   800   |   0.006811   |     -      |     -     |   2.83   \n",
      "   2    |   820   |   0.018041   |     -      |     -     |   2.85   \n",
      "   2    |   840   |   0.001026   |     -      |     -     |   2.83   \n",
      "   2    |   860   |   0.008036   |     -      |     -     |   2.81   \n",
      "   2    |   880   |   0.001089   |     -      |     -     |   2.81   \n",
      "   2    |   900   |   0.011780   |     -      |     -     |   2.86   \n",
      "   2    |   920   |   0.000943   |     -      |     -     |   2.79   \n",
      "   2    |   940   |   0.037164   |     -      |     -     |   2.76   \n",
      "   2    |   960   |   0.012237   |     -      |     -     |   2.76   \n",
      "   2    |   968   |   0.000756   |     -      |     -     |   1.08   \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the train set and the validation set\n",
    "full_train_data = torch.utils.data.ConcatDataset([train_data, val_data])\n",
    "full_train_sampler = RandomSampler(full_train_data)\n",
    "full_train_dataloader = DataLoader(full_train_data, sampler=full_train_sampler, batch_size=32)\n",
    "\n",
    "# Train the Bert Classifier on the entire training data\n",
    "set_seed(42)\n",
    "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "train(bert_classifier, full_train_dataloader, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>i feel so dirty but after spending a day at th...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>i could feel his breath on me and smell the sw...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1333</th>\n",
       "      <td>i just want to feel loved by you</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>i have felt the need to write out my sometimes...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1289</th>\n",
       "      <td>at a party i met a girl who drew me to her</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input Sentiment\n",
       "1860  i feel so dirty but after spending a day at th...   sadness\n",
       "353   i could feel his breath on me and smell the sw...       joy\n",
       "1333                   i just want to feel loved by you      love\n",
       "905   i have felt the need to write out my sometimes...     anger\n",
       "1289         at a party i met a girl who drew me to her     anger"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/psimilan/anaconda3/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2136: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Run `preprocessing_for_bert` on the test set\n",
    "print('Tokenizing data...')\n",
    "test_inputs, test_masks = preprocessing_for_bert(df_test['Input'].values)\n",
    "\n",
    "# Create the DataLoader for our test set\n",
    "test_dataset = TensorDataset(test_inputs, test_masks)\n",
    "test_sampler = SequentialSampler(test_dataset)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets predicted non-negative:  [0 0 0 ... 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(bert_classifier, test_dataloader)\n",
    "\n",
    "# Get predictions from the probabilities\n",
    "threshold = 0.000135\n",
    "preds = np.where(probs[:, 1] > threshold, 1, 0)\n",
    "\n",
    "# Number of tweets predicted non-negative\n",
    "print(\"Number of tweets predicted non-negative: \", preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({'joy': 695, 'sadness': 581, 'anger': 275, 'fear': 224, 'love': 159, 'surprise': 66})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(\"Balanced Checking: \", Counter(df_test['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.61799131e-05 3.20299005e-05 5.06104443e-05 3.41443920e-05\n",
      "  9.99780715e-01 3.63394502e-05]\n",
      " [6.03461631e-05 3.68089532e-05 2.72166490e-05 3.08095223e-05\n",
      "  9.99802530e-01 4.23386555e-05]\n",
      " [6.10930656e-05 3.28891365e-05 2.76123556e-05 3.32480813e-05\n",
      "  9.99805987e-01 3.91205976e-05]\n",
      " ...\n",
      " [4.14003480e-05 3.83911502e-05 9.99844551e-01 4.57402093e-05\n",
      "  1.00497555e-05 1.98572088e-05]\n",
      " [4.22703451e-05 4.98949703e-05 9.99835730e-01 4.18460259e-05\n",
      "  1.15720168e-05 1.86609686e-05]\n",
      " [2.63132178e-03 8.87321591e-01 1.28139579e-03 3.57865880e-04\n",
      "  9.94306174e-04 1.07413530e-01]]\n",
      "[4 4 4 ... 2 2 1]\n",
      "[4, 4, 4, 2, 4, 1, 0, 2, 2, 0, 1, 4, 1, 2, 3, 4, 2, 4, 0, 2, 4, 2, 2, 4, 4, 1, 0, 4, 1, 0, 1, 0, 4, 0, 4, 2, 2, 4, 2, 2, 0, 4, 2, 4, 2, 0, 2, 2, 1, 1, 4, 1, 2, 4, 2, 4, 4, 2, 4, 0, 4, 4, 2, 2, 4, 5, 4, 0, 1, 5, 2, 3, 5, 2, 3, 0, 2, 4, 2, 3, 2, 0, 4, 2, 4, 4, 2, 2, 2, 4, 2, 1, 0, 1, 0, 0, 3, 4, 0, 4, 4, 4, 4, 1, 0, 0, 2, 2, 1, 4, 2, 3, 1, 2, 4, 2, 2, 1, 4, 2, 4, 2, 4, 0, 4, 3, 4, 1, 4, 4, 2, 3, 4, 0, 0, 2, 1, 0, 4, 2, 2, 4, 1, 2, 2, 4, 2, 1, 1, 3, 4, 3, 5, 4, 2, 4, 2, 2, 0, 4, 0, 0, 2, 1, 1, 2, 3, 3, 3, 4, 3, 0, 2, 2, 4, 0, 2, 2, 4, 4, 1, 2, 4, 3, 1, 4, 2, 2, 1, 0, 2, 4, 2, 0, 4, 4, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 3, 1, 1, 2, 0, 4, 2, 1, 2, 4, 0, 4, 0, 0, 2, 1, 5, 2, 2, 2, 0, 2, 3, 1, 4, 4, 2, 2, 1, 2, 4, 2, 4, 2, 4, 3, 1, 2, 4, 4, 4, 0, 2, 5, 4, 4, 4, 0, 3, 4, 2, 2, 4, 0, 0, 0, 2, 0, 0, 3, 2, 2, 0, 4, 0, 0, 1, 4, 0, 4, 2, 1, 0, 4, 2, 4, 4, 2, 2, 2, 3, 4, 2, 2, 5, 1, 3, 4, 3, 1, 0, 4, 4, 0, 2, 0, 3, 3, 2, 1, 0, 3, 1, 1, 2, 4, 1, 2, 4, 0, 3, 5, 0, 1, 4, 4, 4, 2, 4, 4, 3, 0, 4, 4, 1, 4, 4, 3, 4, 2, 4, 2, 2, 4, 0, 3, 5, 2, 2, 2, 2, 1, 1, 2, 4, 4, 4, 2, 2, 3, 3, 4, 4, 2, 0, 4, 4, 0, 2, 2, 3, 4, 0, 3, 4, 2, 2, 0, 2, 4, 2, 4, 0, 4, 1, 0, 5, 1, 2, 0, 0, 1, 2, 4, 4, 3, 4, 4, 1, 4, 0, 2, 4, 1, 1, 2, 5, 4, 3, 2, 2, 4, 2, 4, 1, 0, 2, 2, 0, 2, 1, 4, 0, 1, 2, 1, 1, 2, 4, 2, 4, 2, 0, 1, 0, 4, 1, 1, 1, 4, 2, 0, 0, 4, 2, 5, 0, 4, 4, 2, 4, 4, 2, 0, 4, 0, 4, 4, 1, 4, 2, 1, 2, 0, 1, 2, 4, 4, 4, 2, 3, 4, 4, 5, 1, 4, 2, 2, 0, 2, 4, 0, 2, 1, 4, 4, 0, 2, 2, 4, 1, 0, 2, 2, 2, 4, 2, 1, 2, 2, 2, 4, 2, 1, 0, 0, 0, 2, 2, 2, 4, 0, 4, 4, 2, 2, 2, 3, 1, 2, 2, 2, 0, 2, 3, 4, 1, 0, 2, 4, 1, 4, 0, 3, 2, 2, 2, 2, 2, 3, 1, 0, 2, 4, 2, 2, 2, 5, 4, 0, 2, 2, 2, 4, 2, 4, 5, 4, 2, 2, 4, 0, 2, 2, 2, 0, 4, 2, 0, 4, 4, 4, 4, 2, 2, 4, 2, 4, 3, 3, 2, 0, 1, 2, 2, 2, 4, 2, 4, 1, 4, 4, 4, 2, 1, 4, 4, 3, 4, 3, 5, 2, 4, 1, 4, 0, 4, 0, 0, 4, 2, 2, 3, 2, 0, 4, 2, 5, 3, 3, 4, 2, 2, 2, 4, 3, 2, 1, 0, 5, 1, 3, 2, 3, 3, 2, 1, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 3, 2, 2, 2, 2, 0, 4, 3, 2, 4, 2, 2, 2, 4, 0, 1, 2, 0, 4, 0, 4, 0, 0, 1, 4, 1, 4, 3, 5, 2, 2, 2, 2, 0, 4, 2, 4, 4, 5, 2, 4, 4, 1, 4, 1, 4, 4, 4, 4, 1, 4, 1, 2, 4, 1, 0, 2, 0, 2, 4, 4, 4, 5, 2, 2, 2, 4, 4, 0, 4, 3, 1, 3, 2, 1, 0, 2, 2, 1, 2, 2, 0, 4, 1, 4, 2, 2, 2, 4, 4, 2, 4, 3, 4, 1, 0, 0, 2, 2, 2, 4, 2, 2, 3, 2, 4, 4, 4, 2, 2, 4, 1, 4, 2, 0, 2, 2, 2, 2, 0, 2, 4, 3, 3, 0, 4, 0, 2, 2, 0, 2, 4, 2, 4, 4, 2, 2, 1, 2, 2, 0, 4, 2, 2, 2, 2, 2, 2, 4, 1, 2, 2, 5, 4, 2, 4, 2, 2, 2, 3, 4, 4, 2, 4, 4, 2, 4, 0, 4, 2, 5, 2, 2, 0, 4, 4, 2, 5, 3, 0, 0, 1, 2, 4, 4, 1, 4, 1, 2, 1, 3, 1, 4, 0, 4, 4, 4, 2, 4, 2, 2, 5, 2, 4, 4, 1, 2, 4, 4, 2, 2, 4, 4, 4, 2, 4, 2, 4, 1, 4, 0, 2, 4, 4, 2, 4, 3, 2, 1, 4, 4, 2, 5, 4, 2, 2, 5, 1, 0, 4, 1, 4, 2, 3, 4, 3, 2, 3, 2, 0, 2, 3, 3, 2, 2, 4, 2, 0, 2, 1, 2, 4, 0, 4, 0, 4, 3, 4, 2, 4, 2, 2, 4, 1, 2, 4, 4, 2, 4, 0, 3, 0, 2, 4, 1, 2, 2, 0, 2, 4, 0, 2, 4, 3, 0, 2, 2, 2, 1, 1, 4, 4, 5, 4, 4, 2, 4, 4, 2, 2, 4, 1, 2, 2, 3, 2, 3, 3, 4, 4, 2, 2, 4, 2, 0, 0, 5, 0, 2, 2, 0, 4, 2, 0, 1, 3, 0, 2, 4, 3, 4, 0, 3, 2, 2, 2, 4, 4, 4, 3, 2, 3, 1, 5, 2, 2, 4, 2, 2, 0, 2, 0, 2, 1, 0, 4, 2, 1, 2, 2, 3, 4, 3, 4, 3, 1, 2, 4, 0, 4, 2, 1, 0, 4, 1, 2, 4, 2, 0, 4, 0, 4, 2, 2, 4, 1, 2, 1, 2, 2, 4, 2, 4, 0, 2, 5, 5, 2, 5, 2, 0, 5, 2, 4, 2, 4, 3, 4, 3, 1, 2, 3, 4, 2, 0, 2, 2, 5, 4, 3, 2, 0, 4, 4, 2, 0, 0, 4, 3, 0, 3, 4, 0, 4, 2, 4, 2, 1, 0, 3, 4, 4, 1, 4, 0, 4, 0, 5, 0, 4, 4, 1, 2, 4, 2, 1, 0, 4, 3, 1, 0, 2, 4, 2, 3, 4, 0, 4, 0, 2, 3, 4, 4, 2, 4, 2, 2, 0, 4, 2, 1, 4, 4, 2, 4, 0, 2, 2, 0, 2, 4, 0, 2, 3, 2, 2, 0, 4, 4, 2, 4, 2, 4, 2, 2, 0, 2, 2, 2, 1, 2, 0, 2, 4, 4, 1, 2, 2, 2, 1, 1, 2, 4, 2, 0, 3, 2, 1, 5, 2, 2, 0, 5, 4, 5, 4, 4, 0, 4, 4, 4, 3, 4, 4, 4, 1, 2, 0, 4, 5, 4, 4, 5, 2, 3, 4, 2, 2, 4, 4, 4, 4, 2, 3, 2, 2, 2, 2, 2, 4, 4, 4, 4, 2, 4, 2, 2, 2, 2, 0, 2, 5, 0, 4, 4, 4, 2, 5, 4, 4, 4, 2, 3, 4, 2, 2, 4, 4, 2, 0, 5, 4, 2, 1, 0, 1, 4, 2, 1, 2, 4, 2, 2, 1, 2, 2, 2, 2, 2, 2, 5, 2, 5, 2, 2, 1, 1, 2, 0, 0, 2, 4, 4, 2, 1, 4, 0, 4, 2, 4, 4, 1, 4, 1, 4, 4, 0, 0, 3, 2, 2, 4, 1, 5, 2, 5, 2, 2, 2, 1, 2, 5, 2, 2, 2, 4, 0, 0, 1, 1, 2, 2, 1, 4, 0, 2, 4, 2, 2, 2, 3, 4, 4, 2, 4, 4, 4, 3, 4, 2, 2, 4, 2, 3, 3, 2, 1, 2, 2, 0, 2, 0, 1, 2, 2, 3, 2, 2, 2, 2, 2, 1, 4, 4, 1, 4, 2, 3, 0, 4, 2, 4, 4, 0, 3, 4, 2, 2, 3, 5, 4, 1, 2, 3, 3, 2, 2, 2, 2, 2, 4, 5, 3, 4, 0, 1, 0, 2, 0, 3, 1, 4, 0, 2, 2, 2, 1, 2, 2, 1, 0, 4, 4, 2, 2, 2, 0, 1, 1, 4, 4, 0, 1, 0, 2, 2, 2, 4, 4, 2, 4, 2, 4, 3, 4, 4, 4, 2, 1, 1, 4, 2, 1, 4, 2, 2, 2, 2, 5, 0, 4, 2, 4, 4, 2, 3, 2, 2, 2, 4, 3, 1, 5, 2, 1, 2, 1, 0, 4, 2, 2, 4, 4, 3, 1, 3, 2, 2, 2, 4, 4, 0, 5, 2, 2, 3, 4, 2, 0, 1, 2, 4, 2, 1, 3, 2, 0, 2, 2, 2, 4, 4, 4, 2, 0, 1, 1, 0, 4, 2, 3, 2, 2, 2, 1, 2, 4, 2, 4, 4, 0, 3, 2, 2, 4, 1, 2, 0, 1, 2, 0, 1, 0, 2, 2, 2, 2, 4, 3, 0, 0, 2, 3, 4, 4, 4, 2, 2, 4, 1, 2, 4, 4, 0, 4, 2, 2, 4, 1, 2, 1, 4, 0, 2, 4, 2, 4, 0, 3, 1, 2, 4, 1, 1, 1, 4, 2, 4, 4, 4, 2, 0, 2, 0, 4, 3, 2, 2, 0, 3, 4, 2, 4, 4, 2, 0, 5, 4, 2, 0, 4, 2, 4, 1, 2, 2, 1, 1, 2, 0, 2, 2, 4, 0, 2, 1, 2, 2, 4, 4, 2, 1, 0, 0, 4, 0, 0, 2, 4, 1, 1, 5, 2, 2, 5, 2, 2, 2, 0, 3, 1, 4, 4, 2, 2, 2, 0, 3, 4, 2, 1, 0, 1, 2, 1, 4, 4, 4, 4, 2, 4, 4, 4, 4, 0, 4, 4, 2, 2, 2, 1, 2, 0, 4, 1, 0, 4, 3, 0, 4, 2, 3, 3, 2, 2, 2, 2, 4, 0, 2, 2, 2, 0, 4, 4, 4, 0, 2, 3, 4, 2, 4, 2, 4, 2, 2, 3, 0, 2, 0, 4, 3, 4, 1, 2, 1, 2, 4, 5, 2, 0, 2, 0, 2, 2, 4, 2, 0, 3, 3, 2, 5, 1, 1, 0, 0, 3, 1, 0, 4, 1, 4, 3, 2, 1, 0, 4, 2, 4, 4, 2, 2, 4, 3, 2, 2, 4, 1, 2, 1, 2, 2, 3, 2, 2, 4, 2, 2, 4, 2, 2, 5, 5, 2, 2, 4, 4, 0, 4, 2, 0, 1, 1, 2, 4, 1, 4, 4, 5, 4, 2, 0, 4, 4, 5, 4, 2, 2, 2, 4, 4, 4, 4, 4, 2, 1, 0, 1, 1, 4, 4, 4, 2, 4, 2, 3, 0, 4, 4, 2, 0, 2, 2, 2, 4, 4, 1, 2, 2, 0, 3, 2, 0, 3, 4, 4, 2, 2, 4, 2, 2, 3, 2, 4, 2, 2, 3, 2, 3, 2, 1, 2, 4, 0, 2, 0, 2, 4, 2, 0, 2, 4, 4, 2, 4, 0, 2, 2, 1, 2, 2, 1, 2, 0, 1, 4, 4, 2, 4, 2, 2, 4, 2, 4, 2, 2, 3, 0, 2, 0, 4, 2, 4, 4, 4, 2, 3, 4, 4, 3, 4, 2, 4, 4, 0, 4, 0, 2, 5, 1, 0, 2, 2, 2, 0, 4, 4, 2, 2, 4, 4, 2, 5, 4, 4, 1, 0, 4, 2, 4, 2, 2, 1, 3, 4, 0, 2, 4, 2, 1, 4, 2, 3, 0, 4, 4, 2, 4, 2, 1, 2, 4, 4, 2, 5, 2, 2, 4, 3, 2, 2, 4, 4, 2, 2, 4, 3, 3, 2, 2, 2, 0, 1, 2, 4, 4, 0, 4, 0, 0, 4, 0, 2, 1, 4, 4, 4, 3, 3, 0, 0, 4, 0, 0, 2, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "y_test = [encoding[key] for key in df_test['Sentiment'].values]\n",
    "labels = np.argmax(probs, axis=-1)\n",
    "print(probs)\n",
    "print(labels)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 92.85%\n",
      "F1 Score: 92.81\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       275\n",
      "           1       0.88      0.91      0.89       224\n",
      "           2       0.94      0.95      0.95       695\n",
      "           3       0.82      0.81      0.81       159\n",
      "           4       0.97      0.97      0.97       581\n",
      "           5       0.81      0.71      0.76        66\n",
      "\n",
      "    accuracy                           0.93      2000\n",
      "   macro avg       0.89      0.88      0.88      2000\n",
      "weighted avg       0.93      0.93      0.93      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "y_test = [encoding[key] for key in df_test['Sentiment'].values]\n",
    "preds = np.argmax(probs, axis=-1)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "f1 = f1_score(y_test, preds, average='weighted')\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"F1 Score: %.2f\" % (f1*100))\n",
    "\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/Fine-Tuning_BERT-Emotion.h5', 'wb') as model:\n",
    "    pickle.dump(bert_classifier, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
