{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depression Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>damn taking this personality quiz and realizin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remember experiencing as kid what now realize ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>damn louis really did pull me out of my depres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>my depression is really kicking my ass right n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>feel like my night is going bad family calling...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30995</th>\n",
       "      <td>dnc puppet is claiming she wants to put god am...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30996</th>\n",
       "      <td>as soon as my election job is over ll be back ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30997</th>\n",
       "      <td>the moral of the story is you gotta get it fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30998</th>\n",
       "      <td>got through my hardest week this semester and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30999</th>\n",
       "      <td>lately ve been trying to make an effort to tak...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets   Label\n",
       "0      damn taking this personality quiz and realizin...       1\n",
       "1      remember experiencing as kid what now realize ...       1\n",
       "2      damn louis really did pull me out of my depres...       1\n",
       "3      my depression is really kicking my ass right n...       1\n",
       "4      feel like my night is going bad family calling...       1\n",
       "...                                                  ...     ...\n",
       "30995  dnc puppet is claiming she wants to put god am...       0\n",
       "30996  as soon as my election job is over ll be back ...       0\n",
       "30997  the moral of the story is you gotta get it fir...       0\n",
       "30998  got through my hardest week this semester and ...       0\n",
       "30999  lately ve been trying to make an effort to tak...       0\n",
       "\n",
       "[31000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_train = pd.read_csv('train2Data.csv')\n",
    "depression_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>31000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.516129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.499748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Label\n",
       "count  31000.000000\n",
       "mean       0.516129\n",
       "std        0.499748\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        1.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['damn taking this personality quiz and realizing have severe depression'],\n",
       "       ['remember experiencing as kid what now realize was clinical depression and at the time not knowing how to identify what was feeling other than just don want anything complete and utter lack of desire to exist or do damn thing'],\n",
       "       ['damn louis really did pull me out of my depression painting for the first time in months'],\n",
       "       ['my depression is really kicking my ass right now so damn tired'],\n",
       "       ['feel like my night is going bad family calling me grumpy and whiny like so damn sorry for having depression'],\n",
       "       ['im really trying to embrace it my depression needs to take vacation for scorpio season damn'],\n",
       "       ['please my mom put me on strict no carb diet know im fatass but damn bitch wants to eat her depression away'],\n",
       "       ['being on my medication has helped me so much like literally have the worst memory have adhd depression anxiety and ve had ptsd so all this has made my memory go to crap but now thanks to my medication can actually recall things like damn this is different'],\n",
       "       ['healthy amount of depression helps with weight loss patiently waiting for someone son to break my heart these last ten pounds killer'],\n",
       "       ['oh man thats really rough its so hard to manage stress depression and anxiety its damn near impossible when your physical needs are not being me solidarity friend']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['damn taking this personality quiz and realizing have severe depression']\n",
      " ['remember experiencing as kid what now realize was clinical depression and at the time not knowing how to identify what was feeling other than just don want anything complete and utter lack of desire to exist or do damn thing']\n",
      " ['damn louis really did pull me out of my depression painting for the first time in months']\n",
      " ...\n",
      " ['the moral of the story is you gotta get it first like child certificate when woman gives birth it would be on record to help blacks but they only interested in keeping us back making promises after he gets elected is like car loan you wanted amp got rejected']\n",
      " ['got through my hardest week this semester and feel confident on the rest of the year']\n",
      " ['lately ve been trying to make an effort to take note of positives and good all there are lot of good people in the world']]\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "30995    0\n",
      "30996    0\n",
      "30997    0\n",
      "30998    0\n",
      "30999    0\n",
      "Name:  Label, Length: 31000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = depression_train.iloc[:,:-1]\n",
    "y_train = depression_train.iloc[:,-1]\n",
    "print(X_train.values)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({1: 16000, 0: 15000})\n",
      "Label 0: 48.39%\n",
      "Label 1: 51.61%\n"
     ]
    }
   ],
   "source": [
    "y_train_dict = Counter(y_train)\n",
    "total = sum(y_train_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_train))\n",
    "print(\"Label 0: %.2f%%\" % (y_train_dict.get(0)*100 / total))\n",
    "print(\"Label 1: %.2f%%\" % (y_train_dict.get(1)*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>just know what ur going through battle depress...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wow depression and anxiety really tryna come f...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you aint making joke about someones depression...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>why do insta meme pages post videos of naked w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cant handle school anymore but hate in person ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30995</th>\n",
       "      <td>the only way they can attract good dicks is to...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30996</th>\n",
       "      <td>gotta say like you think we have the same atti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30997</th>\n",
       "      <td>many product companies goes from right to left...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30998</th>\n",
       "      <td>just casually playing animal crossing while wa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30999</th>\n",
       "      <td>in kushner speak look wasn born with silver sp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets   Label\n",
       "0      just know what ur going through battle depress...       1\n",
       "1      wow depression and anxiety really tryna come f...       1\n",
       "2      you aint making joke about someones depression...       1\n",
       "3      why do insta meme pages post videos of naked w...       1\n",
       "4      cant handle school anymore but hate in person ...       1\n",
       "...                                                  ...     ...\n",
       "30995  the only way they can attract good dicks is to...       0\n",
       "30996  gotta say like you think we have the same atti...       0\n",
       "30997  many product companies goes from right to left...       0\n",
       "30998  just casually playing animal crossing while wa...       0\n",
       "30999  in kushner speak look wasn born with silver sp...       0\n",
       "\n",
       "[31000 rows x 2 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression_test = pd.read_csv('test2Data.csv')\n",
    "depression_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Tweets\n",
      "0      just know what ur going through battle depress...\n",
      "1      wow depression and anxiety really tryna come f...\n",
      "2      you aint making joke about someones depression...\n",
      "3      why do insta meme pages post videos of naked w...\n",
      "4      cant handle school anymore but hate in person ...\n",
      "...                                                  ...\n",
      "30995  the only way they can attract good dicks is to...\n",
      "30996  gotta say like you think we have the same atti...\n",
      "30997  many product companies goes from right to left...\n",
      "30998  just casually playing animal crossing while wa...\n",
      "30999  in kushner speak look wasn born with silver sp...\n",
      "\n",
      "[31000 rows x 1 columns]\n",
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "30995    0\n",
      "30996    0\n",
      "30997    0\n",
      "30998    0\n",
      "30999    0\n",
      "Name:  Label, Length: 31000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_test = depression_test.iloc[:,:-1]\n",
    "y_test = depression_test.iloc[:,-1]\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({1: 16000, 0: 15000})\n",
      "Label 0: 48.39%\n",
      "Label 1: 51.61%\n"
     ]
    }
   ],
   "source": [
    "y_test_dict = Counter(y_test)\n",
    "total = sum(y_test_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_test))\n",
    "print(\"Label 0: %.2f%%\" % (y_test_dict.get(0)*100 / total))\n",
    "print(\"Label 1: %.2f%%\" % (y_test_dict.get(1)*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in depression_train['Tweets'].values])\n",
    "X_test_preprocessed = np.array([text_preprocessing(text) for text in depression_test['Tweets'].values])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3), smooth_idf=False)\n",
    "\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = tf_idf.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train_tfidf, depression_train[' Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = depression_test[' Label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.18%\n",
      "F1 Score: 91.09\n",
      "Precision: 92.44\n",
      "Recall: 91.18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90     15000\n",
      "           1       0.85      1.00      0.92     16000\n",
      "\n",
      "    accuracy                           0.91     31000\n",
      "   macro avg       0.93      0.91      0.91     31000\n",
      "weighted avg       0.92      0.91      0.91     31000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "labels_pred = nb.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy = accuracy_score(y_test, labels_pred)\n",
    "f1 = f1_score(y_test, labels_pred, average='weighted')\n",
    "precision = precision_score(y_test, labels_pred, average='weighted')\n",
    "recall = recall_score(y_test, labels_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"F1 Score: %.2f\" % (f1*100))\n",
    "print(\"Precision: %.2f\" % (precision*100))\n",
    "print(\"Recall: %.2f\" % (recall*100))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42, max_iter=300).fit(X_train_tfidf, depression_train[' Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.35%\n",
      "F1 Score: 98.34\n",
      "Precision: 98.40\n",
      "Recall: 98.35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98     15000\n",
      "           1       0.97      1.00      0.98     16000\n",
      "\n",
      "    accuracy                           0.98     31000\n",
      "   macro avg       0.98      0.98      0.98     31000\n",
      "weighted avg       0.98      0.98      0.98     31000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred2 = clf.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_2 = accuracy_score(y_test, labels_pred2)\n",
    "f1_2 = f1_score(y_test, labels_pred2, average='weighted')\n",
    "precision_2 = precision_score(y_test, labels_pred2, average='weighted')\n",
    "recall_2 = recall_score(y_test, labels_pred2, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_2*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_2*100))\n",
    "print(\"Precision: %.2f\" % (precision_2*100))\n",
    "print(\"Recall: %.2f\" % (recall_2*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=24)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(n_estimators = 100, random_state = 24)\n",
    "randomforest.fit(X_train_tfidf, depression_train[' Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.40%\n",
      "F1 Score: 99.40\n",
      "Precision: 99.40\n",
      "Recall: 99.40\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     15000\n",
      "           1       0.99      1.00      0.99     16000\n",
      "\n",
      "    accuracy                           0.99     31000\n",
      "   macro avg       0.99      0.99      0.99     31000\n",
      "weighted avg       0.99      0.99      0.99     31000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred3 = randomforest.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_3 = accuracy_score(y_test, labels_pred3)\n",
    "f1_3 = f1_score(y_test, labels_pred3, average='weighted')\n",
    "precision_3 = precision_score(y_test, labels_pred3, average='weighted')\n",
    "recall_3 = recall_score(y_test, labels_pred3, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_3*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_3*100))\n",
    "print(\"Precision: %.2f\" % (precision_3*100))\n",
    "print(\"Recall: %.2f\" % (recall_3*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear', random_state=42).fit(X_train_tfidf, depression_train[' Label'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.98%\n",
      "F1 Score: 98.98\n",
      "Precision: 99.00\n",
      "Recall: 98.98\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     15000\n",
      "           1       0.98      1.00      0.99     16000\n",
      "\n",
      "    accuracy                           0.99     31000\n",
      "   macro avg       0.99      0.99      0.99     31000\n",
      "weighted avg       0.99      0.99      0.99     31000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred4 = SVM.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_4 = accuracy_score(y_test, labels_pred4)\n",
    "f1_4 = f1_score(y_test, labels_pred4, average='weighted')\n",
    "precision_4 = precision_score(y_test, labels_pred4, average='weighted')\n",
    "recall_4 = recall_score(y_test, labels_pred4, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_4*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_4*100))\n",
    "print(\"Precision: %.2f\" % (precision_4*100))\n",
    "print(\"Recall: %.2f\" % (recall_4*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i didnt feel humiliated</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i can go from feeling so hopeless to so damned...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i am feeling grouchy</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15995</th>\n",
       "      <td>i just had a very brief time in the beanbag an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15996</th>\n",
       "      <td>i am now turning and i feel pathetic that i am...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15997</th>\n",
       "      <td>i feel strong and good overall</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15998</th>\n",
       "      <td>i feel like this was such a rude comment and i...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15999</th>\n",
       "      <td>i know a lot but i feel so stupid because i ca...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Input Sentiment\n",
       "0                                i didnt feel humiliated   sadness\n",
       "1      i can go from feeling so hopeless to so damned...   sadness\n",
       "2       im grabbing a minute to post i feel greedy wrong     anger\n",
       "3      i am ever feeling nostalgic about the fireplac...      love\n",
       "4                                   i am feeling grouchy     anger\n",
       "...                                                  ...       ...\n",
       "15995  i just had a very brief time in the beanbag an...   sadness\n",
       "15996  i am now turning and i feel pathetic that i am...   sadness\n",
       "15997                     i feel strong and good overall       joy\n",
       "15998  i feel like this was such a rude comment and i...     anger\n",
       "15999  i know a lot but i feel so stupid because i ca...   sadness\n",
       "\n",
       "[16000 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('../Dataset/emotion/train.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   Input\n",
      "0                                i didnt feel humiliated\n",
      "1      i can go from feeling so hopeless to so damned...\n",
      "2       im grabbing a minute to post i feel greedy wrong\n",
      "3      i am ever feeling nostalgic about the fireplac...\n",
      "4                                   i am feeling grouchy\n",
      "...                                                  ...\n",
      "15995  i just had a very brief time in the beanbag an...\n",
      "15996  i am now turning and i feel pathetic that i am...\n",
      "15997                     i feel strong and good overall\n",
      "15998  i feel like this was such a rude comment and i...\n",
      "15999  i know a lot but i feel so stupid because i ca...\n",
      "\n",
      "[16000 rows x 1 columns]\n",
      "0        sadness\n",
      "1        sadness\n",
      "2          anger\n",
      "3           love\n",
      "4          anger\n",
      "          ...   \n",
      "15995    sadness\n",
      "15996    sadness\n",
      "15997        joy\n",
      "15998      anger\n",
      "15999    sadness\n",
      "Name: Sentiment, Length: 16000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = df_train.iloc[:,:-1]\n",
    "y_train = df_train.iloc[:,-1]\n",
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({'joy': 5362, 'sadness': 4666, 'anger': 2159, 'fear': 1937, 'love': 1304, 'surprise': 572})\n",
      "Joy: 33.51%\n",
      "Sadness: 29.16%\n",
      "Anger: 13.49%\n",
      "Fear: 12.11%\n",
      "Love: 8.15%\n",
      "Surprise: 3.58%\n"
     ]
    }
   ],
   "source": [
    "y_train_dict = Counter(y_train)\n",
    "total = sum(y_train_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_train))\n",
    "print(\"Joy: %.2f%%\" % (y_train_dict.get('joy')*100 / total))\n",
    "print(\"Sadness: %.2f%%\" % (y_train_dict.get('sadness')*100 / total))\n",
    "print(\"Anger: %.2f%%\" % (y_train_dict.get('anger')*100 / total))\n",
    "print(\"Fear: %.2f%%\" % (y_train_dict.get('fear')*100 / total))\n",
    "print(\"Love: %.2f%%\" % (y_train_dict.get('love')*100 / total))\n",
    "print(\"Surprise: %.2f%%\" % (y_train_dict.get('surprise')*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling rather rotten so im not very ambiti...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>im updating my blog because i feel shitty</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i never make her separate from me because i do...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i left with my bouquet of red and yellow tulip...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i was feeling a little vain when i did this one</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>i just keep feeling like someone is being unki...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>im feeling a little cranky negative after this...</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel that i am useful to my people and that ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>im feeling more comfortable with derby i feel ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel all weird when i have to meet w people ...</td>\n",
       "      <td>fear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input Sentiment\n",
       "0     im feeling rather rotten so im not very ambiti...   sadness\n",
       "1             im updating my blog because i feel shitty   sadness\n",
       "2     i never make her separate from me because i do...   sadness\n",
       "3     i left with my bouquet of red and yellow tulip...       joy\n",
       "4       i was feeling a little vain when i did this one   sadness\n",
       "...                                                 ...       ...\n",
       "1995  i just keep feeling like someone is being unki...     anger\n",
       "1996  im feeling a little cranky negative after this...     anger\n",
       "1997  i feel that i am useful to my people and that ...       joy\n",
       "1998  im feeling more comfortable with derby i feel ...       joy\n",
       "1999  i feel all weird when i have to meet w people ...      fear\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('../Dataset/emotion/test.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Input\n",
      "0     im feeling rather rotten so im not very ambiti...\n",
      "1             im updating my blog because i feel shitty\n",
      "2     i never make her separate from me because i do...\n",
      "3     i left with my bouquet of red and yellow tulip...\n",
      "4       i was feeling a little vain when i did this one\n",
      "...                                                 ...\n",
      "1995  i just keep feeling like someone is being unki...\n",
      "1996  im feeling a little cranky negative after this...\n",
      "1997  i feel that i am useful to my people and that ...\n",
      "1998  im feeling more comfortable with derby i feel ...\n",
      "1999  i feel all weird when i have to meet w people ...\n",
      "\n",
      "[2000 rows x 1 columns]\n",
      "0       sadness\n",
      "1       sadness\n",
      "2       sadness\n",
      "3           joy\n",
      "4       sadness\n",
      "         ...   \n",
      "1995      anger\n",
      "1996      anger\n",
      "1997        joy\n",
      "1998        joy\n",
      "1999       fear\n",
      "Name: Sentiment, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_test = df_test.iloc[:,:-1]\n",
    "y_test = df_test.iloc[:,-1]\n",
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({'joy': 695, 'sadness': 581, 'anger': 275, 'fear': 224, 'love': 159, 'surprise': 66})\n",
      "Joy: 34.75%\n",
      "Sadness: 29.05%\n",
      "Anger: 13.75%\n",
      "Fear: 11.20%\n",
      "Love: 7.95%\n",
      "Surprise: 3.30%\n"
     ]
    }
   ],
   "source": [
    "y_test_dict = Counter(y_test)\n",
    "total = sum(y_test_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_test))\n",
    "print(\"Joy: %.2f%%\" % (y_test_dict.get('joy')*100 / total))\n",
    "print(\"Sadness: %.2f%%\" % (y_test_dict.get('sadness')*100 / total))\n",
    "print(\"Anger: %.2f%%\" % (y_test_dict.get('anger')*100 / total))\n",
    "print(\"Fear: %.2f%%\" % (y_test_dict.get('fear')*100 / total))\n",
    "print(\"Love: %.2f%%\" % (y_test_dict.get('love')*100 / total))\n",
    "print(\"Surprise: %.2f%%\" % (y_test_dict.get('surprise')*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i feel like i am still looking at a blank canv...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i feel like a faithful servant</td>\n",
       "      <td>love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i am just feeling cranky and blue</td>\n",
       "      <td>anger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i can have for a treat or if i am feeling festive</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>im having ssa examination tomorrow in the morn...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>i constantly worry about their fight against n...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>i feel its important to share this info for th...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>i truly feel that if you are passionate enough...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>i feel like i just wanna buy any cute make up ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Input Sentiment\n",
       "0     im feeling quite sad and sorry for myself but ...   sadness\n",
       "1     i feel like i am still looking at a blank canv...   sadness\n",
       "2                        i feel like a faithful servant      love\n",
       "3                     i am just feeling cranky and blue     anger\n",
       "4     i can have for a treat or if i am feeling festive       joy\n",
       "...                                                 ...       ...\n",
       "1995  im having ssa examination tomorrow in the morn...   sadness\n",
       "1996  i constantly worry about their fight against n...       joy\n",
       "1997  i feel its important to share this info for th...       joy\n",
       "1998  i truly feel that if you are passionate enough...       joy\n",
       "1999  i feel like i just wanna buy any cute make up ...       joy\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('../Dataset/emotion/val.txt', header =None, sep =';', names = ['Input','Sentiment'], encoding='utf-8')\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  Input\n",
      "0     im feeling quite sad and sorry for myself but ...\n",
      "1     i feel like i am still looking at a blank canv...\n",
      "2                        i feel like a faithful servant\n",
      "3                     i am just feeling cranky and blue\n",
      "4     i can have for a treat or if i am feeling festive\n",
      "...                                                 ...\n",
      "1995  im having ssa examination tomorrow in the morn...\n",
      "1996  i constantly worry about their fight against n...\n",
      "1997  i feel its important to share this info for th...\n",
      "1998  i truly feel that if you are passionate enough...\n",
      "1999  i feel like i just wanna buy any cute make up ...\n",
      "\n",
      "[2000 rows x 1 columns]\n",
      "0       sadness\n",
      "1       sadness\n",
      "2          love\n",
      "3         anger\n",
      "4           joy\n",
      "         ...   \n",
      "1995    sadness\n",
      "1996        joy\n",
      "1997        joy\n",
      "1998        joy\n",
      "1999        joy\n",
      "Name: Sentiment, Length: 2000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_val = df_val.iloc[:,:-1]\n",
    "y_val = df_val.iloc[:,-1]\n",
    "print(X_val)\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({'joy': 704, 'sadness': 550, 'anger': 275, 'fear': 212, 'love': 178, 'surprise': 81})\n",
      "Joy: 35.20%\n",
      "Sadness: 27.50%\n",
      "Anger: 13.75%\n",
      "Fear: 10.60%\n",
      "Love: 8.90%\n",
      "Surprise: 4.05%\n"
     ]
    }
   ],
   "source": [
    "y_val_dict = Counter(y_val)\n",
    "total = sum(y_val_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_val))\n",
    "print(\"Joy: %.2f%%\" % (y_val_dict.get('joy')*100 / total))\n",
    "print(\"Sadness: %.2f%%\" % (y_val_dict.get('sadness')*100 / total))\n",
    "print(\"Anger: %.2f%%\" % (y_val_dict.get('anger')*100 / total))\n",
    "print(\"Fear: %.2f%%\" % (y_val_dict.get('fear')*100 / total))\n",
    "print(\"Love: %.2f%%\" % (y_val_dict.get('love')*100 / total))\n",
    "print(\"Surprise: %.2f%%\" % (y_val_dict.get('surprise')*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in X_train['Input'].values])\n",
    "X_val_preprocessed = np.array([text_preprocessing(text) for text in X_val['Input'].values])\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3), smooth_idf=False)\n",
    "\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_val_tfidf = tf_idf.transform(X_val_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After undersampling:  Counter({'anger': 572, 'fear': 572, 'joy': 572, 'love': 572, 'sadness': 572, 'surprise': 572})\n"
     ]
    }
   ],
   "source": [
    "# define undersampling strategy\n",
    "undersample = RandomUnderSampler(random_state=0)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_under, y_train_under = undersample.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(\"After undersampling: \", Counter(y_train_under))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After oversampling:  Counter({'sadness': 5362, 'anger': 5362, 'love': 5362, 'surprise': 5362, 'fear': 5362, 'joy': 5362})\n"
     ]
    }
   ],
   "source": [
    "# define oversampling strategy\n",
    "SMOTE = SMOTE(random_state=42)\n",
    "\n",
    "# fit and apply the transform\n",
    "X_train_SMOTE, y_train_SMOTE = SMOTE.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# summarize class distribution\n",
    "print(\"After oversampling: \", Counter(y_train_SMOTE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = { 'anger': 0,\n",
    "    'fear': 1,\n",
    "    'joy': 2,\n",
    "    'love': 3,\n",
    "    'sadness': 4,\n",
    "    'surprise': 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_SMOTE_encode = [encoding[key] for key in y_train_SMOTE.values]\n",
    "y_val = [encoding[key] for key in df_val['Sentiment'].values]\n",
    "y_test = [encoding[key] for key in df_test['Sentiment'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_preprocessed = np.array([text_preprocessing(text) for text in X_test['Input'].values])\n",
    "X_test_tfidf = tf_idf.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train_SMOTE, y_train_SMOTE_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.10%\n",
      "F1 Score: 84.63\n",
      "Precision: 85.97\n",
      "Recall: 84.10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.82      0.82       275\n",
      "           1       0.83      0.78      0.81       224\n",
      "           2       0.91      0.83      0.87       695\n",
      "           3       0.61      0.85      0.71       159\n",
      "           4       0.93      0.88      0.91       581\n",
      "           5       0.50      0.85      0.63        66\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.77      0.84      0.79      2000\n",
      "weighted avg       0.86      0.84      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "labels_pred = nb.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy = accuracy_score(y_test, labels_pred)\n",
    "f1 = f1_score(y_test, labels_pred, average='weighted')\n",
    "precision = precision_score(y_test, labels_pred, average='weighted')\n",
    "recall = recall_score(y_test, labels_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"F1 Score: %.2f\" % (f1*100))\n",
    "print(\"Precision: %.2f\" % (precision*100))\n",
    "print(\"Recall: %.2f\" % (recall*100))\n",
    "\n",
    "\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[226,  10,  13,   5,  17,   4],\n",
       "       [  8, 175,   8,   4,  10,  19],\n",
       "       [ 15,   8, 576,  69,   6,  21],\n",
       "       [  3,   1,  14, 135,   4,   2],\n",
       "       [ 20,  12,  17,   8, 514,  10],\n",
       "       [  1,   4,   3,   1,   1,  56]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/NB_Emotion.h5', 'wb') as model:\n",
    "    pickle.dump(nb, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42, max_iter=300).fit(X_train_SMOTE, y_train_SMOTE_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.85%\n",
      "F1 Score: 88.01\n",
      "Precision: 88.43\n",
      "Recall: 87.85\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       275\n",
      "           1       0.87      0.80      0.84       224\n",
      "           2       0.91      0.89      0.90       695\n",
      "           3       0.71      0.87      0.78       159\n",
      "           4       0.94      0.91      0.92       581\n",
      "           5       0.64      0.82      0.72        66\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.82      0.86      0.84      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred2 = clf.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_2 = accuracy_score(y_test, labels_pred2)\n",
    "f1_2 = f1_score(y_test, labels_pred2, average='weighted')\n",
    "precision_2 = precision_score(y_test, labels_pred2, average='weighted')\n",
    "recall_2 = recall_score(y_test, labels_pred2, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_2*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_2*100))\n",
    "print(\"Precision: %.2f\" % (precision_2*100))\n",
    "print(\"Recall: %.2f\" % (recall_2*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[238,   8,  14,   2,  13,   0],\n",
       "       [  8, 180,   7,   1,  12,  16],\n",
       "       [  4,   4, 619,  50,   7,  11],\n",
       "       [  2,   0,  16, 138,   3,   0],\n",
       "       [ 21,   7,  19,   3, 528,   3],\n",
       "       [  0,   7,   4,   0,   1,  54]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/LogReg_Emotion.h5', 'wb') as model:\n",
    "    pickle.dump(clf, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=24)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(n_estimators = 100, random_state = 24)\n",
    "randomforest.fit(X_train_SMOTE, y_train_SMOTE_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.10%\n",
      "F1 Score: 88.01\n",
      "Precision: 88.02\n",
      "Recall: 88.10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.91      0.89       275\n",
      "           1       0.91      0.82      0.86       224\n",
      "           2       0.89      0.92      0.90       695\n",
      "           3       0.82      0.75      0.78       159\n",
      "           4       0.91      0.91      0.91       581\n",
      "           5       0.67      0.61      0.63        66\n",
      "\n",
      "    accuracy                           0.88      2000\n",
      "   macro avg       0.84      0.82      0.83      2000\n",
      "weighted avg       0.88      0.88      0.88      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred3 = randomforest.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_3 = accuracy_score(y_test, labels_pred3)\n",
    "f1_3 = f1_score(y_test, labels_pred3, average='weighted')\n",
    "precision_3 = precision_score(y_test, labels_pred3, average='weighted')\n",
    "recall_3 = recall_score(y_test, labels_pred3, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_3*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_3*100))\n",
    "print(\"Precision: %.2f\" % (precision_3*100))\n",
    "print(\"Recall: %.2f\" % (recall_3*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[249,   0,  12,   0,  14,   0],\n",
       "       [ 10, 184,   5,   0,  12,  13],\n",
       "       [  6,   3, 638,  25,  19,   4],\n",
       "       [  3,   0,  31, 120,   4,   1],\n",
       "       [ 19,   4,  23,   2, 531,   2],\n",
       "       [  0,  12,  11,   0,   3,  40]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/RF_Emotion.h5', 'wb') as model:\n",
    "    pickle.dump(randomforest, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear', random_state=42).fit(X_train_SMOTE, y_train_SMOTE_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.65%\n",
      "F1 Score: 88.73\n",
      "Precision: 88.87\n",
      "Recall: 88.65\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.88      0.89       275\n",
      "           1       0.86      0.82      0.84       224\n",
      "           2       0.92      0.91      0.91       695\n",
      "           3       0.74      0.82      0.78       159\n",
      "           4       0.93      0.93      0.93       581\n",
      "           5       0.63      0.70      0.66        66\n",
      "\n",
      "    accuracy                           0.89      2000\n",
      "   macro avg       0.83      0.84      0.84      2000\n",
      "weighted avg       0.89      0.89      0.89      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred4 = SVM.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_4 = accuracy_score(y_test, labels_pred4)\n",
    "f1_4 = f1_score(y_test, labels_pred4, average='weighted')\n",
    "precision_4 = precision_score(y_test, labels_pred4, average='weighted')\n",
    "recall_4 = recall_score(y_test, labels_pred4, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_4*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_4*100))\n",
    "print(\"Precision: %.2f\" % (precision_4*100))\n",
    "print(\"Recall: %.2f\" % (recall_4*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[242,   6,  10,   1,  16,   0],\n",
       "       [  8, 184,   5,   2,  12,  13],\n",
       "       [  4,   2, 632,  39,   8,  10],\n",
       "       [  0,   0,  24, 131,   3,   1],\n",
       "       [ 16,   9,  12,   3, 538,   3],\n",
       "       [  0,  13,   5,   0,   2,  46]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./model/SVM_Emotion.h5', 'wb') as model:\n",
    "    pickle.dump(SVM, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599995</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601966</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmandaMarie1028</td>\n",
       "      <td>Just woke up. Having no school is the best fee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599996</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601969</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>TheWDBoards</td>\n",
       "      <td>TheWDB.com - Very cool to hear old Walt interv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599997</th>\n",
       "      <td>4</td>\n",
       "      <td>2193601991</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>bpbabe</td>\n",
       "      <td>Are you ready for your MoJo Makeover? Ask me f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599998</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602064</td>\n",
       "      <td>Tue Jun 16 08:40:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>tinydiamondz</td>\n",
       "      <td>Happy 38th Birthday to my boo of alll time!!! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599999</th>\n",
       "      <td>4</td>\n",
       "      <td>2193602129</td>\n",
       "      <td>Tue Jun 16 08:40:50 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>RyanTrevMorris</td>\n",
       "      <td>happy #charitytuesday @theNSPCC @SparksCharity...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target         ids                          date      flag  \\\n",
       "0             0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1             0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2             0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3             0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4             0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...         ...         ...                           ...       ...   \n",
       "1599995       4  2193601966  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599996       4  2193601969  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599997       4  2193601991  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599998       4  2193602064  Tue Jun 16 08:40:49 PDT 2009  NO_QUERY   \n",
       "1599999       4  2193602129  Tue Jun 16 08:40:50 PDT 2009  NO_QUERY   \n",
       "\n",
       "                    user                                               text  \n",
       "0        _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1          scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2               mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3                ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                 Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                  ...                                                ...  \n",
       "1599995  AmandaMarie1028  Just woke up. Having no school is the best fee...  \n",
       "1599996      TheWDBoards  TheWDB.com - Very cool to hear old Walt interv...  \n",
       "1599997           bpbabe  Are you ready for your MoJo Makeover? Ask me f...  \n",
       "1599998     tinydiamondz  Happy 38th Birthday to my boo of alll time!!! ...  \n",
       "1599999   RyanTrevMorris  happy #charitytuesday @theNSPCC @SparksCharity...  \n",
       "\n",
       "[1600000 rows x 6 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATASET_COLUMNS = [\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"]\n",
    "DATASET_ENCODING = \"ISO-8859-1\"\n",
    "\n",
    "df = pd.read_csv('../Dataset/sentiment_tweets/training.1600000.processed.noemoticon.csv', encoding=DATASET_ENCODING, names=DATASET_COLUMNS)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['target'] = df['target'].replace(4, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D\"\n",
      " \"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\"\n",
      " '@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds'\n",
      " ... 'Are you ready for your MoJo Makeover? Ask me for details '\n",
      " 'Happy 38th Birthday to my boo of alll time!!! Tupac Amaru Shakur '\n",
      " 'happy #charitytuesday @theNSPCC @SparksCharity @SpeakingUpH4H ']\n",
      "0          0\n",
      "1          0\n",
      "2          0\n",
      "3          0\n",
      "4          0\n",
      "          ..\n",
      "1599995    1\n",
      "1599996    1\n",
      "1599997    1\n",
      "1599998    1\n",
      "1599999    1\n",
      "Name: target, Length: 1600000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train = df['text']\n",
    "y_train = df['target']\n",
    "print(X_train.values)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({0: 800000, 1: 800000})\n",
      "Label 0: 50.00%\n",
      "Label 1: 50.00%\n"
     ]
    }
   ],
   "source": [
    "y_train_dict = Counter(y_train)\n",
    "total = sum(y_train_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_train))\n",
    "print(\"Label 0: %.2f%%\" % (y_train_dict.get(0)*100 / total))\n",
    "print(\"Label 1: %.2f%%\" % (y_train_dict.get(1)*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df['target'] == 0]\n",
    "df_1 = df[df['target'] == 1]\n",
    "df_new = pd.concat([df_0[:25000], df_1[:25000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824995</th>\n",
       "      <td>1</td>\n",
       "      <td>1556381057</td>\n",
       "      <td>Sat Apr 18 22:37:08 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ethanattack</td>\n",
       "      <td>Yup. Going to sleep. Night guys.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824996</th>\n",
       "      <td>1</td>\n",
       "      <td>1556381076</td>\n",
       "      <td>Sat Apr 18 22:37:06 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>GinaLaGuardia</td>\n",
       "      <td>@MsUnitedStates Thank you so, so, so, so much ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824997</th>\n",
       "      <td>1</td>\n",
       "      <td>1556381131</td>\n",
       "      <td>Sat Apr 18 22:37:09 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>CarolCalazans</td>\n",
       "      <td>@tommcfly Hey Tom How are you? http://twitpic....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824998</th>\n",
       "      <td>1</td>\n",
       "      <td>1556381147</td>\n",
       "      <td>Sat Apr 18 22:37:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>KKVegas</td>\n",
       "      <td>Teasing and Mack 1-0 are taking Vegas by storm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824999</th>\n",
       "      <td>1</td>\n",
       "      <td>1556381150</td>\n",
       "      <td>Sat Apr 18 22:37:07 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>me0058</td>\n",
       "      <td>@monicachung Love your name! haha It's mine too</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "0            0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1            0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2            0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3            0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4            0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "824995       1  1556381057  Sat Apr 18 22:37:08 PDT 2009  NO_QUERY   \n",
       "824996       1  1556381076  Sat Apr 18 22:37:06 PDT 2009  NO_QUERY   \n",
       "824997       1  1556381131  Sat Apr 18 22:37:09 PDT 2009  NO_QUERY   \n",
       "824998       1  1556381147  Sat Apr 18 22:37:07 PDT 2009  NO_QUERY   \n",
       "824999       1  1556381150  Sat Apr 18 22:37:07 PDT 2009  NO_QUERY   \n",
       "\n",
       "                   user                                               text  \n",
       "0       _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1         scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2              mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3               ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4                Karoli  @nationwideclass no, it's not behaving at all....  \n",
       "...                 ...                                                ...  \n",
       "824995      ethanattack                  Yup. Going to sleep. Night guys.   \n",
       "824996    GinaLaGuardia  @MsUnitedStates Thank you so, so, so, so much ...  \n",
       "824997    CarolCalazans  @tommcfly Hey Tom How are you? http://twitpic....  \n",
       "824998          KKVegas  Teasing and Mack 1-0 are taking Vegas by storm...  \n",
       "824999           me0058   @monicachung Love your name! haha It's mine too   \n",
       "\n",
       "[50000 rows x 6 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 25000, 1: 25000})\n"
     ]
    }
   ],
   "source": [
    "# 0: NEGATIVE\n",
    "# 1: POSITIVE\n",
    "\n",
    "print(Counter(df_new['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    s = re.sub(r'#(\\w+)', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_new, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>814087</th>\n",
       "      <td>1</td>\n",
       "      <td>1550708726</td>\n",
       "      <td>Sat Apr 18 07:01:04 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MissMIsanchez</td>\n",
       "      <td>@anterazor teacup yorkie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805893</th>\n",
       "      <td>1</td>\n",
       "      <td>1468728004</td>\n",
       "      <td>Tue Apr 07 03:24:24 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>rahnocerous</td>\n",
       "      <td>@xCarCrashHearts on friday till monday so plan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820278</th>\n",
       "      <td>1</td>\n",
       "      <td>1553676855</td>\n",
       "      <td>Sat Apr 18 14:54:52 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>alejandradd</td>\n",
       "      <td>@nerdist He's doing great. He read almost 1000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>0</td>\n",
       "      <td>1555901859</td>\n",
       "      <td>Sat Apr 18 21:01:41 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lovesickpause</td>\n",
       "      <td>When did I lose my motivation, my momentum?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>0</td>\n",
       "      <td>1553336123</td>\n",
       "      <td>Sat Apr 18 13:59:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>JenniferBoydon</td>\n",
       "      <td>@lollipopdaisy I have  It's jed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11284</th>\n",
       "      <td>0</td>\n",
       "      <td>1551291795</td>\n",
       "      <td>Sat Apr 18 08:39:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Srizzil</td>\n",
       "      <td>7-10 Crusaders Lead!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819732</th>\n",
       "      <td>1</td>\n",
       "      <td>1553492848</td>\n",
       "      <td>Sat Apr 18 14:24:55 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>vaporcat</td>\n",
       "      <td>Allo internets. Out? Now? Dammit. &amp;lt;3  i has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813158</th>\n",
       "      <td>1</td>\n",
       "      <td>1548702733</td>\n",
       "      <td>Fri Apr 17 21:42:44 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Calilily</td>\n",
       "      <td>yummm the best tasting rice crispees ever! It ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0</td>\n",
       "      <td>1468023146</td>\n",
       "      <td>Mon Apr 06 23:18:33 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>EikLovesYou</td>\n",
       "      <td>@reannaremick doesnt work on my cell  go to sl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15795</th>\n",
       "      <td>0</td>\n",
       "      <td>1554496052</td>\n",
       "      <td>Sat Apr 18 17:09:14 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>divatracy0227</td>\n",
       "      <td>@InkedFrackGrl I dont understand why you cant ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "814087       1  1550708726  Sat Apr 18 07:01:04 PDT 2009  NO_QUERY   \n",
       "805893       1  1468728004  Tue Apr 07 03:24:24 PDT 2009  NO_QUERY   \n",
       "820278       1  1553676855  Sat Apr 18 14:54:52 PDT 2009  NO_QUERY   \n",
       "16398        0  1555901859  Sat Apr 18 21:01:41 PDT 2009  NO_QUERY   \n",
       "13653        0  1553336123  Sat Apr 18 13:59:45 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "11284        0  1551291795  Sat Apr 18 08:39:57 PDT 2009  NO_QUERY   \n",
       "819732       1  1553492848  Sat Apr 18 14:24:55 PDT 2009  NO_QUERY   \n",
       "813158       1  1548702733  Fri Apr 17 21:42:44 PDT 2009  NO_QUERY   \n",
       "860          0  1468023146  Mon Apr 06 23:18:33 PDT 2009  NO_QUERY   \n",
       "15795        0  1554496052  Sat Apr 18 17:09:14 PDT 2009  NO_QUERY   \n",
       "\n",
       "                  user                                               text  \n",
       "814087   MissMIsanchez                          @anterazor teacup yorkie   \n",
       "805893     rahnocerous  @xCarCrashHearts on friday till monday so plan...  \n",
       "820278     alejandradd  @nerdist He's doing great. He read almost 1000...  \n",
       "16398    lovesickpause       When did I lose my motivation, my momentum?   \n",
       "13653   JenniferBoydon                    @lollipopdaisy I have  It's jed  \n",
       "...                ...                                                ...  \n",
       "11284          Srizzil                              7-10 Crusaders Lead!   \n",
       "819732        vaporcat  Allo internets. Out? Now? Dammit. &lt;3  i has...  \n",
       "813158        Calilily  yummm the best tasting rice crispees ever! It ...  \n",
       "860        EikLovesYou  @reannaremick doesnt work on my cell  go to sl...  \n",
       "15795    divatracy0227  @InkedFrackGrl I dont understand why you cant ...  \n",
       "\n",
       "[40000 rows x 6 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>808553</th>\n",
       "      <td>1</td>\n",
       "      <td>1469243500</td>\n",
       "      <td>Tue Apr 07 05:44:17 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>einsteinradio</td>\n",
       "      <td>@petshopboys Good stuff sirs, I hope it's soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>0</td>\n",
       "      <td>1548745312</td>\n",
       "      <td>Fri Apr 17 21:50:46 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Paolo1792</td>\n",
       "      <td>Just woke up.. It's 12:49pm here in the Philip...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0</td>\n",
       "      <td>1467861413</td>\n",
       "      <td>Mon Apr 06 22:32:58 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>AmyJade</td>\n",
       "      <td>couldn't get shit done today ~ i'm so screwed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>0</td>\n",
       "      <td>1551807543</td>\n",
       "      <td>Sat Apr 18 10:01:29 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>grimlok</td>\n",
       "      <td>this rick ross album makes me wish i had a car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814489</th>\n",
       "      <td>1</td>\n",
       "      <td>1550819919</td>\n",
       "      <td>Sat Apr 18 07:21:27 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>lilellis92</td>\n",
       "      <td>nice day outside so think its the right time f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803567</th>\n",
       "      <td>1</td>\n",
       "      <td>1468394654</td>\n",
       "      <td>Tue Apr 07 01:24:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>MissBossiie</td>\n",
       "      <td>Being The SweetHeart That I Am!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800079</th>\n",
       "      <td>1</td>\n",
       "      <td>1467825491</td>\n",
       "      <td>Mon Apr 06 22:23:36 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Scyranth</td>\n",
       "      <td>@mattgalloway Thanks for the hook up with @Car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18707</th>\n",
       "      <td>0</td>\n",
       "      <td>1556668828</td>\n",
       "      <td>Sat Apr 18 23:48:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>firewontquell</td>\n",
       "      <td>ate an insane amount of food at @bombnomnom's ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15200</th>\n",
       "      <td>0</td>\n",
       "      <td>1554038553</td>\n",
       "      <td>Sat Apr 18 15:54:03 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mandyyx</td>\n",
       "      <td>fucking a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5857</th>\n",
       "      <td>0</td>\n",
       "      <td>1469216422</td>\n",
       "      <td>Tue Apr 07 05:38:32 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>cath_ka</td>\n",
       "      <td>I have a terrible headache</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        target         ids                          date      flag  \\\n",
       "808553       1  1469243500  Tue Apr 07 05:44:17 PDT 2009  NO_QUERY   \n",
       "9427         0  1548745312  Fri Apr 17 21:50:46 PDT 2009  NO_QUERY   \n",
       "199          0  1467861413  Mon Apr 06 22:32:58 PDT 2009  NO_QUERY   \n",
       "12447        0  1551807543  Sat Apr 18 10:01:29 PDT 2009  NO_QUERY   \n",
       "814489       1  1550819919  Sat Apr 18 07:21:27 PDT 2009  NO_QUERY   \n",
       "...        ...         ...                           ...       ...   \n",
       "803567       1  1468394654  Tue Apr 07 01:24:12 PDT 2009  NO_QUERY   \n",
       "800079       1  1467825491  Mon Apr 06 22:23:36 PDT 2009  NO_QUERY   \n",
       "18707        0  1556668828  Sat Apr 18 23:48:03 PDT 2009  NO_QUERY   \n",
       "15200        0  1554038553  Sat Apr 18 15:54:03 PDT 2009  NO_QUERY   \n",
       "5857         0  1469216422  Tue Apr 07 05:38:32 PDT 2009  NO_QUERY   \n",
       "\n",
       "                 user                                               text  \n",
       "808553  einsteinradio    @petshopboys Good stuff sirs, I hope it's soon   \n",
       "9427        Paolo1792  Just woke up.. It's 12:49pm here in the Philip...  \n",
       "199           AmyJade     couldn't get shit done today ~ i'm so screwed   \n",
       "12447         grimlok    this rick ross album makes me wish i had a car   \n",
       "814489     lilellis92  nice day outside so think its the right time f...  \n",
       "...               ...                                                ...  \n",
       "803567    MissBossiie                   Being The SweetHeart That I Am!   \n",
       "800079       Scyranth  @mattgalloway Thanks for the hook up with @Car...  \n",
       "18707   firewontquell  ate an insane amount of food at @bombnomnom's ...  \n",
       "15200         mandyyx                                         fucking a   \n",
       "5857          cath_ka                        I have a terrible headache   \n",
       "\n",
       "[10000 rows x 6 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 20022, 0: 19978})\n",
      "Counter({0: 5022, 1: 4978})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df_train['target']))\n",
    "print(Counter(df_test['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in df_train['text'].values])\n",
    "X_test_preprocessed = np.array([text_preprocessing(text) for text in df_test['text'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['teacup yorkie', 'friday till monday plan alot relaxing beach',\n",
       "       'great read almost 1000 names less 45 minutes', ...,\n",
       "       'yummm best tasting rice crispees ever marshmellows',\n",
       "       'doesnt work cell go sleep p', 'dont understand cant pull'],\n",
       "      dtype='<U150')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X_train_preprocessed.pickle', 'wb') as train:\n",
    "    pickle.dump(X_train_preprocessed, train)\n",
    "    \n",
    "with open('X_test_preprocessed.pickle', 'wb') as test:\n",
    "    pickle.dump(X_test_preprocessed, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('X_train_preprocessed.pickle', 'rb') as train:\n",
    "    X_train_preprocessed = pickle.load(train)\n",
    "    \n",
    "with open('X_test_preprocessed.pickle', 'rb') as test:\n",
    "    X_test_preprocessed = pickle.load(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3), smooth_idf=False)\n",
    "\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = tf_idf.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.38%\n",
      "F1 Score: 76.36\n",
      "Precision: 76.45\n",
      "Recall: 76.38\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77      5022\n",
      "           1       0.78      0.74      0.76      4978\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "labels_pred = nb.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "y_test = df_test['target'].values\n",
    "accuracy = accuracy_score(y_test, labels_pred)\n",
    "f1 = f1_score(y_test, labels_pred, average='weighted')\n",
    "precision = precision_score(y_test, labels_pred, average='weighted')\n",
    "recall = recall_score(y_test, labels_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy*100))\n",
    "print(\"F1 Score: %.2f\" % (f1*100))\n",
    "print(\"Precision: %.2f\" % (precision*100))\n",
    "print(\"Recall: %.2f\" % (recall*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3979, 1043],\n",
       "       [1319, 3659]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42, max_iter=500).fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.25%\n",
      "F1 Score: 76.25\n",
      "Precision: 76.25\n",
      "Recall: 76.25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      5022\n",
      "           1       0.76      0.76      0.76      4978\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "y_test = df_test['target'].values\n",
    "labels_pred2 = clf.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_2 = accuracy_score(y_test, labels_pred2)\n",
    "f1_2 = f1_score(y_test, labels_pred2, average='weighted')\n",
    "precision_2 = precision_score(y_test, labels_pred2, average='weighted')\n",
    "recall_2 = recall_score(y_test, labels_pred2, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_2*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_2*100))\n",
    "print(\"Precision: %.2f\" % (precision_2*100))\n",
    "print(\"Recall: %.2f\" % (recall_2*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3865, 1157],\n",
       "       [1218, 3760]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=1e-06, random_state=42)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "clf_svm = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-6, random_state=42)\n",
    "clf_svm.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.12%\n",
      "F1 Score: 76.12\n",
      "Precision: 76.12\n",
      "Recall: 76.12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.77      0.76      5022\n",
      "           1       0.76      0.75      0.76      4978\n",
      "\n",
      "    accuracy                           0.76     10000\n",
      "   macro avg       0.76      0.76      0.76     10000\n",
      "weighted avg       0.76      0.76      0.76     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "labels_pred4 = clf_svm.predict(X_test_tfidf)\n",
    "y_test = df_test['target'].values\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_4 = accuracy_score(y_test, labels_pred4)\n",
    "f1_4 = f1_score(y_test, labels_pred4, average='weighted')\n",
    "precision_4 = precision_score(y_test, labels_pred4, average='weighted')\n",
    "recall_4 = recall_score(y_test, labels_pred4, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_4*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_4*100))\n",
    "print(\"Precision: %.2f\" % (precision_4*100))\n",
    "print(\"Recall: %.2f\" % (recall_4*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3857, 1165],\n",
       "       [1223, 3755]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=24)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(n_estimators = 100, random_state = 24)\n",
    "randomforest.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 74.83%\n",
      "F1 Score: 74.82\n",
      "Precision: 74.87\n",
      "Recall: 74.83\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      5022\n",
      "           1       0.74      0.77      0.75      4978\n",
      "\n",
      "    accuracy                           0.75     10000\n",
      "   macro avg       0.75      0.75      0.75     10000\n",
      "weighted avg       0.75      0.75      0.75     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = df_test['target'].values\n",
    "labels_pred3 = randomforest.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_3 = accuracy_score(y_test, labels_pred3)\n",
    "f1_3 = f1_score(y_test, labels_pred3, average='weighted')\n",
    "precision_3 = precision_score(y_test, labels_pred3, average='weighted')\n",
    "recall_3 = recall_score(y_test, labels_pred3, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_3*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_3*100))\n",
    "print(\"Precision: %.2f\" % (precision_3*100))\n",
    "print(\"Recall: %.2f\" % (recall_3*100))\n",
    "\n",
    "print(classification_report(y_test, labels_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': {'score': '0', 'polarity-neg': False, 'polarity-pos': False, 'polarity': ''}, 'preprocess': {'input': 'I like this game', 'neg': [], 'pos': [], 'segmented': ['I', ' ', 'like', ' ', 'this', ' ', 'game'], 'keyword': ['I', 'like', 'this', 'game']}, 'alert': [], 'comparative': [], 'associative': [], 'intention': {'request': '0', 'sentiment': '0', 'question': '0', 'announcement': '0'}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    " \n",
    "url = \"https://api.aiforthai.in.th/ssense\"\n",
    " \n",
    "text = 'I like this game'\n",
    " \n",
    "params = {'text':text}\n",
    " \n",
    "headers = {\n",
    "    'Apikey': \"g9DsotewMbQATsKL74HhB7jw1F16nEmm\"\n",
    "    }\n",
    " \n",
    "response = requests.get(url, headers=headers, params=params)\n",
    " \n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suicidal Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Content</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.964062e+07</td>\n",
       "      <td>The end.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.350528e+07</td>\n",
       "      <td>GOD OVER EVERYTHING.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.350528e+07</td>\n",
       "      <td>I'm sorry.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.350528e+07</td>\n",
       "      <td>God... please forgive me.</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.350528e+07</td>\n",
       "      <td>This day couldn't get any worse...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>9.334510e+17</td>\n",
       "      <td>endless pain in life,end it</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>9.368910e+17</td>\n",
       "      <td>lets ave a lot of fun</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>9.123420e+17</td>\n",
       "      <td>Nothing left in this world for me,i want to die</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>9.368910e+17</td>\n",
       "      <td>I am successful in life</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>9.368910e+17</td>\n",
       "      <td>End my life</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Id                                          Content Sentiment\n",
       "0    4.964062e+07                                         The end.  Negative\n",
       "1    4.350528e+07                             GOD OVER EVERYTHING.  Negative\n",
       "2    4.350528e+07                                       I'm sorry.  Negative\n",
       "3    4.350528e+07                        God... please forgive me.  Negative\n",
       "4    4.350528e+07               This day couldn't get any worse...  Negative\n",
       "..            ...                                              ...       ...\n",
       "298  9.334510e+17                      endless pain in life,end it  Negative\n",
       "299  9.368910e+17                            lets ave a lot of fun  Positive\n",
       "300  9.123420e+17  Nothing left in this world for me,i want to die  Negative\n",
       "301  9.368910e+17                          I am successful in life  Positive\n",
       "302  9.368910e+17                                      End my life  Negative\n",
       "\n",
       "[303 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suicide_df = pd.read_csv('../Dataset/Twitter_Suicide_Data_new.csv')\n",
    "suicide_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Checking:  Counter({'Negative': 175, 'Positive': 128})\n",
      "Label 0: 57.76%\n",
      "Label 1: 42.24%\n"
     ]
    }
   ],
   "source": [
    "y_train = suicide_df['Sentiment']\n",
    "y_train_dict = Counter(y_train)\n",
    "total = sum(y_train_dict.values())\n",
    "print(\"Balanced Checking: \", Counter(y_train))\n",
    "print(\"Label 0: %.2f%%\" % (y_train_dict.get('Negative')*100 / total))\n",
    "print(\"Label 1: %.2f%%\" % (y_train_dict.get('Positive')*100 / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(suicide_df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# Uncomment to download \"stopwords\"\n",
    "#nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "def text_preprocessing(s):\n",
    "    \"\"\"\n",
    "    - Lowercase the sentence\n",
    "    - Change \"'t\" to \"not\"\n",
    "    - Remove \"@name\"\n",
    "    - Isolate and remove punctuations except \"?\"\n",
    "    - Remove other special characters\n",
    "    - Remove stop words except \"not\" and \"can\"\n",
    "    - Remove trailing whitespace\n",
    "    \"\"\"\n",
    "    s = s.lower()\n",
    "    # Change 't to 'not'\n",
    "    s = re.sub(r\"\\'t\", \" not\", s)\n",
    "    # Remove @name\n",
    "    s = re.sub(r'(@.*?)[\\s]', ' ', s)\n",
    "    # Isolate and remove punctuations except '?'\n",
    "    s = re.sub(r'([\\'\\\"\\.\\(\\)\\!\\?\\\\\\/\\,])', r' \\1 ', s)\n",
    "    s = re.sub(r'[^\\w\\s\\?]', ' ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•«\\n])', ' ', s)\n",
    "    # Remove stopwords except 'not' and 'can'\n",
    "    s = \" \".join([word for word in s.split()\n",
    "                  if word not in stopwords.words('english')\n",
    "                  or word in ['not', 'can']])\n",
    "    # Remove trailing whitespace\n",
    "    s = re.sub(r'\\s+', ' ', s).strip()\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Negative': 135, 'Positive': 107})\n",
      "Counter({'Negative': 40, 'Positive': 21})\n"
     ]
    }
   ],
   "source": [
    "print(Counter(df_train['Sentiment']))\n",
    "print(Counter(df_test['Sentiment']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = { 'Negative': 0,\n",
    "    'Positive': 1,\n",
    "}\n",
    "\n",
    "y_train = [encoding[key] for key in df_train['Sentiment'].values]\n",
    "y_test = [encoding[key] for key in df_test['Sentiment'].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Preprocess text\n",
    "X_train_preprocessed = np.array([text_preprocessing(text) for text in df_train['Content'].values])\n",
    "X_test_preprocessed = np.array([text_preprocessing(text) for text in df_test['Content'].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Calculate TF-IDF\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1, 3), smooth_idf=False, max_features=100)\n",
    "\n",
    "X_train_tfidf = tf_idf.fit_transform(X_train_preprocessed)\n",
    "X_test_tfidf = tf_idf.transform(X_test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB().fit(X_train_tfidf, df_train['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.951\n",
      "F1 Score: 0.951\n",
      "Precision: 0.952\n",
      "Recall: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.95      0.96        40\n",
      "    Positive       0.91      0.95      0.93        21\n",
      "\n",
      "    accuracy                           0.95        61\n",
      "   macro avg       0.94      0.95      0.95        61\n",
      "weighted avg       0.95      0.95      0.95        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "labels_pred = nb.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "y_test = df_test['Sentiment'].values\n",
    "accuracy = accuracy_score(y_test, labels_pred)\n",
    "f1 = f1_score(y_test, labels_pred, average='weighted')\n",
    "precision = precision_score(y_test, labels_pred, average='weighted')\n",
    "recall = recall_score(y_test, labels_pred, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.3f\" % (accuracy))\n",
    "print(\"F1 Score: %.3f\" % (f1))\n",
    "print(\"Precision: %.3f\" % (precision))\n",
    "print(\"Recall: %.3f\" % (recall))\n",
    "\n",
    "print(classification_report(y_test, labels_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[38,  2],\n",
       "       [ 1, 20]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=42).fit(X_train_tfidf, df_train['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.967\n",
      "F1 Score: 0.967\n",
      "Precision: 0.967\n",
      "Recall: 0.967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.97      0.97        40\n",
      "    Positive       0.95      0.95      0.95        21\n",
      "\n",
      "    accuracy                           0.97        61\n",
      "   macro avg       0.96      0.96      0.96        61\n",
      "weighted avg       0.97      0.97      0.97        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import  classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "labels_pred2 = clf.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy = accuracy_score(y_test, labels_pred2)\n",
    "f1 = f1_score(y_test, labels_pred2, average='weighted')\n",
    "precision = precision_score(y_test, labels_pred2, average='weighted')\n",
    "recall = recall_score(y_test, labels_pred2, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.3f\" % (accuracy))\n",
    "print(\"F1 Score: %.3f\" % (f1))\n",
    "print(\"Precision: %.3f\" % (precision))\n",
    "print(\"Recall: %.3f\" % (recall))\n",
    "\n",
    "print(classification_report(y_test, labels_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[39,  1],\n",
       "       [ 1, 20]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=24)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "randomforest = RandomForestClassifier(n_estimators = 100, random_state = 24)\n",
    "randomforest.fit(X_train_tfidf, df_train['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.44%\n",
      "F1 Score: 93.51\n",
      "Precision: 0.938\n",
      "Recall: 0.934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.93      0.95        40\n",
      "    Positive       0.87      0.95      0.91        21\n",
      "\n",
      "    accuracy                           0.93        61\n",
      "   macro avg       0.92      0.94      0.93        61\n",
      "weighted avg       0.94      0.93      0.94        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred3 = randomforest.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "y_test = df_test['Sentiment'].values\n",
    "accuracy_3 = accuracy_score(y_test, labels_pred3)\n",
    "f1_3 = f1_score(y_test, labels_pred3, average='weighted')\n",
    "precision_3 = precision_score(y_test, labels_pred3, average='weighted')\n",
    "recall_3 = recall_score(y_test, labels_pred3, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_3*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_3*100))\n",
    "print(\"Precision: %.3f\" % (precision_3))\n",
    "print(\"Recall: %.3f\" % (recall_3))\n",
    "\n",
    "print(classification_report(y_test, labels_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[35,  5],\n",
       "       [ 3, 18]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "SVM = SVC(kernel='linear', random_state=42).fit(X_train_tfidf, df_train['Sentiment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.08%\n",
      "F1 Score: 95.11\n",
      "Precision: 0.952\n",
      "Recall: 0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.95      0.96        40\n",
      "    Positive       0.91      0.95      0.93        21\n",
      "\n",
      "    accuracy                           0.95        61\n",
      "   macro avg       0.94      0.95      0.95        61\n",
      "weighted avg       0.95      0.95      0.95        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels_pred4 = SVM.predict(X_test_tfidf)\n",
    "#labels_pred = np.round(labels_pred.flatten())\n",
    "accuracy_4 = accuracy_score(y_test, labels_pred4)\n",
    "f1_4 = f1_score(y_test, labels_pred4, average='weighted')\n",
    "precision_4 = precision_score(y_test, labels_pred4, average='weighted')\n",
    "recall_4 = recall_score(y_test, labels_pred4, average='weighted')\n",
    "\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy_4*100))\n",
    "print(\"F1 Score: %.2f\" % (f1_4*100))\n",
    "print(\"Precision: %.3f\" % (precision_4))\n",
    "print(\"Recall: %.3f\" % (recall_4))\n",
    "\n",
    "print(classification_report(y_test, labels_pred4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37,  3],\n",
       "       [ 1, 20]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, labels_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
